2024-10-15 00:07:46,867 - log.py[38] - DEBUG: entry file content: ---------------------------------
2024-10-15 00:07:46,867 - log.py[39] - DEBUG: 
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "1"

from legodnn.utils.dl.common.env import set_random_seed
set_random_seed(0)

import sys
sys.setrecursionlimit(100000)
import torch

from legodnn import BlockExtractor, BlockTrainer, ServerBlockProfiler, EdgeBlockProfiler, OptimalRuntime
from legodnn.gen_series_legodnn_models import gen_series_legodnn_models
from legodnn.block_detection.model_topology_extraction import topology_extraction
from legodnn.presets.auto_block_manager import AutoBlockManager
from legodnn.presets.common_detection_manager_1204_new import CommonDetectionManager
from legodnn.model_manager.common_model_manager import CommonModelManager
from legodnn.utils.common.file import experiments_model_file_path
from legodnn.utils.dl.common.model import get_module, set_module, get_model_size

from cv_task.datasets.image_classification.cifar_dataloader import CIFAR10Dataloader, CIFAR100Dataloader
from cv_task.image_classification.cifar.models import resnet18
from cv_task.image_classification.cifar.legodnn_configs import get_cifar100_train_config_200e


if __name__ == '__main__':
    cv_task = 'image_classification'
    dataset_name = 'cifar100'
    model_name = 'resnet18'
    method = 'legodnn'
    device = 'cuda'
    compress_layer_max_ratio = 0.125
    model_input_size = (1, 3, 32, 32)
    
    block_sparsity = [0.0, 0.2, 0.4, 0.6, 0.8]
    root_path = os.path.join('results/legodnn', cv_task, model_name+'_'+dataset_name + '_' + str(compress_layer_max_ratio).replace('.', '-'))

    compressed_blocks_dir_path = root_path + '/compressed'
    trained_blocks_dir_path = root_path + '/trained'
    descendant_models_dir_path = root_path + '/descendant'
    block_training_max_epoch = 65
    test_sample_num = 100
    
    checkpoint = '/data/gxy/legodnn-auto-on-cv-models/cv_task_model/image_classification/cifar100/resnet18/2024-10-14/20-15-10/resnet18.pth'
    teacher_model = resnet18(num_classes=100).to(device)
    teacher_model.load_state_dict(torch.load(checkpoint)['net'])

    print('\033[1;36m-------------------------------->    BUILD LEGODNN GRAPH\033[0m')
    model_graph = topology_extraction(teacher_model, model_input_size, device=device, mode='unpack')
    model_graph.print_ordered_node()
    
    print('\033[1;36m-------------------------------->    START BLOCK DETECTION\033[0m')
    detection_manager = CommonDetectionManager(model_graph, max_ratio=compress_layer_max_ratio)
    detection_manager.detection_all_blocks()
    detection_manager.print_all_blocks()

    model_manager = CommonModelManager()
    block_manager = AutoBlockManager(block_sparsity, detection_manager, model_manager)
    
    print('\033[1;36m-------------------------------->    START BLOCK EXTRACTION\033[0m')
    block_extractor = BlockExtractor(teacher_model, block_manager, compressed_blocks_dir_path, model_input_size, device)
    block_extractor.extract_all_blocks()

    print('\033[1;36m-------------------------------->    START BLOCK TRAIN\033[0m')
    train_loader, test_loader = CIFAR100Dataloader()
    block_trainer = BlockTrainer(teacher_model, block_manager, model_manager, compressed_blocks_dir_path,
                                 trained_blocks_dir_path, block_training_max_epoch, train_loader, device=device)
    block_trainer.train_all_blocks()

    server_block_profiler = ServerBlockProfiler(teacher_model, block_manager, model_manager,
                                                trained_blocks_dir_path, test_loader, model_input_size, device)
    server_block_profiler.profile_all_blocks()

    edge_block_profiler = EdgeBlockProfiler(block_manager, model_manager, trained_blocks_dir_path, 
                                            test_sample_num, model_input_size, device)
    edge_block_profiler.profile_all_blocks()

    optimal_runtime = OptimalRuntime(trained_blocks_dir_path, model_input_size,
                                     block_manager, model_manager, device)
    model_size_min = get_model_size(torch.load(os.path.join(compressed_blocks_dir_path, 'model_frame.pt')))/1024**2
    model_size_max = get_model_size(teacher_model)/1024**2 + 1
    gen_series_legodnn_models(deadline=100, model_size_search_range=[model_size_min, model_size_max], target_model_num=100, optimal_runtime=optimal_runtime, descendant_models_save_path=descendant_models_dir_path, device=device)
2024-10-15 00:07:46,867 - log.py[40] - DEBUG: entry file content: ---------------------------------
2024-10-15 00:07:54,119 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-0.pt
2024-10-15 00:07:54,120 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:54,424 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-2.pt
2024-10-15 00:07:54,424 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:54,784 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-4.pt
2024-10-15 00:07:54,784 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:55,205 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-6.pt
2024-10-15 00:07:55,205 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:55,476 - block_extractor.py[28] - INFO: save pruned block block-0 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-0-8.pt
2024-10-15 00:07:55,476 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu1): ReLU()
  (layer1): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:55,506 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-0.pt
2024-10-15 00:07:55,506 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:55,767 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-2.pt
2024-10-15 00:07:55,767 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:56,045 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-4.pt
2024-10-15 00:07:56,045 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(39, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:56,344 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-6.pt
2024-10-15 00:07:56,344 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:56,611 - block_extractor.py[28] - INFO: save pruned block block-1 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-1-8.pt
2024-10-15 00:07:56,611 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer1): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(64, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:56,644 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-0.pt
2024-10-15 00:07:56,644 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:56,857 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-2.pt
2024-10-15 00:07:56,857 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:57,073 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-4.pt
2024-10-15 00:07:57,073 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 77, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:57,306 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-6.pt
2024-10-15 00:07:57,306 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:57,531 - block_extractor.py[28] - INFO: save pruned block block-2 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-2-8.pt
2024-10-15 00:07:57,531 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(64, 26, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:57,661 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-0.pt
2024-10-15 00:07:57,661 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:58,051 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-2.pt
2024-10-15 00:07:58,051 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:58,319 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-4.pt
2024-10-15 00:07:58,319 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 77, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(77, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(77, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:58,585 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-6.pt
2024-10-15 00:07:58,585 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:58,869 - block_extractor.py[28] - INFO: save pruned block block-3 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-3-8.pt
2024-10-15 00:07:58,869 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer2): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(128, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(26, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:07:58,903 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-0.pt
2024-10-15 00:07:58,903 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:59,136 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-2.pt
2024-10-15 00:07:59,136 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:59,478 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-4.pt
2024-10-15 00:07:59,478 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 154, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:59,699 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-6.pt
2024-10-15 00:07:59,699 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:59,912 - block_extractor.py[28] - INFO: save pruned block block-4 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-4-8.pt
2024-10-15 00:07:59,912 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(128, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:07:59,947 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-0.pt
2024-10-15 00:07:59,948 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:00,230 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-2.pt
2024-10-15 00:08:00,230 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:00,538 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-4.pt
2024-10-15 00:08:00,538 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 154, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(154, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(154, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:00,901 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-6.pt
2024-10-15 00:08:00,901 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:01,214 - block_extractor.py[28] - INFO: save pruned block block-5 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-5-8.pt
2024-10-15 00:08:01,214 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer3): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(256, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(52, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:01,264 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-0.pt
2024-10-15 00:08:01,264 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:08:01,542 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-2.pt
2024-10-15 00:08:01,543 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 410, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(410, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(410, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:08:01,828 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-4.pt
2024-10-15 00:08:01,828 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 308, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(308, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(308, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:08:02,098 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-6.pt
2024-10-15 00:08:02,098 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 205, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:08:02,374 - block_extractor.py[28] - INFO: save pruned block block-6 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-6-8.pt
2024-10-15 00:08:02,374 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (conv1): Conv2d(256, 103, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    )
  )
)
2024-10-15 00:08:02,428 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.0) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-0.pt
2024-10-15 00:08:02,428 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:02,806 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.2) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-2.pt
2024-10-15 00:08:02,806 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 410, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(410, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(410, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:03,160 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.4) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-4.pt
2024-10-15 00:08:03,160 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 308, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(308, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(308, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:03,518 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.6) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-6.pt
2024-10-15 00:08:03,518 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 205, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(205, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(205, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:03,998 - block_extractor.py[28] - INFO: save pruned block block-7 (sparsity 0.8) in results/legodnn/image_classification/resnet18_cifar100_0-125/compressed/block-7-8.pt
2024-10-15 00:08:03,998 - block_extractor.py[29] - DEBUG: LegoDNNBlock(
  (layer4): ModuleDict(
    (0): ModuleDict(
      (relu2): ReLU()
    )
    (1): ModuleDict(
      (conv1): Conv2d(512, 103, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(103, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU()
      (conv2): Conv2d(103, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
2024-10-15 00:08:06,108 - block_trainer.py[183] - INFO: start block training...
2024-10-15 00:10:11,088 - block_trainer.py[357] - INFO: epoch 0 (124.979672s, 40 blocks still need training), blocks loss: 
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-0 | 0.00021892 | 0.00022647 | 0.00031054 | 0.00084484 | 0.00359833 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-1 | 0.00004112 | 0.00006425 | 0.00047315 | 0.00238608 | 0.00591138 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-2 | 0.00006046 | 0.00025119 | 0.00081996 | 0.00253919 | 0.00778742 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-3 | 0.00007223 | 0.00036950 | 0.00102172 | 0.00209934 | 0.00522966 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-4 | 0.00010934 | 0.00051940 | 0.00124319 | 0.00280183 | 0.00687667 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-5 | 0.00009048 | 0.00009622 | 0.00042137 | 0.00126805 | 0.00314627 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-6 | 0.00004730 | 0.00018399 | 0.00042422 | 0.00081396 | 0.00164106 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+
+---------+------------+------------+------------+------------+------------+
|         |    0.0     |    0.2     |    0.4     |    0.6     |    0.8     |
+---------+------------+------------+------------+------------+------------+
| block-7 | 0.01308439 | 0.02870520 | 0.05207160 | 0.09062205 | 0.15978823 |
|         |    (-)     |    (-)     |    (-)     |    (-)     |    (-)     |
+---------+------------+------------+------------+------------+------------+

2024-10-15 00:12:25,175 - block_trainer.py[357] - INFO: epoch 1 (134.086707s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00021247   |   0.00021657   |   0.00026241   |   0.00051524   |   0.00189929   |
|         | (↓ 0.00000646) | (↓ 0.00000990) | (↓ 0.00004813) | (↓ 0.00032959) | (↓ 0.00169904) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003873   |   0.00005490   |   0.00021056   |   0.00086571   |   0.00275289   |
|         | (↓ 0.00000239) | (↓ 0.00000935) | (↓ 0.00026259) | (↓ 0.00152037) | (↓ 0.00315849) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005546   |   0.00015162   |   0.00038477   |   0.00098260   |   0.00291917   |
|         | (↓ 0.00000500) | (↓ 0.00009958) | (↓ 0.00043518) | (↓ 0.00155659) | (↓ 0.00486825) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006366   |   0.00024036   |   0.00073911   |   0.00159639   |   0.00371893   |
|         | (↓ 0.00000857) | (↓ 0.00012914) | (↓ 0.00028261) | (↓ 0.00050296) | (↓ 0.00151073) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010609   |   0.00038057   |   0.00080889   |   0.00157464   |   0.00335352   |
|         | (↓ 0.00000325) | (↓ 0.00013882) | (↓ 0.00043430) | (↓ 0.00122719) | (↓ 0.00352315) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008808   |   0.00009395   |   0.00038394   |   0.00108112   |   0.00247511   |
|         | (↓ 0.00000240) | (↓ 0.00000227) | (↓ 0.00003743) | (↓ 0.00018693) | (↓ 0.00067116) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004394   |   0.00016139   |   0.00034283   |   0.00060732   |   0.00109558   |
|         | (↓ 0.00000336) | (↓ 0.00002260) | (↓ 0.00008139) | (↓ 0.00020665) | (↓ 0.00054548) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01229231   |   0.02629708   |   0.04621983   |   0.07624135   |   0.12154239   |
|         | (↓ 0.00079208) | (↓ 0.00240813) | (↓ 0.00585177) | (↓ 0.01438070) | (↓ 0.03824584) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:14:39,211 - block_trainer.py[357] - INFO: epoch 2 (134.034857s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-0 |    0.00022010   |    0.00022412   |    0.00026687   |   0.00049405   |   0.00173797   |
|         | (↓ -0.00000763) | (↓ -0.00000755) | (↓ -0.00000445) | (↓ 0.00002119) | (↓ 0.00016132) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003739   |   0.00005304   |   0.00019309   |   0.00076152   |   0.00245847   |
|         | (↓ 0.00000134) | (↓ 0.00000186) | (↓ 0.00001747) | (↓ 0.00010420) | (↓ 0.00029442) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00005557   |   0.00014390   |   0.00035472   |   0.00086168   |   0.00243034   |
|         | (↓ -0.00000011) | (↓ 0.00000772) | (↓ 0.00003005) | (↓ 0.00012092) | (↓ 0.00048883) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00006390   |   0.00023073   |   0.00071007   |   0.00152347   |   0.00352444   |
|         | (↓ -0.00000024) | (↓ 0.00000963) | (↓ 0.00002904) | (↓ 0.00007292) | (↓ 0.00019449) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00010752   |   0.00036740   |   0.00077622   |   0.00148413   |   0.00300862   |
|         | (↓ -0.00000143) | (↓ 0.00001318) | (↓ 0.00003267) | (↓ 0.00009051) | (↓ 0.00034490) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00008875   |    0.00009428   |   0.00037916   |   0.00104409   |   0.00236277   |
|         | (↓ -0.00000067) | (↓ -0.00000033) | (↓ 0.00000478) | (↓ 0.00003703) | (↓ 0.00011234) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00004638   |   0.00016066   |   0.00033289   |   0.00058674   |   0.00102677   |
|         | (↓ -0.00000244) | (↓ 0.00000073) | (↓ 0.00000994) | (↓ 0.00002057) | (↓ 0.00006882) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01226566   |   0.02589616   |   0.04512873   |   0.07376130   |   0.11540851   |
|         | (↓ 0.00002665) | (↓ 0.00040092) | (↓ 0.00109110) | (↓ 0.00248005) | (↓ 0.00613388) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:16:52,081 - block_trainer.py[357] - INFO: epoch 3 (132.869634s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00021587   |   0.00021988   |   0.00026059   |   0.00047674   |   0.00165458   |
|         | (↓ 0.00000422) | (↓ 0.00000425) | (↓ 0.00000628) | (↓ 0.00001731) | (↓ 0.00008339) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-1 |    0.00003983   |    0.00005521   |   0.00018902   |   0.00072117   |   0.00235309   |
|         | (↓ -0.00000244) | (↓ -0.00000217) | (↓ 0.00000407) | (↓ 0.00004035) | (↓ 0.00010538) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00005800   |   0.00014328   |   0.00034469   |   0.00081473   |   0.00223863   |
|         | (↓ -0.00000242) | (↓ 0.00000061) | (↓ 0.00001003) | (↓ 0.00004695) | (↓ 0.00019171) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00006562   |   0.00022871   |   0.00067373   |   0.00148682   |   0.00345693   |
|         | (↓ -0.00000172) | (↓ 0.00000203) | (↓ 0.00003634) | (↓ 0.00003665) | (↓ 0.00006751) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00011261   |   0.00036613   |   0.00076418   |   0.00144682   |   0.00283609   |
|         | (↓ -0.00000508) | (↓ 0.00000127) | (↓ 0.00001204) | (↓ 0.00003731) | (↓ 0.00017253) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008504   |   0.00009073   |   0.00037086   |   0.00102127   |   0.00230953   |
|         | (↓ 0.00000371) | (↓ 0.00000355) | (↓ 0.00000830) | (↓ 0.00002282) | (↓ 0.00005323) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004535   |   0.00015859   |   0.00032464   |   0.00057301   |   0.00098835   |
|         | (↓ 0.00000103) | (↓ 0.00000207) | (↓ 0.00000825) | (↓ 0.00001374) | (↓ 0.00003841) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01183215   |   0.02526881   |   0.04406998   |   0.07194373   |   0.11225797   |
|         | (↓ 0.00043351) | (↓ 0.00062735) | (↓ 0.00105875) | (↓ 0.00181757) | (↓ 0.00315054) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:19:04,047 - block_trainer.py[357] - INFO: epoch 4 (131.965662s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-0 |    0.00021607   |    0.00022018   |   0.00025998   |   0.00046962   |   0.00160580   |
|         | (↓ -0.00000019) | (↓ -0.00000030) | (↓ 0.00000061) | (↓ 0.00000712) | (↓ 0.00004878) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003967   |   0.00005485   |   0.00018534   |   0.00069524   |   0.00229988   |
|         | (↓ 0.00000016) | (↓ 0.00000036) | (↓ 0.00000369) | (↓ 0.00002593) | (↓ 0.00005320) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-2 |    0.00005917   |   0.00014198   |   0.00033716   |   0.00078829   |   0.00214236   |
|         | (↓ -0.00000117) | (↓ 0.00000130) | (↓ 0.00000753) | (↓ 0.00002643) | (↓ 0.00009626) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00006747   |   0.00022714   |   0.00066089   |   0.00147151   |   0.00342335   |
|         | (↓ -0.00000186) | (↓ 0.00000156) | (↓ 0.00001284) | (↓ 0.00001531) | (↓ 0.00003359) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010782   |   0.00035564   |   0.00074458   |   0.00141490   |   0.00272297   |
|         | (↓ 0.00000479) | (↓ 0.00001049) | (↓ 0.00001960) | (↓ 0.00003192) | (↓ 0.00011312) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008358   |   0.00008941   |   0.00036570   |   0.00100674   |   0.00228164   |
|         | (↓ 0.00000146) | (↓ 0.00000133) | (↓ 0.00000515) | (↓ 0.00001453) | (↓ 0.00002790) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00004540   |   0.00015740   |   0.00031991   |   0.00056240   |   0.00096333   |
|         | (↓ -0.00000006) | (↓ 0.00000119) | (↓ 0.00000474) | (↓ 0.00001061) | (↓ 0.00002502) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01165422   |   0.02484960   |   0.04341441   |   0.07089284   |   0.11060483   |
|         | (↓ 0.00017793) | (↓ 0.00041921) | (↓ 0.00065557) | (↓ 0.00105089) | (↓ 0.00165314) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:21:09,643 - block_trainer.py[357] - INFO: epoch 5 (125.595721s, 40 blocks still need training), blocks loss: 
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-0 |    0.00021614   |   0.00022013   |   0.00025917   |   0.00046602   |   0.00157564   |
|         | (↓ -0.00000007) | (↓ 0.00000005) | (↓ 0.00000081) | (↓ 0.00000360) | (↓ 0.00003016) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003942   |   0.00005460   |   0.00018229   |   0.00067888   |   0.00226836   |
|         | (↓ 0.00000025) | (↓ 0.00000025) | (↓ 0.00000305) | (↓ 0.00001637) | (↓ 0.00003153) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005886   |   0.00013984   |   0.00033102   |   0.00077062   |   0.00208618   |
|         | (↓ 0.00000031) | (↓ 0.00000214) | (↓ 0.00000614) | (↓ 0.00001767) | (↓ 0.00005618) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-3 |    0.00006750   |   0.00022659   |   0.00065466   |   0.00146511   |   0.00340420   |
|         | (↓ -0.00000002) | (↓ 0.00000055) | (↓ 0.00000623) | (↓ 0.00000639) | (↓ 0.00001915) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010637   |   0.00035074   |   0.00073386   |   0.00139523   |   0.00265140   |
|         | (↓ 0.00000145) | (↓ 0.00000490) | (↓ 0.00001072) | (↓ 0.00001967) | (↓ 0.00007157) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008292   |   0.00008866   |   0.00035508   |   0.00099410   |   0.00226501   |
|         | (↓ 0.00000066) | (↓ 0.00000075) | (↓ 0.00001062) | (↓ 0.00001264) | (↓ 0.00001662) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004485   |   0.00015493   |   0.00031583   |   0.00055468   |   0.00094694   |
|         | (↓ 0.00000055) | (↓ 0.00000247) | (↓ 0.00000407) | (↓ 0.00000772) | (↓ 0.00001639) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01149086   |   0.02446903   |   0.04285251   |   0.07005002   |   0.10958883   |
|         | (↓ 0.00016336) | (↓ 0.00038057) | (↓ 0.00056189) | (↓ 0.00084282) | (↓ 0.00101600) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:23:22,978 - block_trainer.py[357] - INFO: epoch 6 (133.334623s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00021381   |   0.00021802   |   0.00025643   |   0.00046100   |   0.00155007   |
|         | (↓ 0.00000233) | (↓ 0.00000211) | (↓ 0.00000274) | (↓ 0.00000502) | (↓ 0.00002556) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003817   |   0.00005316   |   0.00017866   |   0.00066766   |   0.00224562   |
|         | (↓ 0.00000125) | (↓ 0.00000144) | (↓ 0.00000362) | (↓ 0.00001121) | (↓ 0.00002274) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-2 |    0.00006066   |    0.00014071   |   0.00032958   |   0.00076069   |   0.00205445   |
|         | (↓ -0.00000179) | (↓ -0.00000086) | (↓ 0.00000144) | (↓ 0.00000993) | (↓ 0.00003173) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006697   |   0.00022571   |   0.00065071   |   0.00146193   |   0.00339022   |
|         | (↓ 0.00000052) | (↓ 0.00000088) | (↓ 0.00000395) | (↓ 0.00000318) | (↓ 0.00001398) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00010911   |   0.00035003   |   0.00072953   |   0.00138318   |   0.00260630   |
|         | (↓ -0.00000274) | (↓ 0.00000071) | (↓ 0.00000433) | (↓ 0.00001205) | (↓ 0.00004510) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00008339   |    0.00008928   |   0.00035028   |   0.00098787   |   0.00225780   |
|         | (↓ -0.00000047) | (↓ -0.00000063) | (↓ 0.00000480) | (↓ 0.00000623) | (↓ 0.00000721) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004442   |   0.00015332   |   0.00031344   |   0.00054916   |   0.00093541   |
|         | (↓ 0.00000043) | (↓ 0.00000161) | (↓ 0.00000240) | (↓ 0.00000552) | (↓ 0.00001153) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01137481   |   0.02411226   |   0.04230531   |   0.06931521   |   0.10875535   |
|         | (↓ 0.00011605) | (↓ 0.00035677) | (↓ 0.00054720) | (↓ 0.00073481) | (↓ 0.00083348) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:25:36,255 - block_trainer.py[357] - INFO: epoch 7 (133.276227s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020613   |   0.00021048   |   0.00024796   |   0.00045180   |   0.00152372   |
|         | (↓ 0.00000768) | (↓ 0.00000754) | (↓ 0.00000847) | (↓ 0.00000920) | (↓ 0.00002636) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003652   |   0.00005152   |   0.00017587   |   0.00065922   |   0.00222514   |
|         | (↓ 0.00000165) | (↓ 0.00000164) | (↓ 0.00000280) | (↓ 0.00000844) | (↓ 0.00002048) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005523   |   0.00013492   |   0.00032246   |   0.00074683   |   0.00202768   |
|         | (↓ 0.00000542) | (↓ 0.00000578) | (↓ 0.00000711) | (↓ 0.00001386) | (↓ 0.00002677) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-3 |    0.00006713   |    0.00022596   |   0.00064933   |   0.00146059   |   0.00338170   |
|         | (↓ -0.00000015) | (↓ -0.00000025) | (↓ 0.00000138) | (↓ 0.00000134) | (↓ 0.00000852) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010661   |   0.00034394   |   0.00071960   |   0.00136713   |   0.00256964   |
|         | (↓ 0.00000250) | (↓ 0.00000609) | (↓ 0.00000993) | (↓ 0.00001604) | (↓ 0.00003666) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008057   |   0.00008639   |   0.00034495   |   0.00097740   |   0.00224920   |
|         | (↓ 0.00000281) | (↓ 0.00000289) | (↓ 0.00000533) | (↓ 0.00001047) | (↓ 0.00000860) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004386   |   0.00015114   |   0.00031024   |   0.00054326   |   0.00092584   |
|         | (↓ 0.00000056) | (↓ 0.00000219) | (↓ 0.00000320) | (↓ 0.00000590) | (↓ 0.00000957) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01126395   |   0.02377746   |   0.04180143   |   0.06871060   |   0.10790322   |
|         | (↓ 0.00011086) | (↓ 0.00033480) | (↓ 0.00050388) | (↓ 0.00060461) | (↓ 0.00085213) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:27:54,844 - block_trainer.py[357] - INFO: epoch 8 (138.588704s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020394   |   0.00020819   |   0.00024406   |   0.00044710   |   0.00150716   |
|         | (↓ 0.00000218) | (↓ 0.00000229) | (↓ 0.00000391) | (↓ 0.00000470) | (↓ 0.00001656) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003625   |   0.00005110   |   0.00017386   |   0.00065330   |   0.00220993   |
|         | (↓ 0.00000026) | (↓ 0.00000042) | (↓ 0.00000200) | (↓ 0.00000592) | (↓ 0.00001521) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005481   |   0.00013363   |   0.00032008   |   0.00073940   |   0.00201222   |
|         | (↓ 0.00000042) | (↓ 0.00000130) | (↓ 0.00000238) | (↓ 0.00000743) | (↓ 0.00001547) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006297   |   0.00022197   |   0.00064433   |   0.00145543   |   0.00336898   |
|         | (↓ 0.00000416) | (↓ 0.00000399) | (↓ 0.00000500) | (↓ 0.00000516) | (↓ 0.00001272) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010412   |   0.00033829   |   0.00071206   |   0.00135493   |   0.00254305   |
|         | (↓ 0.00000250) | (↓ 0.00000565) | (↓ 0.00000754) | (↓ 0.00001220) | (↓ 0.00002659) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008054   |   0.00008625   |   0.00034312   |   0.00097061   |   0.00224326   |
|         | (↓ 0.00000003) | (↓ 0.00000014) | (↓ 0.00000184) | (↓ 0.00000678) | (↓ 0.00000594) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004276   |   0.00014944   |   0.00030757   |   0.00053883   |   0.00091767   |
|         | (↓ 0.00000110) | (↓ 0.00000170) | (↓ 0.00000267) | (↓ 0.00000443) | (↓ 0.00000817) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01136274   |   0.02368648   |   0.04153661   |   0.06836819   |   0.10744544   |
|         | (↓ -0.00009880) | (↓ 0.00009098) | (↓ 0.00026482) | (↓ 0.00034242) | (↓ 0.00045778) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:30:09,532 - block_trainer.py[357] - INFO: epoch 9 (134.687648s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-0 |    0.00020992   |    0.00021427   |    0.00024896   |    0.00045247   |   0.00150366   |
|         | (↓ -0.00000598) | (↓ -0.00000608) | (↓ -0.00000490) | (↓ -0.00000536) | (↓ 0.00000350) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003791   |    0.00005271   |    0.00017444   |   0.00065039   |   0.00219784   |
|         | (↓ -0.00000165) | (↓ -0.00000161) | (↓ -0.00000058) | (↓ 0.00000292) | (↓ 0.00001209) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005790   |    0.00013607   |    0.00032148   |   0.00073650   |   0.00200326   |
|         | (↓ -0.00000308) | (↓ -0.00000244) | (↓ -0.00000139) | (↓ 0.00000290) | (↓ 0.00000895) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006658   |    0.00022531   |    0.00064504   |    0.00145629   |   0.00336049   |
|         | (↓ -0.00000362) | (↓ -0.00000334) | (↓ -0.00000070) | (↓ -0.00000086) | (↓ 0.00000849) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00010679   |   0.00033775   |   0.00070841   |   0.00134712   |   0.00252453   |
|         | (↓ -0.00000267) | (↓ 0.00000054) | (↓ 0.00000365) | (↓ 0.00000781) | (↓ 0.00001852) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007284   |   0.00007872   |   0.00033575   |   0.00095849   |   0.00223262   |
|         | (↓ 0.00000770) | (↓ 0.00000753) | (↓ 0.00000737) | (↓ 0.00001213) | (↓ 0.00001064) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004255   |   0.00014844   |   0.00030505   |   0.00053457   |   0.00091211   |
|         | (↓ 0.00000021) | (↓ 0.00000099) | (↓ 0.00000252) | (↓ 0.00000426) | (↓ 0.00000556) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01118761   |   0.02343361   |   0.04112702   |   0.06781046   |   0.10695776   |
|         | (↓ 0.00017514) | (↓ 0.00025287) | (↓ 0.00040959) | (↓ 0.00055772) | (↓ 0.00048768) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:32:39,019 - block_trainer.py[357] - INFO: epoch 10 (149.486133s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-0 |    0.00021111   |    0.00021568   |    0.00024898   |   0.00045229   |   0.00149932   |
|         | (↓ -0.00000119) | (↓ -0.00000141) | (↓ -0.00000002) | (↓ 0.00000018) | (↓ 0.00000434) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003716   |   0.00005207   |   0.00017366   |   0.00064780   |   0.00218700   |
|         | (↓ 0.00000074) | (↓ 0.00000064) | (↓ 0.00000078) | (↓ 0.00000259) | (↓ 0.00001084) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005786   |   0.00013539   |   0.00032020   |   0.00073186   |   0.00199521   |
|         | (↓ 0.00000004) | (↓ 0.00000068) | (↓ 0.00000127) | (↓ 0.00000464) | (↓ 0.00000805) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006410   |   0.00022313   |   0.00063949   |   0.00145410   |   0.00335319   |
|         | (↓ 0.00000248) | (↓ 0.00000218) | (↓ 0.00000555) | (↓ 0.00000219) | (↓ 0.00000730) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00010766   |   0.00033694   |   0.00070436   |   0.00134033   |   0.00251237   |
|         | (↓ -0.00000087) | (↓ 0.00000081) | (↓ 0.00000405) | (↓ 0.00000679) | (↓ 0.00001216) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007831   |    0.00008413   |    0.00033997   |    0.00096026   |   0.00223214   |
|         | (↓ -0.00000547) | (↓ -0.00000541) | (↓ -0.00000422) | (↓ -0.00000177) | (↓ 0.00000048) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004307   |    0.00014850   |   0.00030346   |   0.00053250   |   0.00090860   |
|         | (↓ -0.00000053) | (↓ -0.00000005) | (↓ 0.00000159) | (↓ 0.00000208) | (↓ 0.00000351) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01111989   |   0.02331193   |   0.04083764   |   0.06743731   |   0.10658739   |
|         | (↓ 0.00006771) | (↓ 0.00012168) | (↓ 0.00028938) | (↓ 0.00037316) | (↓ 0.00037036) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:34:53,437 - block_trainer.py[357] - INFO: epoch 11 (134.418068s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020994   |   0.00021477   |   0.00024753   |   0.00045141   |   0.00149496   |
|         | (↓ 0.00000117) | (↓ 0.00000091) | (↓ 0.00000145) | (↓ 0.00000088) | (↓ 0.00000436) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003712   |   0.00005188   |   0.00017276   |   0.00064394   |   0.00217675   |
|         | (↓ 0.00000004) | (↓ 0.00000019) | (↓ 0.00000090) | (↓ 0.00000386) | (↓ 0.00001026) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005550   |   0.00013288   |   0.00031689   |   0.00072596   |   0.00198502   |
|         | (↓ 0.00000236) | (↓ 0.00000251) | (↓ 0.00000331) | (↓ 0.00000591) | (↓ 0.00001020) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006325   |   0.00022145   |   0.00063480   |   0.00145179   |   0.00334396   |
|         | (↓ 0.00000085) | (↓ 0.00000169) | (↓ 0.00000469) | (↓ 0.00000231) | (↓ 0.00000923) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010230   |   0.00033100   |   0.00069610   |   0.00132964   |   0.00249493   |
|         | (↓ 0.00000535) | (↓ 0.00000594) | (↓ 0.00000825) | (↓ 0.00001069) | (↓ 0.00001744) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007592   |   0.00008182   |   0.00033738   |   0.00095677   |   0.00222906   |
|         | (↓ 0.00000239) | (↓ 0.00000230) | (↓ 0.00000259) | (↓ 0.00000349) | (↓ 0.00000308) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004103   |   0.00014643   |   0.00029981   |   0.00052867   |   0.00090309   |
|         | (↓ 0.00000204) | (↓ 0.00000207) | (↓ 0.00000365) | (↓ 0.00000383) | (↓ 0.00000551) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01107049   |   0.02319295   |   0.04060086   |   0.06707567   |   0.10612437   |
|         | (↓ 0.00004941) | (↓ 0.00011898) | (↓ 0.00023678) | (↓ 0.00036164) | (↓ 0.00046302) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:37:10,060 - block_trainer.py[357] - INFO: epoch 12 (136.622271s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020675   |   0.00021153   |   0.00024316   |   0.00044679   |   0.00148709   |
|         | (↓ 0.00000319) | (↓ 0.00000324) | (↓ 0.00000437) | (↓ 0.00000462) | (↓ 0.00000787) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003838   |    0.00005327   |    0.00017401   |   0.00064341   |   0.00217212   |
|         | (↓ -0.00000125) | (↓ -0.00000139) | (↓ -0.00000126) | (↓ 0.00000053) | (↓ 0.00000463) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005977   |    0.00013661   |    0.00031955   |   0.00072590   |   0.00198181   |
|         | (↓ -0.00000427) | (↓ -0.00000373) | (↓ -0.00000266) | (↓ 0.00000005) | (↓ 0.00000321) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006227   |   0.00022085   |   0.00063336   |   0.00145011   |   0.00334023   |
|         | (↓ 0.00000098) | (↓ 0.00000060) | (↓ 0.00000144) | (↓ 0.00000169) | (↓ 0.00000373) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00010537   |    0.00033199   |   0.00069456   |   0.00132582   |   0.00248622   |
|         | (↓ -0.00000306) | (↓ -0.00000099) | (↓ 0.00000155) | (↓ 0.00000382) | (↓ 0.00000871) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00008213   |    0.00008801   |    0.00034395   |    0.00096328   |    0.00223236   |
|         | (↓ -0.00000621) | (↓ -0.00000618) | (↓ -0.00000657) | (↓ -0.00000651) | (↓ -0.00000330) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004205   |    0.00014684   |   0.00029908   |   0.00052750   |   0.00090151   |
|         | (↓ -0.00000102) | (↓ -0.00000041) | (↓ 0.00000073) | (↓ 0.00000116) | (↓ 0.00000158) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01107461   |   0.02315289   |   0.04044590   |   0.06682040   |   0.10587284   |
|         | (↓ -0.00000412) | (↓ 0.00004006) | (↓ 0.00015495) | (↓ 0.00025527) | (↓ 0.00025154) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:39:24,723 - block_trainer.py[357] - INFO: epoch 13 (134.662554s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020112   |   0.00020594   |   0.00023703   |   0.00044083   |   0.00147754   |
|         | (↓ 0.00000563) | (↓ 0.00000559) | (↓ 0.00000613) | (↓ 0.00000597) | (↓ 0.00000955) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003553   |   0.00005045   |   0.00017063   |   0.00063773   |   0.00216460   |
|         | (↓ 0.00000285) | (↓ 0.00000282) | (↓ 0.00000338) | (↓ 0.00000567) | (↓ 0.00000751) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005630   |   0.00013312   |   0.00031590   |   0.00072077   |   0.00197518   |
|         | (↓ 0.00000347) | (↓ 0.00000348) | (↓ 0.00000365) | (↓ 0.00000514) | (↓ 0.00000662) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006501   |    0.00022362   |    0.00063555   |    0.00145214   |   0.00334017   |
|         | (↓ -0.00000274) | (↓ -0.00000277) | (↓ -0.00000219) | (↓ -0.00000204) | (↓ 0.00000006) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00011078   |    0.00033622   |    0.00069693   |   0.00132529   |   0.00248256   |
|         | (↓ -0.00000542) | (↓ -0.00000423) | (↓ -0.00000237) | (↓ 0.00000053) | (↓ 0.00000366) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008102   |   0.00008691   |   0.00034228   |   0.00096024   |   0.00222768   |
|         | (↓ 0.00000111) | (↓ 0.00000109) | (↓ 0.00000166) | (↓ 0.00000304) | (↓ 0.00000469) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00004244   |   0.00014588   |   0.00029804   |   0.00052636   |   0.00090014   |
|         | (↓ -0.00000039) | (↓ 0.00000096) | (↓ 0.00000104) | (↓ 0.00000114) | (↓ 0.00000137) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01095988   |   0.02301083   |   0.04023864   |   0.06645896   |   0.10561494   |
|         | (↓ 0.00011472) | (↓ 0.00014206) | (↓ 0.00020727) | (↓ 0.00036144) | (↓ 0.00025789) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:42:35,603 - block_trainer.py[357] - INFO: epoch 14 (190.879456s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019993   |   0.00020473   |   0.00023486   |   0.00043856   |   0.00147133   |
|         | (↓ 0.00000119) | (↓ 0.00000121) | (↓ 0.00000217) | (↓ 0.00000226) | (↓ 0.00000620) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003664   |    0.00005144   |    0.00017130   |   0.00063717   |   0.00216185   |
|         | (↓ -0.00000111) | (↓ -0.00000099) | (↓ -0.00000067) | (↓ 0.00000056) | (↓ 0.00000275) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-2 |    0.00005754   |    0.00013377   |   0.00031550   |   0.00071872   |   0.00197147   |
|         | (↓ -0.00000124) | (↓ -0.00000065) | (↓ 0.00000040) | (↓ 0.00000204) | (↓ 0.00000372) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006438   |   0.00022261   |   0.00063451   |   0.00145065   |   0.00333641   |
|         | (↓ 0.00000063) | (↓ 0.00000101) | (↓ 0.00000104) | (↓ 0.00000150) | (↓ 0.00000375) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010734   |   0.00033104   |   0.00069125   |   0.00131795   |   0.00247167   |
|         | (↓ 0.00000344) | (↓ 0.00000518) | (↓ 0.00000568) | (↓ 0.00000734) | (↓ 0.00001089) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007673   |   0.00008256   |   0.00033685   |   0.00095492   |   0.00222265   |
|         | (↓ 0.00000430) | (↓ 0.00000435) | (↓ 0.00000543) | (↓ 0.00000532) | (↓ 0.00000503) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00004256   |   0.00014471   |   0.00029648   |   0.00052395   |   0.00089712   |
|         | (↓ -0.00000011) | (↓ 0.00000117) | (↓ 0.00000156) | (↓ 0.00000241) | (↓ 0.00000302) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01091276   |   0.02290934   |   0.04007936   |   0.06617083   |   0.10509894   |
|         | (↓ 0.00004713) | (↓ 0.00010149) | (↓ 0.00015928) | (↓ 0.00028812) | (↓ 0.00051600) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:45:57,420 - block_trainer.py[357] - INFO: epoch 15 (201.816709s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00021279   |    0.00021830   |    0.00024828   |    0.00045227   |    0.00148683   |
|         | (↓ -0.00001287) | (↓ -0.00001357) | (↓ -0.00001342) | (↓ -0.00001371) | (↓ -0.00001550) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003578   |   0.00005064   |   0.00017032   |   0.00063334   |   0.00215831   |
|         | (↓ 0.00000086) | (↓ 0.00000080) | (↓ 0.00000098) | (↓ 0.00000384) | (↓ 0.00000355) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005431   |   0.00013102   |   0.00031284   |   0.00071539   |   0.00196713   |
|         | (↓ 0.00000323) | (↓ 0.00000275) | (↓ 0.00000266) | (↓ 0.00000334) | (↓ 0.00000433) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006299   |   0.00022149   |   0.00063337   |   0.00144950   |   0.00333489   |
|         | (↓ 0.00000139) | (↓ 0.00000112) | (↓ 0.00000113) | (↓ 0.00000115) | (↓ 0.00000152) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010181   |   0.00032542   |   0.00068575   |   0.00131103   |   0.00246286   |
|         | (↓ 0.00000553) | (↓ 0.00000562) | (↓ 0.00000550) | (↓ 0.00000692) | (↓ 0.00000882) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00007594   |   0.00008179   |    0.00033719   |    0.00095526   |    0.00222356   |
|         | (↓ 0.00000078) | (↓ 0.00000077) | (↓ -0.00000034) | (↓ -0.00000034) | (↓ -0.00000090) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004103   |   0.00014222   |   0.00029411   |   0.00052112   |   0.00089424   |
|         | (↓ 0.00000153) | (↓ 0.00000248) | (↓ 0.00000237) | (↓ 0.00000283) | (↓ 0.00000288) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
| block-7 |    0.01092705   |    0.02291709   |   0.03998701   |   0.06604885   |    0.10510466   |
|         | (↓ -0.00001430) | (↓ -0.00000775) | (↓ 0.00009235) | (↓ 0.00012198) | (↓ -0.00000572) |
+---------+-----------------+-----------------+----------------+----------------+-----------------+

2024-10-15 00:49:20,303 - block_trainer.py[357] - INFO: epoch 16 (202.882433s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020931   |   0.00021469   |   0.00024429   |   0.00044822   |   0.00148012   |
|         | (↓ 0.00000348) | (↓ 0.00000361) | (↓ 0.00000398) | (↓ 0.00000405) | (↓ 0.00000671) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003722   |    0.00005196   |    0.00017149   |   0.00063220   |   0.00215798   |
|         | (↓ -0.00000144) | (↓ -0.00000132) | (↓ -0.00000117) | (↓ 0.00000114) | (↓ 0.00000032) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00006067   |    0.00013676   |    0.00031734   |    0.00071781   |   0.00196678   |
|         | (↓ -0.00000636) | (↓ -0.00000574) | (↓ -0.00000450) | (↓ -0.00000243) | (↓ 0.00000035) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00006378   |    0.00022232   |    0.00063386   |   0.00144857   |   0.00333376   |
|         | (↓ -0.00000079) | (↓ -0.00000083) | (↓ -0.00000048) | (↓ 0.00000093) | (↓ 0.00000113) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00010697   |    0.00032930   |    0.00068903   |   0.00131096   |   0.00246135   |
|         | (↓ -0.00000516) | (↓ -0.00000388) | (↓ -0.00000328) | (↓ 0.00000008) | (↓ 0.00000151) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00008150   |    0.00008732   |    0.00034179   |    0.00095750   |    0.00222596   |
|         | (↓ -0.00000556) | (↓ -0.00000553) | (↓ -0.00000460) | (↓ -0.00000225) | (↓ -0.00000240) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00004330   |    0.00014352   |    0.00029499   |    0.00052139   |    0.00089460   |
|         | (↓ -0.00000227) | (↓ -0.00000130) | (↓ -0.00000088) | (↓ -0.00000027) | (↓ -0.00000036) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01092701   |   0.02287115   |   0.03990958   |   0.06585744   |   0.10474434   |
|         | (↓ 0.00000004) | (↓ 0.00004593) | (↓ 0.00007743) | (↓ 0.00019141) | (↓ 0.00036032) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:52:34,279 - block_trainer.py[357] - INFO: epoch 17 (193.974951s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020152   |   0.00020700   |   0.00023652   |   0.00044008   |   0.00147068   |
|         | (↓ 0.00000779) | (↓ 0.00000770) | (↓ 0.00000777) | (↓ 0.00000814) | (↓ 0.00000944) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003701   |   0.00005180   |   0.00017110   |   0.00062959   |   0.00215581   |
|         | (↓ 0.00000021) | (↓ 0.00000016) | (↓ 0.00000040) | (↓ 0.00000261) | (↓ 0.00000217) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005487   |   0.00013113   |   0.00031167   |   0.00071138   |   0.00195938   |
|         | (↓ 0.00000580) | (↓ 0.00000563) | (↓ 0.00000567) | (↓ 0.00000644) | (↓ 0.00000740) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006551   |    0.00022378   |    0.00063545   |    0.00144980   |    0.00333559   |
|         | (↓ -0.00000173) | (↓ -0.00000146) | (↓ -0.00000159) | (↓ -0.00000123) | (↓ -0.00000183) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010657   |   0.00032816   |   0.00068746   |   0.00130777   |   0.00245689   |
|         | (↓ 0.00000040) | (↓ 0.00000114) | (↓ 0.00000157) | (↓ 0.00000318) | (↓ 0.00000446) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00008016   |   0.00008608   |   0.00033973   |   0.00095343   |   0.00222103   |
|         | (↓ 0.00000134) | (↓ 0.00000124) | (↓ 0.00000206) | (↓ 0.00000407) | (↓ 0.00000493) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004169   |   0.00014199   |   0.00029333   |   0.00051974   |   0.00089259   |
|         | (↓ 0.00000160) | (↓ 0.00000153) | (↓ 0.00000166) | (↓ 0.00000165) | (↓ 0.00000201) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01089837   |   0.02279912   |   0.03982344   |   0.06572057   |   0.10464842   |
|         | (↓ 0.00002864) | (↓ 0.00007203) | (↓ 0.00008614) | (↓ 0.00013687) | (↓ 0.00009593) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:55:57,708 - block_trainer.py[357] - INFO: epoch 18 (203.429152s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00021407   |    0.00021948   |    0.00024855   |    0.00045187   |    0.00148291   |
|         | (↓ -0.00001254) | (↓ -0.00001249) | (↓ -0.00001203) | (↓ -0.00001179) | (↓ -0.00001223) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003766   |    0.00005230   |    0.00017119   |   0.00062796   |   0.00215353   |
|         | (↓ -0.00000065) | (↓ -0.00000050) | (↓ -0.00000009) | (↓ 0.00000163) | (↓ 0.00000228) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005398   |   0.00013026   |   0.00031035   |   0.00070935   |   0.00195652   |
|         | (↓ 0.00000090) | (↓ 0.00000087) | (↓ 0.00000132) | (↓ 0.00000203) | (↓ 0.00000286) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006401   |   0.00022249   |   0.00063420   |   0.00144833   |   0.00333406   |
|         | (↓ 0.00000150) | (↓ 0.00000129) | (↓ 0.00000126) | (↓ 0.00000147) | (↓ 0.00000153) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010646   |   0.00032773   |   0.00068677   |   0.00130523   |   0.00245456   |
|         | (↓ 0.00000011) | (↓ 0.00000043) | (↓ 0.00000069) | (↓ 0.00000254) | (↓ 0.00000233) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-5 |   0.00007830   |   0.00008413   |   0.00033864   |   0.00095102   |    0.00222143   |
|         | (↓ 0.00000186) | (↓ 0.00000195) | (↓ 0.00000108) | (↓ 0.00000241) | (↓ -0.00000040) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004087   |   0.00014104   |   0.00029192   |   0.00051837   |   0.00089148   |
|         | (↓ 0.00000083) | (↓ 0.00000095) | (↓ 0.00000142) | (↓ 0.00000137) | (↓ 0.00000112) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01083949   |   0.02270667   |   0.03975228   |   0.06556022   |   0.10447358   |
|         | (↓ 0.00005888) | (↓ 0.00009245) | (↓ 0.00007116) | (↓ 0.00016035) | (↓ 0.00017483) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 00:59:19,737 - block_trainer.py[357] - INFO: epoch 19 (202.028350s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019974   |   0.00020566   |   0.00023508   |   0.00043793   |   0.00146506   |
|         | (↓ 0.00001433) | (↓ 0.00001382) | (↓ 0.00001346) | (↓ 0.00001394) | (↓ 0.00001785) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003575   |   0.00005043   |   0.00016931   |   0.00062473   |   0.00214893   |
|         | (↓ 0.00000191) | (↓ 0.00000187) | (↓ 0.00000188) | (↓ 0.00000323) | (↓ 0.00000460) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-2 |    0.00005476   |    0.00013062   |   0.00030999   |   0.00070763   |   0.00195313   |
|         | (↓ -0.00000078) | (↓ -0.00000037) | (↓ 0.00000036) | (↓ 0.00000172) | (↓ 0.00000339) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006159   |   0.00021957   |   0.00063108   |   0.00144362   |   0.00332987   |
|         | (↓ 0.00000243) | (↓ 0.00000292) | (↓ 0.00000312) | (↓ 0.00000472) | (↓ 0.00000419) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010429   |   0.00032470   |   0.00068370   |   0.00129989   |   0.00244798   |
|         | (↓ 0.00000217) | (↓ 0.00000303) | (↓ 0.00000306) | (↓ 0.00000534) | (↓ 0.00000658) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007909   |    0.00008499   |    0.00033889   |   0.00094889   |   0.00221866   |
|         | (↓ -0.00000079) | (↓ -0.00000086) | (↓ -0.00000024) | (↓ 0.00000213) | (↓ 0.00000277) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004153   |    0.00014120   |   0.00029108   |   0.00051681   |   0.00088998   |
|         | (↓ -0.00000067) | (↓ -0.00000016) | (↓ 0.00000084) | (↓ 0.00000156) | (↓ 0.00000150) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01077604   |   0.02257287   |   0.03963807   |   0.06538900   |   0.10429127   |
|         | (↓ 0.00006345) | (↓ 0.00013379) | (↓ 0.00011422) | (↓ 0.00017122) | (↓ 0.00018231) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:02:34,197 - block_trainer.py[357] - INFO: epoch 20 (194.460104s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020353   |    0.00020934   |    0.00023846   |    0.00044125   |    0.00146885   |
|         | (↓ -0.00000379) | (↓ -0.00000368) | (↓ -0.00000338) | (↓ -0.00000332) | (↓ -0.00000380) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003550   |   0.00005017   |   0.00016881   |   0.00062246   |   0.00214855   |
|         | (↓ 0.00000025) | (↓ 0.00000026) | (↓ 0.00000050) | (↓ 0.00000227) | (↓ 0.00000038) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00005592   |    0.00013200   |    0.00031119   |    0.00070834   |   0.00195282   |
|         | (↓ -0.00000116) | (↓ -0.00000137) | (↓ -0.00000119) | (↓ -0.00000071) | (↓ 0.00000032) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006190   |    0.00022026   |    0.00063211   |    0.00144377   |    0.00333226   |
|         | (↓ -0.00000031) | (↓ -0.00000070) | (↓ -0.00000104) | (↓ -0.00000015) | (↓ -0.00000240) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009973   |   0.00032076   |   0.00068033   |   0.00129524   |   0.00244376   |
|         | (↓ 0.00000456) | (↓ 0.00000394) | (↓ 0.00000337) | (↓ 0.00000464) | (↓ 0.00000422) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-5 |   0.00007749   |   0.00008336   |   0.00033837   |   0.00094639   |    0.00221965   |
|         | (↓ 0.00000159) | (↓ 0.00000163) | (↓ 0.00000052) | (↓ 0.00000251) | (↓ -0.00000099) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004082   |   0.00014038   |   0.00028995   |   0.00051535   |   0.00088787   |
|         | (↓ 0.00000072) | (↓ 0.00000082) | (↓ 0.00000113) | (↓ 0.00000146) | (↓ 0.00000211) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01074690   |   0.02244467   |   0.03952797   |   0.06517452   |   0.10398801   |
|         | (↓ 0.00002914) | (↓ 0.00012820) | (↓ 0.00011010) | (↓ 0.00021448) | (↓ 0.00030326) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:05:44,350 - block_trainer.py[357] - INFO: epoch 21 (190.152257s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019535   |   0.00020106   |   0.00023014   |   0.00043320   |   0.00145891   |
|         | (↓ 0.00000819) | (↓ 0.00000829) | (↓ 0.00000832) | (↓ 0.00000804) | (↓ 0.00000995) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003626   |    0.00005075   |    0.00016944   |   0.00062221   |   0.00214842   |
|         | (↓ -0.00000077) | (↓ -0.00000057) | (↓ -0.00000063) | (↓ 0.00000026) | (↓ 0.00000013) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00005755   |    0.00013344   |    0.00031211   |    0.00070840   |   0.00195257   |
|         | (↓ -0.00000163) | (↓ -0.00000145) | (↓ -0.00000093) | (↓ -0.00000006) | (↓ 0.00000024) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-3 |    0.00006193   |    0.00022033   |   0.00063194   |   0.00144213   |   0.00333023   |
|         | (↓ -0.00000003) | (↓ -0.00000006) | (↓ 0.00000017) | (↓ 0.00000163) | (↓ 0.00000204) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-4 |    0.00010478   |    0.00032489   |    0.00068324   |    0.00129614   |   0.00244369   |
|         | (↓ -0.00000505) | (↓ -0.00000413) | (↓ -0.00000291) | (↓ -0.00000090) | (↓ 0.00000007) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007968   |    0.00008557   |    0.00033939   |   0.00094222   |   0.00221864   |
|         | (↓ -0.00000218) | (↓ -0.00000220) | (↓ -0.00000103) | (↓ 0.00000417) | (↓ 0.00000101) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00004044   |   0.00014013   |   0.00028955   |   0.00051503   |   0.00088755   |
|         | (↓ 0.00000038) | (↓ 0.00000025) | (↓ 0.00000039) | (↓ 0.00000032) | (↓ 0.00000032) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01065412   |   0.02227238   |   0.03939632   |   0.06499298   |   0.10379968   |
|         | (↓ 0.00009279) | (↓ 0.00017229) | (↓ 0.00013164) | (↓ 0.00018154) | (↓ 0.00018833) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:09:29,341 - block_trainer.py[357] - INFO: epoch 22 (224.990649s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00021566   |    0.00022235   |    0.00025133   |    0.00045467   |    0.00147973   |
|         | (↓ -0.00002031) | (↓ -0.00002130) | (↓ -0.00002119) | (↓ -0.00002147) | (↓ -0.00002082) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003571   |   0.00005030   |   0.00016908   |   0.00061928   |   0.00214566   |
|         | (↓ 0.00000056) | (↓ 0.00000045) | (↓ 0.00000036) | (↓ 0.00000293) | (↓ 0.00000277) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005369   |   0.00012962   |   0.00030836   |   0.00070407   |   0.00194744   |
|         | (↓ 0.00000386) | (↓ 0.00000383) | (↓ 0.00000376) | (↓ 0.00000433) | (↓ 0.00000513) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006450   |    0.00022261   |    0.00063409   |    0.00144335   |    0.00333138   |
|         | (↓ -0.00000257) | (↓ -0.00000228) | (↓ -0.00000215) | (↓ -0.00000122) | (↓ -0.00000115) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010421   |   0.00032395   |   0.00068222   |   0.00129375   |   0.00244117   |
|         | (↓ 0.00000057) | (↓ 0.00000094) | (↓ 0.00000103) | (↓ 0.00000239) | (↓ 0.00000252) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007827   |   0.00008419   |   0.00033798   |   0.00093862   |   0.00221778   |
|         | (↓ 0.00000140) | (↓ 0.00000138) | (↓ 0.00000141) | (↓ 0.00000360) | (↓ 0.00000085) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00004096   |    0.00014036   |   0.00028894   |   0.00051385   |   0.00088666   |
|         | (↓ -0.00000052) | (↓ -0.00000023) | (↓ 0.00000062) | (↓ 0.00000117) | (↓ 0.00000089) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01074567   |   0.02225358   |   0.03935301   |   0.06484415   |   0.10366663   |
|         | (↓ -0.00009155) | (↓ 0.00001881) | (↓ 0.00004332) | (↓ 0.00014883) | (↓ 0.00013304) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:13:18,360 - block_trainer.py[357] - INFO: epoch 23 (229.018857s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020808   |   0.00021531   |   0.00024465   |   0.00044703   |   0.00147156   |
|         | (↓ 0.00000757) | (↓ 0.00000704) | (↓ 0.00000668) | (↓ 0.00000764) | (↓ 0.00000817) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003498   |   0.00004915   |   0.00016824   |   0.00061008   |   0.00214364   |
|         | (↓ 0.00000073) | (↓ 0.00000114) | (↓ 0.00000084) | (↓ 0.00000920) | (↓ 0.00000201) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-2 |    0.00005501   |    0.00013085   |    0.00030932   |    0.00070421   |   0.00194704   |
|         | (↓ -0.00000132) | (↓ -0.00000124) | (↓ -0.00000096) | (↓ -0.00000014) | (↓ 0.00000040) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005954   |   0.00021781   |   0.00062969   |   0.00143820   |   0.00332770   |
|         | (↓ 0.00000496) | (↓ 0.00000480) | (↓ 0.00000440) | (↓ 0.00000516) | (↓ 0.00000368) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010125   |   0.00032089   |   0.00067936   |   0.00128964   |   0.00243769   |
|         | (↓ 0.00000296) | (↓ 0.00000306) | (↓ 0.00000286) | (↓ 0.00000411) | (↓ 0.00000348) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007529   |   0.00008115   |   0.00033506   |   0.00093209   |   0.00221488   |
|         | (↓ 0.00000298) | (↓ 0.00000304) | (↓ 0.00000293) | (↓ 0.00000653) | (↓ 0.00000291) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003967   |   0.00013921   |   0.00028785   |   0.00051248   |   0.00088486   |
|         | (↓ 0.00000130) | (↓ 0.00000115) | (↓ 0.00000108) | (↓ 0.00000137) | (↓ 0.00000180) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01065935   |   0.02212769   |   0.03922770   |   0.06470459   |   0.10347909   |
|         | (↓ 0.00008632) | (↓ 0.00012589) | (↓ 0.00012530) | (↓ 0.00013956) | (↓ 0.00018755) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:17:06,873 - block_trainer.py[357] - INFO: epoch 24 (228.511913s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020293   |   0.00020938   |   0.00023830   |   0.00044090   |   0.00146355   |
|         | (↓ 0.00000515) | (↓ 0.00000593) | (↓ 0.00000634) | (↓ 0.00000613) | (↓ 0.00000801) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+-----------------+----------------+----------------+
|         |       0.0       |      0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+-----------------+----------------+----------------+
| block-1 |    0.00003571   |   0.00004817   |    0.00016857   |   0.00060412   |   0.00214169   |
|         | (↓ -0.00000072) | (↓ 0.00000098) | (↓ -0.00000033) | (↓ 0.00000596) | (↓ 0.00000196) |
+---------+-----------------+----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005593   |    0.00013187   |    0.00031013   |    0.00070469   |    0.00194754   |
|         | (↓ -0.00000092) | (↓ -0.00000102) | (↓ -0.00000081) | (↓ -0.00000048) | (↓ -0.00000050) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-3 |    0.00006015   |    0.00021836   |    0.00063020   |   0.00143780   |   0.00332741   |
|         | (↓ -0.00000061) | (↓ -0.00000055) | (↓ -0.00000051) | (↓ 0.00000040) | (↓ 0.00000029) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-4 |    0.00010159   |    0.00032097   |   0.00067889   |   0.00128803   |   0.00243557   |
|         | (↓ -0.00000034) | (↓ -0.00000008) | (↓ 0.00000047) | (↓ 0.00000161) | (↓ 0.00000212) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007357   |   0.00007949   |   0.00033386   |   0.00092931   |   0.00221247   |
|         | (↓ 0.00000172) | (↓ 0.00000166) | (↓ 0.00000120) | (↓ 0.00000278) | (↓ 0.00000241) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00003976   |   0.00013905   |   0.00028693   |   0.00051175   |   0.00088365   |
|         | (↓ -0.00000009) | (↓ 0.00000016) | (↓ 0.00000092) | (↓ 0.00000073) | (↓ 0.00000121) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01066573   |   0.02208091   |   0.03920177   |   0.06455494   |   0.10336153   |
|         | (↓ -0.00000639) | (↓ 0.00004678) | (↓ 0.00002593) | (↓ 0.00014965) | (↓ 0.00011756) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:20:57,109 - block_trainer.py[357] - INFO: epoch 25 (230.235582s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020880   |    0.00021625   |    0.00024502   |    0.00044758   |    0.00146887   |
|         | (↓ -0.00000586) | (↓ -0.00000687) | (↓ -0.00000671) | (↓ -0.00000669) | (↓ -0.00000532) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003449   |   0.00004605   |   0.00016729   |   0.00059903   |   0.00214004   |
|         | (↓ 0.00000121) | (↓ 0.00000212) | (↓ 0.00000128) | (↓ 0.00000509) | (↓ 0.00000164) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005435   |   0.00013016   |   0.00030825   |   0.00070230   |   0.00194430   |
|         | (↓ 0.00000158) | (↓ 0.00000171) | (↓ 0.00000188) | (↓ 0.00000239) | (↓ 0.00000324) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006119   |    0.00021933   |    0.00063111   |    0.00143847   |    0.00332915   |
|         | (↓ -0.00000103) | (↓ -0.00000097) | (↓ -0.00000091) | (↓ -0.00000068) | (↓ -0.00000173) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010074   |   0.00032023   |   0.00067817   |   0.00128574   |   0.00243356   |
|         | (↓ 0.00000085) | (↓ 0.00000075) | (↓ 0.00000072) | (↓ 0.00000230) | (↓ 0.00000200) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007770   |    0.00008362   |    0.00033774   |    0.00093185   |    0.00221626   |
|         | (↓ -0.00000413) | (↓ -0.00000413) | (↓ -0.00000389) | (↓ -0.00000254) | (↓ -0.00000380) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003923   |   0.00013865   |   0.00028633   |   0.00051084   |   0.00088196   |
|         | (↓ 0.00000053) | (↓ 0.00000040) | (↓ 0.00000060) | (↓ 0.00000091) | (↓ 0.00000169) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01063165   |   0.02202720   |   0.03912494   |   0.06451939   |   0.10323896   |
|         | (↓ 0.00003409) | (↓ 0.00005370) | (↓ 0.00007684) | (↓ 0.00003554) | (↓ 0.00012257) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:24:44,238 - block_trainer.py[357] - INFO: epoch 26 (227.128707s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020236   |   0.00020973   |   0.00023886   |   0.00044112   |   0.00146064   |
|         | (↓ 0.00000643) | (↓ 0.00000652) | (↓ 0.00000616) | (↓ 0.00000647) | (↓ 0.00000823) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-1 |    0.00003539   |    0.00004629   |    0.00016843   |   0.00059807   |    0.00214009   |
|         | (↓ -0.00000090) | (↓ -0.00000024) | (↓ -0.00000114) | (↓ 0.00000096) | (↓ -0.00000004) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005532   |    0.00013095   |    0.00030882   |   0.00070223   |   0.00194387   |
|         | (↓ -0.00000097) | (↓ -0.00000079) | (↓ -0.00000057) | (↓ 0.00000007) | (↓ 0.00000043) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006312   |    0.00022125   |    0.00063317   |    0.00144067   |    0.00333017   |
|         | (↓ -0.00000193) | (↓ -0.00000192) | (↓ -0.00000207) | (↓ -0.00000220) | (↓ -0.00000103) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00010397   |    0.00032245   |    0.00067926   |   0.00128565   |   0.00243334   |
|         | (↓ -0.00000323) | (↓ -0.00000222) | (↓ -0.00000110) | (↓ 0.00000008) | (↓ 0.00000023) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007869   |    0.00008460   |    0.00033811   |    0.00093187   |   0.00221570   |
|         | (↓ -0.00000099) | (↓ -0.00000098) | (↓ -0.00000036) | (↓ -0.00000002) | (↓ 0.00000056) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00004036   |    0.00013998   |    0.00028705   |    0.00051189   |    0.00088433   |
|         | (↓ -0.00000113) | (↓ -0.00000133) | (↓ -0.00000072) | (↓ -0.00000105) | (↓ -0.00000237) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01054910   |   0.02191996   |   0.03902815   |   0.06431031   |   0.10303288   |
|         | (↓ 0.00008254) | (↓ 0.00010724) | (↓ 0.00009679) | (↓ 0.00020908) | (↓ 0.00020607) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:28:32,513 - block_trainer.py[357] - INFO: epoch 27 (228.274821s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020692   |    0.00021440   |    0.00024341   |    0.00044552   |    0.00146519   |
|         | (↓ -0.00000456) | (↓ -0.00000467) | (↓ -0.00000455) | (↓ -0.00000440) | (↓ -0.00000455) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003528   |   0.00004565   |   0.00016790   |   0.00059626   |   0.00213741   |
|         | (↓ 0.00000012) | (↓ 0.00000064) | (↓ 0.00000053) | (↓ 0.00000181) | (↓ 0.00000268) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005625   |    0.00013153   |    0.00030886   |   0.00070169   |   0.00194268   |
|         | (↓ -0.00000092) | (↓ -0.00000058) | (↓ -0.00000003) | (↓ 0.00000054) | (↓ 0.00000119) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006199   |   0.00022024   |   0.00063228   |   0.00143911   |   0.00332782   |
|         | (↓ 0.00000113) | (↓ 0.00000101) | (↓ 0.00000089) | (↓ 0.00000156) | (↓ 0.00000236) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010158   |   0.00032029   |   0.00067746   |   0.00128422   |   0.00243103   |
|         | (↓ 0.00000239) | (↓ 0.00000216) | (↓ 0.00000181) | (↓ 0.00000143) | (↓ 0.00000231) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007605   |   0.00008189   |   0.00033554   |   0.00092842   |   0.00221280   |
|         | (↓ 0.00000264) | (↓ 0.00000270) | (↓ 0.00000257) | (↓ 0.00000345) | (↓ 0.00000290) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003905   |   0.00013792   |   0.00028456   |   0.00050919   |   0.00088052   |
|         | (↓ 0.00000131) | (↓ 0.00000206) | (↓ 0.00000250) | (↓ 0.00000270) | (↓ 0.00000381) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01056522   |   0.02190750   |   0.03897850   |   0.06426255   |   0.10300204   |
|         | (↓ -0.00001612) | (↓ 0.00001246) | (↓ 0.00004965) | (↓ 0.00004776) | (↓ 0.00003084) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:32:23,583 - block_trainer.py[357] - INFO: epoch 28 (231.069476s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020811   |    0.00021623   |    0.00024533   |    0.00044674   |    0.00146722   |
|         | (↓ -0.00000118) | (↓ -0.00000183) | (↓ -0.00000192) | (↓ -0.00000122) | (↓ -0.00000202) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00003629   |    0.00004650   |    0.00016887   |    0.00059630   |   0.00213697   |
|         | (↓ -0.00000101) | (↓ -0.00000085) | (↓ -0.00000097) | (↓ -0.00000004) | (↓ 0.00000043) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005310   |   0.00012874   |   0.00030664   |   0.00069927   |   0.00194033   |
|         | (↓ 0.00000315) | (↓ 0.00000279) | (↓ 0.00000221) | (↓ 0.00000242) | (↓ 0.00000235) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006100   |   0.00021893   |   0.00063049   |   0.00143715   |   0.00332532   |
|         | (↓ 0.00000100) | (↓ 0.00000131) | (↓ 0.00000179) | (↓ 0.00000196) | (↓ 0.00000250) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010061   |   0.00031883   |   0.00067485   |   0.00128059   |   0.00242669   |
|         | (↓ 0.00000097) | (↓ 0.00000146) | (↓ 0.00000261) | (↓ 0.00000363) | (↓ 0.00000434) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007673   |    0.00008260   |    0.00033596   |   0.00092794   |   0.00221170   |
|         | (↓ -0.00000068) | (↓ -0.00000071) | (↓ -0.00000042) | (↓ 0.00000048) | (↓ 0.00000109) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+-----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+----------------+----------------+-----------------+----------------+
| block-6 |    0.00003924   |   0.00013780   |   0.00028435   |    0.00050926   |   0.00088051   |
|         | (↓ -0.00000020) | (↓ 0.00000012) | (↓ 0.00000021) | (↓ -0.00000007) | (↓ 0.00000000) |
+---------+-----------------+----------------+----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01052945   |   0.02184350   |   0.03888213   |   0.06406106   |   0.10275859   |
|         | (↓ 0.00003577) | (↓ 0.00006401) | (↓ 0.00009637) | (↓ 0.00020149) | (↓ 0.00024346) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:36:13,601 - block_trainer.py[357] - INFO: epoch 29 (230.017590s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020553   |   0.00021283   |   0.00024151   |   0.00044310   |   0.00145849   |
|         | (↓ 0.00000258) | (↓ 0.00000340) | (↓ 0.00000382) | (↓ 0.00000365) | (↓ 0.00000873) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003600   |   0.00004611   |   0.00016855   |   0.00059475   |   0.00213429   |
|         | (↓ 0.00000028) | (↓ 0.00000039) | (↓ 0.00000033) | (↓ 0.00000155) | (↓ 0.00000268) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005537   |    0.00013072   |    0.00030815   |    0.00069997   |    0.00194055   |
|         | (↓ -0.00000227) | (↓ -0.00000198) | (↓ -0.00000151) | (↓ -0.00000069) | (↓ -0.00000022) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006016   |   0.00021798   |   0.00062987   |   0.00143646   |   0.00332521   |
|         | (↓ 0.00000084) | (↓ 0.00000095) | (↓ 0.00000062) | (↓ 0.00000069) | (↓ 0.00000010) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009825   |   0.00031675   |   0.00067306   |   0.00127870   |   0.00242463   |
|         | (↓ 0.00000236) | (↓ 0.00000208) | (↓ 0.00000179) | (↓ 0.00000189) | (↓ 0.00000206) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-5 |   0.00007584   |   0.00008170   |   0.00033490   |   0.00092729   |    0.00221280   |
|         | (↓ 0.00000089) | (↓ 0.00000090) | (↓ 0.00000106) | (↓ 0.00000065) | (↓ -0.00000109) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00003993   |   0.00013761   |   0.00028337   |   0.00050795   |   0.00087896   |
|         | (↓ -0.00000069) | (↓ 0.00000019) | (↓ 0.00000098) | (↓ 0.00000131) | (↓ 0.00000156) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01050725   |   0.02178765   |   0.03882698   |   0.06399114   |   0.10262130   |
|         | (↓ 0.00002220) | (↓ 0.00005584) | (↓ 0.00005515) | (↓ 0.00006992) | (↓ 0.00013729) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:40:01,507 - block_trainer.py[357] - INFO: epoch 30 (227.905263s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020195   |   0.00020938   |   0.00023837   |   0.00044017   |   0.00145734   |
|         | (↓ 0.00000358) | (↓ 0.00000345) | (↓ 0.00000314) | (↓ 0.00000293) | (↓ 0.00000115) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003577   |   0.00004580   |   0.00016795   |   0.00059367   |   0.00213376   |
|         | (↓ 0.00000023) | (↓ 0.00000031) | (↓ 0.00000060) | (↓ 0.00000108) | (↓ 0.00000053) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005228   |   0.00012773   |   0.00030538   |   0.00069725   |   0.00193869   |
|         | (↓ 0.00000309) | (↓ 0.00000299) | (↓ 0.00000277) | (↓ 0.00000272) | (↓ 0.00000186) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006188   |    0.00021974   |    0.00063133   |    0.00143754   |    0.00332546   |
|         | (↓ -0.00000172) | (↓ -0.00000176) | (↓ -0.00000146) | (↓ -0.00000107) | (↓ -0.00000025) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00010068   |    0.00031859   |    0.00067386   |   0.00127842   |   0.00242414   |
|         | (↓ -0.00000242) | (↓ -0.00000185) | (↓ -0.00000080) | (↓ 0.00000029) | (↓ 0.00000049) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007424   |   0.00008007   |   0.00033285   |   0.00092446   |   0.00220865   |
|         | (↓ 0.00000160) | (↓ 0.00000163) | (↓ 0.00000205) | (↓ 0.00000283) | (↓ 0.00000414) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-6 |   0.00003898   |   0.00013719   |   0.00028301   |    0.00050834   |    0.00087996   |
|         | (↓ 0.00000095) | (↓ 0.00000042) | (↓ 0.00000036) | (↓ -0.00000039) | (↓ -0.00000101) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01044170   |   0.02171858   |   0.03875363   |   0.06389027   |   0.10261308   |
|         | (↓ 0.00006555) | (↓ 0.00006908) | (↓ 0.00007335) | (↓ 0.00010087) | (↓ 0.00000822) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:43:34,397 - block_trainer.py[357] - INFO: epoch 31 (212.889055s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020581   |    0.00021359   |    0.00024253   |    0.00044356   |    0.00145785   |
|         | (↓ -0.00000386) | (↓ -0.00000421) | (↓ -0.00000417) | (↓ -0.00000339) | (↓ -0.00000051) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003514   |   0.00004512   |   0.00016707   |   0.00059251   |   0.00213191   |
|         | (↓ 0.00000063) | (↓ 0.00000068) | (↓ 0.00000088) | (↓ 0.00000116) | (↓ 0.00000186) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005398   |    0.00012956   |    0.00030735   |    0.00069874   |    0.00193949   |
|         | (↓ -0.00000170) | (↓ -0.00000183) | (↓ -0.00000197) | (↓ -0.00000149) | (↓ -0.00000080) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006482   |    0.00022286   |    0.00063475   |    0.00144110   |    0.00333077   |
|         | (↓ -0.00000295) | (↓ -0.00000313) | (↓ -0.00000342) | (↓ -0.00000356) | (↓ -0.00000530) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
| block-4 |    0.00010102   |    0.00031897   |   0.00067369   |   0.00127811   |    0.00242449   |
|         | (↓ -0.00000035) | (↓ -0.00000038) | (↓ 0.00000017) | (↓ 0.00000030) | (↓ -0.00000036) |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007753   |    0.00008343   |    0.00033660   |    0.00092827   |    0.00221327   |
|         | (↓ -0.00000329) | (↓ -0.00000336) | (↓ -0.00000375) | (↓ -0.00000381) | (↓ -0.00000462) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00003905   |   0.00013668   |   0.00028175   |   0.00050650   |   0.00087752   |
|         | (↓ -0.00000006) | (↓ 0.00000051) | (↓ 0.00000127) | (↓ 0.00000184) | (↓ 0.00000245) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01049690   |   0.02169389   |   0.03869866   |   0.06382215   |   0.10251577   |
|         | (↓ -0.00005520) | (↓ 0.00002469) | (↓ 0.00005497) | (↓ 0.00006812) | (↓ 0.00009731) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:47:03,035 - block_trainer.py[357] - INFO: epoch 32 (208.638106s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020200   |   0.00020988   |   0.00023863   |   0.00043966   |   0.00145442   |
|         | (↓ 0.00000381) | (↓ 0.00000371) | (↓ 0.00000391) | (↓ 0.00000390) | (↓ 0.00000343) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003788   |    0.00004785   |    0.00016991   |    0.00059476   |    0.00213363   |
|         | (↓ -0.00000274) | (↓ -0.00000273) | (↓ -0.00000284) | (↓ -0.00000225) | (↓ -0.00000173) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005690   |    0.00013212   |    0.00030948   |    0.00070030   |    0.00194008   |
|         | (↓ -0.00000292) | (↓ -0.00000256) | (↓ -0.00000213) | (↓ -0.00000156) | (↓ -0.00000059) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006178   |   0.00021983   |   0.00063156   |   0.00143802   |   0.00332594   |
|         | (↓ 0.00000305) | (↓ 0.00000303) | (↓ 0.00000319) | (↓ 0.00000308) | (↓ 0.00000483) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-4 |    0.00010235   |    0.00032023   |    0.00067454   |    0.00127872   |   0.00242339   |
|         | (↓ -0.00000132) | (↓ -0.00000126) | (↓ -0.00000085) | (↓ -0.00000061) | (↓ 0.00000111) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007606   |   0.00008197   |   0.00033479   |   0.00092635   |   0.00221038   |
|         | (↓ 0.00000147) | (↓ 0.00000146) | (↓ 0.00000181) | (↓ 0.00000192) | (↓ 0.00000289) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-6 |    0.00003915   |    0.00013695   |    0.00028207   |    0.00050699   |   0.00087741   |
|         | (↓ -0.00000010) | (↓ -0.00000027) | (↓ -0.00000032) | (↓ -0.00000049) | (↓ 0.00000011) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01057530   |    0.02176270   |    0.03881139   |    0.06385000   |   0.10250768   |
|         | (↓ -0.00007840) | (↓ -0.00006881) | (↓ -0.00011273) | (↓ -0.00002784) | (↓ 0.00000809) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2024-10-15 01:50:47,031 - block_trainer.py[357] - INFO: epoch 33 (223.994640s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020823   |    0.00021603   |    0.00024481   |    0.00044575   |    0.00146000   |
|         | (↓ -0.00000624) | (↓ -0.00000614) | (↓ -0.00000619) | (↓ -0.00000608) | (↓ -0.00000558) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003682   |   0.00004687   |   0.00016899   |   0.00059380   |   0.00213208   |
|         | (↓ 0.00000105) | (↓ 0.00000098) | (↓ 0.00000092) | (↓ 0.00000096) | (↓ 0.00000155) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005455   |   0.00013002   |   0.00030802   |   0.00069881   |   0.00193915   |
|         | (↓ 0.00000235) | (↓ 0.00000210) | (↓ 0.00000146) | (↓ 0.00000148) | (↓ 0.00000093) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-3 |    0.00006208   |    0.00022026   |    0.00063210   |   0.00143802   |    0.00332698   |
|         | (↓ -0.00000030) | (↓ -0.00000043) | (↓ -0.00000054) | (↓ 0.00000000) | (↓ -0.00000104) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+----------------+-----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
| block-4 |   0.00010192   |   0.00031980   |    0.00067466   |    0.00127889   |    0.00242391   |
|         | (↓ 0.00000042) | (↓ 0.00000042) | (↓ -0.00000012) | (↓ -0.00000017) | (↓ -0.00000052) |
+---------+----------------+----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007446   |   0.00008032   |   0.00033315   |   0.00092449   |   0.00220884   |
|         | (↓ 0.00000159) | (↓ 0.00000165) | (↓ 0.00000164) | (↓ 0.00000186) | (↓ 0.00000154) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003755   |   0.00013550   |   0.00028081   |   0.00050610   |   0.00087683   |
|         | (↓ 0.00000160) | (↓ 0.00000145) | (↓ 0.00000125) | (↓ 0.00000089) | (↓ 0.00000058) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01038933   |   0.02154453   |   0.03856558   |   0.06358704   |   0.10223817   |
|         | (↓ 0.00018597) | (↓ 0.00021817) | (↓ 0.00024581) | (↓ 0.00026295) | (↓ 0.00026951) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:54:17,410 - block_trainer.py[357] - INFO: epoch 34 (210.378311s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020309   |   0.00021106   |   0.00023978   |   0.00044050   |   0.00145402   |
|         | (↓ 0.00000514) | (↓ 0.00000496) | (↓ 0.00000503) | (↓ 0.00000525) | (↓ 0.00000599) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00003740   |    0.00004742   |    0.00016947   |    0.00059407   |   0.00213170   |
|         | (↓ -0.00000057) | (↓ -0.00000055) | (↓ -0.00000048) | (↓ -0.00000027) | (↓ 0.00000038) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005362   |   0.00012860   |   0.00030608   |   0.00069623   |   0.00193652   |
|         | (↓ 0.00000093) | (↓ 0.00000142) | (↓ 0.00000194) | (↓ 0.00000258) | (↓ 0.00000264) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006214   |    0.00022061   |    0.00063231   |    0.00143877   |    0.00332699   |
|         | (↓ -0.00000007) | (↓ -0.00000035) | (↓ -0.00000021) | (↓ -0.00000075) | (↓ -0.00000001) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00010016   |   0.00031778   |   0.00067154   |   0.00127472   |   0.00241969   |
|         | (↓ 0.00000176) | (↓ 0.00000203) | (↓ 0.00000313) | (↓ 0.00000417) | (↓ 0.00000421) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007462   |    0.00008048   |    0.00033326   |   0.00092447   |   0.00220870   |
|         | (↓ -0.00000015) | (↓ -0.00000016) | (↓ -0.00000011) | (↓ 0.00000002) | (↓ 0.00000014) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00003786   |   0.00013536   |   0.00027978   |   0.00050469   |   0.00087530   |
|         | (↓ -0.00000031) | (↓ 0.00000014) | (↓ 0.00000103) | (↓ 0.00000141) | (↓ 0.00000152) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01034545   |   0.02145682   |   0.03845137   |   0.06347054   |   0.10208333   |
|         | (↓ 0.00004388) | (↓ 0.00008771) | (↓ 0.00011421) | (↓ 0.00011650) | (↓ 0.00015484) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 01:58:00,691 - block_trainer.py[357] - INFO: epoch 35 (223.279779s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019901   |   0.00020705   |   0.00023579   |   0.00043653   |   0.00144788   |
|         | (↓ 0.00000408) | (↓ 0.00000402) | (↓ 0.00000399) | (↓ 0.00000396) | (↓ 0.00000614) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003566   |   0.00004549   |   0.00016741   |   0.00059210   |   0.00213042   |
|         | (↓ 0.00000173) | (↓ 0.00000193) | (↓ 0.00000206) | (↓ 0.00000197) | (↓ 0.00000128) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005380   |    0.00012874   |    0.00030642   |    0.00069650   |    0.00193693   |
|         | (↓ -0.00000019) | (↓ -0.00000013) | (↓ -0.00000033) | (↓ -0.00000027) | (↓ -0.00000041) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005950   |   0.00021761   |   0.00062943   |   0.00143533   |   0.00332410   |
|         | (↓ 0.00000264) | (↓ 0.00000301) | (↓ 0.00000288) | (↓ 0.00000344) | (↓ 0.00000289) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009850   |   0.00031614   |   0.00067001   |   0.00127294   |   0.00241730   |
|         | (↓ 0.00000166) | (↓ 0.00000163) | (↓ 0.00000153) | (↓ 0.00000178) | (↓ 0.00000239) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007296   |   0.00007880   |   0.00033209   |   0.00092288   |   0.00220729   |
|         | (↓ 0.00000166) | (↓ 0.00000168) | (↓ 0.00000117) | (↓ 0.00000159) | (↓ 0.00000141) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003869   |    0.00013569   |    0.00027998   |    0.00050473   |    0.00087597   |
|         | (↓ -0.00000083) | (↓ -0.00000033) | (↓ -0.00000020) | (↓ -0.00000004) | (↓ -0.00000067) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01050121   |    0.02162302   |    0.03860719   |    0.06355195   |    0.10215785   |
|         | (↓ -0.00015576) | (↓ -0.00016620) | (↓ -0.00015581) | (↓ -0.00008141) | (↓ -0.00007453) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 02:01:47,433 - block_trainer.py[357] - INFO: epoch 36 (226.741344s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+-----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+----------------+-----------------+----------------+
| block-0 |   0.00019890   |   0.00020686   |   0.00023575   |    0.00043687   |   0.00144558   |
|         | (↓ 0.00000011) | (↓ 0.00000018) | (↓ 0.00000004) | (↓ -0.00000034) | (↓ 0.00000230) |
+---------+----------------+----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003567   |    0.00004562   |    0.00016770   |   0.00059166   |   0.00212886   |
|         | (↓ -0.00000001) | (↓ -0.00000014) | (↓ -0.00000029) | (↓ 0.00000044) | (↓ 0.00000155) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005445   |    0.00012934   |    0.00030707   |    0.00069703   |    0.00193712   |
|         | (↓ -0.00000064) | (↓ -0.00000060) | (↓ -0.00000065) | (↓ -0.00000053) | (↓ -0.00000019) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006225   |    0.00022032   |    0.00063194   |    0.00143813   |    0.00332672   |
|         | (↓ -0.00000275) | (↓ -0.00000272) | (↓ -0.00000251) | (↓ -0.00000280) | (↓ -0.00000262) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00010099   |    0.00031914   |    0.00067270   |    0.00127503   |    0.00241964   |
|         | (↓ -0.00000248) | (↓ -0.00000300) | (↓ -0.00000269) | (↓ -0.00000209) | (↓ -0.00000233) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007458   |    0.00008042   |    0.00033355   |    0.00092494   |    0.00220831   |
|         | (↓ -0.00000162) | (↓ -0.00000162) | (↓ -0.00000146) | (↓ -0.00000206) | (↓ -0.00000102) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-6 |    0.00003903   |    0.00013616   |    0.00028053   |    0.00050541   |   0.00087570   |
|         | (↓ -0.00000033) | (↓ -0.00000047) | (↓ -0.00000055) | (↓ -0.00000068) | (↓ 0.00000027) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01043810   |   0.02152829   |   0.03852624   |   0.06345687   |   0.10207183   |
|         | (↓ 0.00006310) | (↓ 0.00009473) | (↓ 0.00008095) | (↓ 0.00009508) | (↓ 0.00008602) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:05:40,286 - block_trainer.py[357] - INFO: epoch 37 (232.852175s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00021377   |    0.00022172   |    0.00025052   |    0.00045100   |    0.00145855   |
|         | (↓ -0.00001486) | (↓ -0.00001486) | (↓ -0.00001477) | (↓ -0.00001413) | (↓ -0.00001297) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003899   |    0.00004881   |    0.00017108   |    0.00059485   |    0.00213169   |
|         | (↓ -0.00000332) | (↓ -0.00000319) | (↓ -0.00000338) | (↓ -0.00000318) | (↓ -0.00000282) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005601   |    0.00013061   |    0.00030842   |    0.00069804   |    0.00193811   |
|         | (↓ -0.00000156) | (↓ -0.00000128) | (↓ -0.00000135) | (↓ -0.00000101) | (↓ -0.00000100) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006643   |    0.00022428   |    0.00063593   |    0.00144174   |    0.00333000   |
|         | (↓ -0.00000417) | (↓ -0.00000396) | (↓ -0.00000399) | (↓ -0.00000361) | (↓ -0.00000328) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00010543   |    0.00032306   |    0.00067658   |    0.00127812   |    0.00242211   |
|         | (↓ -0.00000444) | (↓ -0.00000392) | (↓ -0.00000389) | (↓ -0.00000309) | (↓ -0.00000247) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-5 |   0.00007456   |    0.00008044   |   0.00033305   |   0.00092347   |   0.00220683   |
|         | (↓ 0.00000002) | (↓ -0.00000002) | (↓ 0.00000050) | (↓ 0.00000148) | (↓ 0.00000148) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-6 |    0.00003984   |    0.00013676   |    0.00028075   |   0.00050518   |    0.00087582   |
|         | (↓ -0.00000081) | (↓ -0.00000061) | (↓ -0.00000022) | (↓ 0.00000023) | (↓ -0.00000012) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01038791   |   0.02145508   |   0.03844922   |   0.06338945   |   0.10193730   |
|         | (↓ 0.00005019) | (↓ 0.00007321) | (↓ 0.00007701) | (↓ 0.00006742) | (↓ 0.00013453) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:09:40,273 - block_trainer.py[357] - INFO: epoch 38 (239.986591s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020071   |   0.00020944   |   0.00023849   |   0.00043890   |   0.00144525   |
|         | (↓ 0.00001305) | (↓ 0.00001228) | (↓ 0.00001203) | (↓ 0.00001210) | (↓ 0.00001330) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003569   |   0.00004549   |   0.00016721   |   0.00059144   |   0.00212770   |
|         | (↓ 0.00000330) | (↓ 0.00000333) | (↓ 0.00000387) | (↓ 0.00000341) | (↓ 0.00000398) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005855   |    0.00013298   |    0.00031083   |    0.00070006   |    0.00193973   |
|         | (↓ -0.00000254) | (↓ -0.00000236) | (↓ -0.00000241) | (↓ -0.00000202) | (↓ -0.00000161) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006188   |   0.00021978   |   0.00063157   |   0.00143733   |   0.00332687   |
|         | (↓ 0.00000455) | (↓ 0.00000450) | (↓ 0.00000436) | (↓ 0.00000441) | (↓ 0.00000313) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009982   |   0.00031695   |   0.00066971   |   0.00127086   |   0.00241626   |
|         | (↓ 0.00000561) | (↓ 0.00000611) | (↓ 0.00000688) | (↓ 0.00000726) | (↓ 0.00000585) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-5 |   0.00007440   |   0.00008022   |   0.00033259   |    0.00092360   |    0.00220743   |
|         | (↓ 0.00000015) | (↓ 0.00000022) | (↓ 0.00000046) | (↓ -0.00000013) | (↓ -0.00000061) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003886   |   0.00013554   |   0.00027940   |   0.00050405   |   0.00087452   |
|         | (↓ 0.00000098) | (↓ 0.00000122) | (↓ 0.00000135) | (↓ 0.00000113) | (↓ 0.00000130) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01032700   |   0.02140998   |   0.03835190   |   0.06325114   |   0.10185444   |
|         | (↓ 0.00006091) | (↓ 0.00004510) | (↓ 0.00009732) | (↓ 0.00013831) | (↓ 0.00008287) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:13:14,356 - block_trainer.py[357] - INFO: epoch 39 (214.082095s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020577   |    0.00021497   |    0.00024399   |    0.00044426   |    0.00144730   |
|         | (↓ -0.00000505) | (↓ -0.00000552) | (↓ -0.00000550) | (↓ -0.00000536) | (↓ -0.00000205) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003381   |   0.00004368   |   0.00016527   |   0.00058963   |   0.00212665   |
|         | (↓ 0.00000189) | (↓ 0.00000180) | (↓ 0.00000194) | (↓ 0.00000181) | (↓ 0.00000106) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005273   |   0.00012708   |   0.00030495   |   0.00069401   |   0.00193430   |
|         | (↓ 0.00000582) | (↓ 0.00000590) | (↓ 0.00000587) | (↓ 0.00000605) | (↓ 0.00000543) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006279   |    0.00022099   |    0.00063278   |    0.00143907   |    0.00332767   |
|         | (↓ -0.00000091) | (↓ -0.00000121) | (↓ -0.00000120) | (↓ -0.00000174) | (↓ -0.00000080) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009771   |   0.00031472   |   0.00066737   |   0.00126768   |   0.00241303   |
|         | (↓ 0.00000212) | (↓ 0.00000223) | (↓ 0.00000234) | (↓ 0.00000318) | (↓ 0.00000322) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007238   |   0.00007825   |   0.00033053   |   0.00092146   |   0.00220498   |
|         | (↓ 0.00000203) | (↓ 0.00000197) | (↓ 0.00000206) | (↓ 0.00000214) | (↓ 0.00000246) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003827   |   0.00013502   |   0.00027861   |   0.00050328   |   0.00087312   |
|         | (↓ 0.00000059) | (↓ 0.00000052) | (↓ 0.00000079) | (↓ 0.00000077) | (↓ 0.00000140) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01038841   |    0.02145289   |    0.03839091   |    0.06334237   |    0.10191577   |
|         | (↓ -0.00006141) | (↓ -0.00004292) | (↓ -0.00003901) | (↓ -0.00009123) | (↓ -0.00006133) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 02:16:50,932 - block_trainer.py[357] - INFO: epoch 40 (216.575540s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019365   |   0.00020135   |   0.00022983   |   0.00042957   |   0.00142986   |
|         | (↓ 0.00001212) | (↓ 0.00001362) | (↓ 0.00001416) | (↓ 0.00001469) | (↓ 0.00001744) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003623   |    0.00004617   |    0.00016800   |    0.00059210   |    0.00212875   |
|         | (↓ -0.00000243) | (↓ -0.00000249) | (↓ -0.00000273) | (↓ -0.00000247) | (↓ -0.00000211) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005258   |   0.00012684   |   0.00030479   |   0.00069356   |   0.00193327   |
|         | (↓ 0.00000015) | (↓ 0.00000024) | (↓ 0.00000016) | (↓ 0.00000045) | (↓ 0.00000104) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006446   |    0.00022274   |    0.00063451   |    0.00144034   |    0.00332814   |
|         | (↓ -0.00000166) | (↓ -0.00000174) | (↓ -0.00000173) | (↓ -0.00000128) | (↓ -0.00000047) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-4 |    0.00009880   |    0.00031542   |    0.00066765   |   0.00126757   |   0.00241269   |
|         | (↓ -0.00000110) | (↓ -0.00000070) | (↓ -0.00000028) | (↓ 0.00000011) | (↓ 0.00000034) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |   0.00007237   |    0.00007826   |    0.00033084   |    0.00092186   |    0.00220575   |
|         | (↓ 0.00000001) | (↓ -0.00000001) | (↓ -0.00000031) | (↓ -0.00000040) | (↓ -0.00000078) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
| block-6 |    0.00003863   |    0.00013526   |   0.00027857   |    0.00050353   |    0.00087392   |
|         | (↓ -0.00000036) | (↓ -0.00000024) | (↓ 0.00000004) | (↓ -0.00000025) | (↓ -0.00000080) |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01039048   |   0.02141974   |   0.03834912   |   0.06316016   |   0.10169592   |
|         | (↓ -0.00000207) | (↓ 0.00003316) | (↓ 0.00004179) | (↓ 0.00018222) | (↓ 0.00021985) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:20:20,492 - block_trainer.py[357] - INFO: epoch 41 (209.560225s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020299   |    0.00021150   |    0.00024025   |    0.00043982   |    0.00143965   |
|         | (↓ -0.00000934) | (↓ -0.00001016) | (↓ -0.00001041) | (↓ -0.00001025) | (↓ -0.00000978) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003451   |   0.00004444   |   0.00016592   |   0.00058987   |   0.00212631   |
|         | (↓ 0.00000172) | (↓ 0.00000173) | (↓ 0.00000208) | (↓ 0.00000223) | (↓ 0.00000245) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005215   |   0.00012619   |   0.00030393   |   0.00069215   |   0.00193073   |
|         | (↓ 0.00000043) | (↓ 0.00000065) | (↓ 0.00000087) | (↓ 0.00000140) | (↓ 0.00000254) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005997   |   0.00021773   |   0.00062916   |   0.00143456   |   0.00332171   |
|         | (↓ 0.00000448) | (↓ 0.00000501) | (↓ 0.00000535) | (↓ 0.00000578) | (↓ 0.00000644) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009686   |   0.00031364   |   0.00066622   |   0.00126542   |   0.00241077   |
|         | (↓ 0.00000194) | (↓ 0.00000179) | (↓ 0.00000143) | (↓ 0.00000215) | (↓ 0.00000192) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007271   |    0.00007855   |    0.00033148   |    0.00092221   |   0.00220492   |
|         | (↓ -0.00000034) | (↓ -0.00000029) | (↓ -0.00000064) | (↓ -0.00000036) | (↓ 0.00000083) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003713   |   0.00013405   |   0.00027734   |   0.00050231   |   0.00087173   |
|         | (↓ 0.00000150) | (↓ 0.00000122) | (↓ 0.00000124) | (↓ 0.00000122) | (↓ 0.00000218) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-7 |   0.01035029   |   0.02138633   |   0.03833599   |    0.06318778   |    0.10175176   |
|         | (↓ 0.00004019) | (↓ 0.00003341) | (↓ 0.00001313) | (↓ -0.00002763) | (↓ -0.00005584) |
+---------+----------------+----------------+----------------+-----------------+-----------------+

2024-10-15 02:23:42,718 - block_trainer.py[357] - INFO: epoch 42 (202.225352s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-0 |    0.00020348   |    0.00021157   |   0.00024022   |   0.00043936   |   0.00143757   |
|         | (↓ -0.00000049) | (↓ -0.00000007) | (↓ 0.00000003) | (↓ 0.00000047) | (↓ 0.00000207) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003635   |    0.00004621   |    0.00016720   |    0.00059132   |    0.00212705   |
|         | (↓ -0.00000184) | (↓ -0.00000177) | (↓ -0.00000128) | (↓ -0.00000146) | (↓ -0.00000074) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005223   |    0.00012632   |    0.00030427   |   0.00069215   |   0.00193069   |
|         | (↓ -0.00000008) | (↓ -0.00000013) | (↓ -0.00000034) | (↓ 0.00000000) | (↓ 0.00000004) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006170   |    0.00021973   |    0.00063126   |    0.00143676   |    0.00332530   |
|         | (↓ -0.00000173) | (↓ -0.00000200) | (↓ -0.00000210) | (↓ -0.00000219) | (↓ -0.00000359) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009559   |   0.00031288   |   0.00066549   |   0.00126381   |   0.00240895   |
|         | (↓ 0.00000127) | (↓ 0.00000076) | (↓ 0.00000073) | (↓ 0.00000161) | (↓ 0.00000183) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007389   |    0.00007969   |    0.00033211   |    0.00092391   |    0.00220709   |
|         | (↓ -0.00000118) | (↓ -0.00000114) | (↓ -0.00000063) | (↓ -0.00000170) | (↓ -0.00000217) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-6 |   0.00003710   |    0.00013419   |   0.00027719   |   0.00050199   |   0.00087151   |
|         | (↓ 0.00000002) | (↓ -0.00000014) | (↓ 0.00000015) | (↓ 0.00000032) | (↓ 0.00000022) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01031988   |   0.02132100   |   0.03822579   |   0.06303796   |   0.10156753   |
|         | (↓ 0.00003041) | (↓ 0.00006533) | (↓ 0.00011020) | (↓ 0.00014982) | (↓ 0.00018423) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:27:03,030 - block_trainer.py[357] - INFO: epoch 43 (200.311693s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020214   |   0.00021062   |   0.00023942   |   0.00043864   |   0.00143517   |
|         | (↓ 0.00000133) | (↓ 0.00000096) | (↓ 0.00000080) | (↓ 0.00000071) | (↓ 0.00000241) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003516   |   0.00004504   |   0.00016556   |   0.00059095   |   0.00212622   |
|         | (↓ 0.00000119) | (↓ 0.00000117) | (↓ 0.00000163) | (↓ 0.00000038) | (↓ 0.00000083) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005338   |    0.00012738   |    0.00030530   |    0.00069269   |    0.00193132   |
|         | (↓ -0.00000114) | (↓ -0.00000106) | (↓ -0.00000103) | (↓ -0.00000054) | (↓ -0.00000063) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006074   |   0.00021884   |   0.00063052   |   0.00143583   |   0.00332294   |
|         | (↓ 0.00000096) | (↓ 0.00000089) | (↓ 0.00000074) | (↓ 0.00000093) | (↓ 0.00000237) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-4 |    0.00009638   |   0.00031272   |   0.00066470   |   0.00126212   |   0.00240687   |
|         | (↓ -0.00000079) | (↓ 0.00000015) | (↓ 0.00000079) | (↓ 0.00000169) | (↓ 0.00000208) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007615   |    0.00008196   |    0.00033415   |    0.00092436   |   0.00220514   |
|         | (↓ -0.00000226) | (↓ -0.00000227) | (↓ -0.00000204) | (↓ -0.00000045) | (↓ 0.00000195) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00003770   |    0.00013448   |   0.00027670   |   0.00050166   |   0.00087090   |
|         | (↓ -0.00000060) | (↓ -0.00000029) | (↓ 0.00000049) | (↓ 0.00000033) | (↓ 0.00000061) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01034511   |    0.02135220   |    0.03825836   |    0.06307272   |    0.10158766   |
|         | (↓ -0.00002523) | (↓ -0.00003120) | (↓ -0.00003256) | (↓ -0.00003476) | (↓ -0.00002013) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 02:30:09,073 - block_trainer.py[357] - INFO: epoch 44 (186.042022s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020767   |    0.00021664   |    0.00024588   |    0.00044494   |    0.00144151   |
|         | (↓ -0.00000552) | (↓ -0.00000602) | (↓ -0.00000646) | (↓ -0.00000629) | (↓ -0.00000634) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003451   |   0.00004432   |   0.00016297   |   0.00058912   |   0.00212456   |
|         | (↓ 0.00000066) | (↓ 0.00000072) | (↓ 0.00000259) | (↓ 0.00000183) | (↓ 0.00000166) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005466   |    0.00012851   |    0.00030618   |    0.00069362   |    0.00193240   |
|         | (↓ -0.00000129) | (↓ -0.00000112) | (↓ -0.00000089) | (↓ -0.00000093) | (↓ -0.00000108) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006196   |    0.00022036   |    0.00063198   |    0.00143777   |    0.00332503   |
|         | (↓ -0.00000122) | (↓ -0.00000152) | (↓ -0.00000146) | (↓ -0.00000194) | (↓ -0.00000209) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009945   |    0.00031646   |    0.00066873   |    0.00126591   |    0.00241235   |
|         | (↓ -0.00000307) | (↓ -0.00000374) | (↓ -0.00000403) | (↓ -0.00000379) | (↓ -0.00000548) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007168   |   0.00007759   |   0.00033025   |   0.00092201   |   0.00220430   |
|         | (↓ 0.00000447) | (↓ 0.00000437) | (↓ 0.00000390) | (↓ 0.00000234) | (↓ 0.00000084) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-6 |   0.00003676   |   0.00013383   |   0.00027629   |    0.00050203   |    0.00087160   |
|         | (↓ 0.00000094) | (↓ 0.00000064) | (↓ 0.00000041) | (↓ -0.00000037) | (↓ -0.00000070) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-7 |    0.01036103   |   0.02134367   |   0.03821946   |   0.06300895   |   0.10157108   |
|         | (↓ -0.00001592) | (↓ 0.00000853) | (↓ 0.00003889) | (↓ 0.00006377) | (↓ 0.00001658) |
+---------+-----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:33:01,077 - block_trainer.py[357] - INFO: epoch 45 (172.003776s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020316   |   0.00021165   |   0.00024050   |   0.00043908   |   0.00143381   |
|         | (↓ 0.00000451) | (↓ 0.00000500) | (↓ 0.00000538) | (↓ 0.00000586) | (↓ 0.00000770) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-1 |   0.00003341   |   0.00004333   |   0.00016085   |   0.00058894   |    0.00212461   |
|         | (↓ 0.00000109) | (↓ 0.00000099) | (↓ 0.00000212) | (↓ 0.00000018) | (↓ -0.00000005) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-2 |    0.00005483   |    0.00012870   |    0.00030652   |   0.00069356   |   0.00193206   |
|         | (↓ -0.00000017) | (↓ -0.00000020) | (↓ -0.00000033) | (↓ 0.00000005) | (↓ 0.00000034) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006034   |   0.00021865   |   0.00063046   |   0.00143635   |   0.00332440   |
|         | (↓ 0.00000162) | (↓ 0.00000171) | (↓ 0.00000153) | (↓ 0.00000142) | (↓ 0.00000063) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009720   |   0.00031383   |   0.00066604   |   0.00126220   |   0.00240807   |
|         | (↓ 0.00000225) | (↓ 0.00000263) | (↓ 0.00000269) | (↓ 0.00000371) | (↓ 0.00000428) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007589   |    0.00008173   |    0.00033417   |    0.00092487   |    0.00220686   |
|         | (↓ -0.00000421) | (↓ -0.00000414) | (↓ -0.00000392) | (↓ -0.00000286) | (↓ -0.00000256) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00003744   |    0.00013422   |   0.00027555   |   0.00050112   |   0.00087029   |
|         | (↓ -0.00000068) | (↓ -0.00000038) | (↓ 0.00000074) | (↓ 0.00000092) | (↓ 0.00000132) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-7 |   0.01027225   |   0.02124150   |   0.03816929   |   0.06291934   |    0.10157228   |
|         | (↓ 0.00008878) | (↓ 0.00010216) | (↓ 0.00005017) | (↓ 0.00008962) | (↓ -0.00000120) |
+---------+----------------+----------------+----------------+----------------+-----------------+

2024-10-15 02:36:19,061 - block_trainer.py[357] - INFO: epoch 46 (197.983288s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020188   |   0.00021012   |   0.00023902   |   0.00043719   |   0.00143116   |
|         | (↓ 0.00000128) | (↓ 0.00000153) | (↓ 0.00000148) | (↓ 0.00000190) | (↓ 0.00000265) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003562   |    0.00004546   |    0.00016160   |    0.00059050   |    0.00212545   |
|         | (↓ -0.00000221) | (↓ -0.00000213) | (↓ -0.00000074) | (↓ -0.00000157) | (↓ -0.00000085) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005580   |    0.00012949   |    0.00030707   |    0.00069373   |    0.00193237   |
|         | (↓ -0.00000097) | (↓ -0.00000079) | (↓ -0.00000055) | (↓ -0.00000017) | (↓ -0.00000031) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006201   |    0.00022023   |    0.00063190   |    0.00143756   |    0.00332572   |
|         | (↓ -0.00000167) | (↓ -0.00000158) | (↓ -0.00000144) | (↓ -0.00000121) | (↓ -0.00000132) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009816   |    0.00031460   |    0.00066674   |    0.00126222   |    0.00240857   |
|         | (↓ -0.00000096) | (↓ -0.00000078) | (↓ -0.00000070) | (↓ -0.00000001) | (↓ -0.00000050) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007485   |   0.00008065   |   0.00033214   |   0.00092258   |   0.00220401   |
|         | (↓ 0.00000104) | (↓ 0.00000108) | (↓ 0.00000203) | (↓ 0.00000229) | (↓ 0.00000285) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003659   |   0.00013347   |   0.00027489   |   0.00050096   |   0.00086962   |
|         | (↓ 0.00000084) | (↓ 0.00000075) | (↓ 0.00000067) | (↓ 0.00000015) | (↓ 0.00000067) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01037206   |    0.02134082   |    0.03825922   |    0.06303058   |    0.10159866   |
|         | (↓ -0.00009981) | (↓ -0.00009932) | (↓ -0.00008993) | (↓ -0.00011125) | (↓ -0.00002638) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 02:39:14,764 - block_trainer.py[357] - INFO: epoch 47 (175.703255s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019538   |   0.00020377   |   0.00023281   |   0.00043035   |   0.00142231   |
|         | (↓ 0.00000650) | (↓ 0.00000634) | (↓ 0.00000622) | (↓ 0.00000683) | (↓ 0.00000885) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003354   |   0.00004333   |   0.00015855   |   0.00058823   |   0.00212286   |
|         | (↓ 0.00000208) | (↓ 0.00000213) | (↓ 0.00000305) | (↓ 0.00000227) | (↓ 0.00000260) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00004994   |   0.00012397   |   0.00030220   |   0.00068942   |   0.00192766   |
|         | (↓ 0.00000587) | (↓ 0.00000552) | (↓ 0.00000486) | (↓ 0.00000431) | (↓ 0.00000471) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00006083   |   0.00021904   |   0.00063064   |   0.00143651   |   0.00332462   |
|         | (↓ 0.00000118) | (↓ 0.00000119) | (↓ 0.00000126) | (↓ 0.00000105) | (↓ 0.00000110) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009668   |   0.00031288   |   0.00066454   |   0.00125983   |   0.00240643   |
|         | (↓ 0.00000148) | (↓ 0.00000172) | (↓ 0.00000220) | (↓ 0.00000238) | (↓ 0.00000213) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007495   |    0.00008079   |    0.00033326   |    0.00092435   |    0.00220644   |
|         | (↓ -0.00000010) | (↓ -0.00000013) | (↓ -0.00000112) | (↓ -0.00000177) | (↓ -0.00000243) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
| block-6 |    0.00003685   |    0.00013380   |   0.00027479   |    0.00050117   |    0.00087017   |
|         | (↓ -0.00000026) | (↓ -0.00000033) | (↓ 0.00000010) | (↓ -0.00000021) | (↓ -0.00000055) |
+---------+-----------------+-----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01026303   |   0.02120420   |   0.03811051   |   0.06288340   |   0.10144346   |
|         | (↓ 0.00010902) | (↓ 0.00013663) | (↓ 0.00014871) | (↓ 0.00014718) | (↓ 0.00015521) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:42:34,732 - block_trainer.py[357] - INFO: epoch 48 (199.966905s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019005   |   0.00019823   |   0.00022729   |   0.00042469   |   0.00141709   |
|         | (↓ 0.00000533) | (↓ 0.00000554) | (↓ 0.00000552) | (↓ 0.00000566) | (↓ 0.00000522) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-1 |    0.00003373   |    0.00004351   |   0.00015804   |    0.00058845   |   0.00212269   |
|         | (↓ -0.00000019) | (↓ -0.00000018) | (↓ 0.00000051) | (↓ -0.00000021) | (↓ 0.00000016) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-2 |    0.00005031   |    0.00012412   |   0.00030207   |   0.00068868   |   0.00192686   |
|         | (↓ -0.00000038) | (↓ -0.00000015) | (↓ 0.00000014) | (↓ 0.00000074) | (↓ 0.00000080) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005990   |   0.00021768   |   0.00062911   |   0.00143478   |   0.00332347   |
|         | (↓ 0.00000093) | (↓ 0.00000136) | (↓ 0.00000153) | (↓ 0.00000173) | (↓ 0.00000116) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009351   |   0.00030958   |   0.00066142   |   0.00125589   |   0.00240176   |
|         | (↓ 0.00000317) | (↓ 0.00000330) | (↓ 0.00000312) | (↓ 0.00000394) | (↓ 0.00000467) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-5 |    0.00007685   |    0.00008267   |    0.00033474   |    0.00092502   |   0.00220609   |
|         | (↓ -0.00000190) | (↓ -0.00000188) | (↓ -0.00000148) | (↓ -0.00000067) | (↓ 0.00000035) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003667   |   0.00013322   |   0.00027341   |   0.00049982   |   0.00086856   |
|         | (↓ 0.00000018) | (↓ 0.00000058) | (↓ 0.00000138) | (↓ 0.00000135) | (↓ 0.00000160) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01013782   |   0.02107907   |   0.03798223   |   0.06272893   |   0.10125647   |
|         | (↓ 0.00012522) | (↓ 0.00012513) | (↓ 0.00012828) | (↓ 0.00015447) | (↓ 0.00018699) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:45:55,365 - block_trainer.py[357] - INFO: epoch 49 (200.633460s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019442   |    0.00020299   |    0.00023190   |    0.00042875   |    0.00141796   |
|         | (↓ -0.00000437) | (↓ -0.00000477) | (↓ -0.00000462) | (↓ -0.00000406) | (↓ -0.00000086) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003638   |    0.00004626   |    0.00016032   |    0.00059046   |    0.00212400   |
|         | (↓ -0.00000265) | (↓ -0.00000275) | (↓ -0.00000229) | (↓ -0.00000201) | (↓ -0.00000131) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005185   |    0.00012577   |    0.00030356   |    0.00068961   |    0.00192730   |
|         | (↓ -0.00000153) | (↓ -0.00000165) | (↓ -0.00000150) | (↓ -0.00000093) | (↓ -0.00000044) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00006012   |    0.00021821   |    0.00062972   |    0.00143488   |   0.00332188   |
|         | (↓ -0.00000022) | (↓ -0.00000053) | (↓ -0.00000061) | (↓ -0.00000010) | (↓ 0.00000158) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009627   |    0.00031222   |    0.00066354   |    0.00125714   |    0.00240287   |
|         | (↓ -0.00000276) | (↓ -0.00000264) | (↓ -0.00000212) | (↓ -0.00000125) | (↓ -0.00000111) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007295   |   0.00007877   |   0.00033112   |   0.00092155   |   0.00220310   |
|         | (↓ 0.00000390) | (↓ 0.00000389) | (↓ 0.00000362) | (↓ 0.00000347) | (↓ 0.00000299) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003653   |   0.00013294   |   0.00027267   |   0.00049934   |   0.00086802   |
|         | (↓ 0.00000014) | (↓ 0.00000027) | (↓ 0.00000073) | (↓ 0.00000048) | (↓ 0.00000054) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.01023234   |    0.02110256   |    0.03800315   |   0.06270921   |   0.10116457   |
|         | (↓ -0.00009452) | (↓ -0.00002350) | (↓ -0.00002092) | (↓ 0.00001972) | (↓ 0.00009190) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2024-10-15 02:48:54,308 - block_trainer.py[357] - INFO: epoch 50 (178.942362s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00019887   |    0.00020772   |    0.00023683   |    0.00043397   |    0.00142023   |
|         | (↓ -0.00000445) | (↓ -0.00000473) | (↓ -0.00000492) | (↓ -0.00000522) | (↓ -0.00000227) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003391   |   0.00004369   |   0.00015698   |   0.00058869   |   0.00212239   |
|         | (↓ 0.00000247) | (↓ 0.00000257) | (↓ 0.00000335) | (↓ 0.00000176) | (↓ 0.00000161) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005435   |    0.00012809   |    0.00030589   |    0.00069204   |    0.00192982   |
|         | (↓ -0.00000250) | (↓ -0.00000232) | (↓ -0.00000233) | (↓ -0.00000242) | (↓ -0.00000252) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-3 |   0.00005841   |   0.00021647   |   0.00062831   |   0.00143404   |    0.00332286   |
|         | (↓ 0.00000171) | (↓ 0.00000174) | (↓ 0.00000141) | (↓ 0.00000085) | (↓ -0.00000098) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009636   |    0.00031277   |    0.00066455   |    0.00125773   |    0.00240388   |
|         | (↓ -0.00000009) | (↓ -0.00000055) | (↓ -0.00000101) | (↓ -0.00000059) | (↓ -0.00000101) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007256   |   0.00007840   |   0.00033000   |   0.00092059   |   0.00220184   |
|         | (↓ 0.00000039) | (↓ 0.00000037) | (↓ 0.00000112) | (↓ 0.00000096) | (↓ 0.00000125) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
|         |      0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |   0.00003644   |    0.00013303   |    0.00027320   |    0.00050031   |    0.00086884   |
|         | (↓ 0.00000009) | (↓ -0.00000008) | (↓ -0.00000052) | (↓ -0.00000097) | (↓ -0.00000082) |
+---------+----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01018074   |   0.02105415   |   0.03797960   |   0.06266601   |   0.10115841   |
|         | (↓ 0.00005160) | (↓ 0.00004841) | (↓ 0.00002355) | (↓ 0.00004320) | (↓ 0.00000616) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:51:50,200 - block_trainer.py[357] - INFO: epoch 51 (175.891646s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019486   |   0.00020390   |   0.00023308   |   0.00042992   |   0.00141709   |
|         | (↓ 0.00000401) | (↓ 0.00000383) | (↓ 0.00000375) | (↓ 0.00000405) | (↓ 0.00000314) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003420   |    0.00004408   |    0.00015737   |    0.00058915   |    0.00212397   |
|         | (↓ -0.00000029) | (↓ -0.00000039) | (↓ -0.00000040) | (↓ -0.00000046) | (↓ -0.00000158) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005602   |    0.00012944   |    0.00030710   |    0.00069283   |    0.00193026   |
|         | (↓ -0.00000167) | (↓ -0.00000135) | (↓ -0.00000122) | (↓ -0.00000080) | (↓ -0.00000044) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006024   |    0.00021805   |    0.00062983   |    0.00143526   |    0.00332443   |
|         | (↓ -0.00000183) | (↓ -0.00000158) | (↓ -0.00000152) | (↓ -0.00000123) | (↓ -0.00000157) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
| block-4 |    0.00009745   |    0.00031301   |   0.00066424   |   0.00125679   |    0.00240399   |
|         | (↓ -0.00000109) | (↓ -0.00000024) | (↓ 0.00000031) | (↓ 0.00000094) | (↓ -0.00000011) |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007309   |    0.00007889   |    0.00033064   |    0.00092166   |    0.00220376   |
|         | (↓ -0.00000054) | (↓ -0.00000049) | (↓ -0.00000064) | (↓ -0.00000107) | (↓ -0.00000191) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00003718   |    0.00013323   |   0.00027249   |   0.00049957   |   0.00086861   |
|         | (↓ -0.00000074) | (↓ -0.00000021) | (↓ 0.00000070) | (↓ 0.00000074) | (↓ 0.00000023) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01034475   |    0.02118778   |    0.03809018   |    0.06278287   |    0.10127289   |
|         | (↓ -0.00016401) | (↓ -0.00013363) | (↓ -0.00011058) | (↓ -0.00011686) | (↓ -0.00011448) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 02:54:47,229 - block_trainer.py[357] - INFO: epoch 52 (177.028028s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020330   |    0.00021213   |    0.00024157   |    0.00043866   |    0.00142687   |
|         | (↓ -0.00000845) | (↓ -0.00000824) | (↓ -0.00000849) | (↓ -0.00000873) | (↓ -0.00000978) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003578   |    0.00004559   |    0.00015826   |    0.00059043   |    0.00212455   |
|         | (↓ -0.00000158) | (↓ -0.00000151) | (↓ -0.00000089) | (↓ -0.00000128) | (↓ -0.00000057) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005437   |   0.00012795   |   0.00030569   |   0.00069123   |   0.00192796   |
|         | (↓ 0.00000165) | (↓ 0.00000149) | (↓ 0.00000142) | (↓ 0.00000161) | (↓ 0.00000230) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006149   |    0.00021957   |    0.00063111   |    0.00143657   |    0.00332508   |
|         | (↓ -0.00000125) | (↓ -0.00000152) | (↓ -0.00000128) | (↓ -0.00000131) | (↓ -0.00000064) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+-----------------+----------------+----------------+----------------+
|         |      0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+-----------------+----------------+----------------+----------------+
| block-4 |   0.00009696   |    0.00031311   |   0.00066423   |   0.00125645   |   0.00240279   |
|         | (↓ 0.00000049) | (↓ -0.00000010) | (↓ 0.00000001) | (↓ 0.00000034) | (↓ 0.00000120) |
+---------+----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-5 |    0.00007361   |    0.00007950   |    0.00033133   |   0.00092164   |   0.00220233   |
|         | (↓ -0.00000051) | (↓ -0.00000061) | (↓ -0.00000070) | (↓ 0.00000003) | (↓ 0.00000142) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+-----------------+-----------------+----------------+
|         |      0.0       |      0.2       |       0.4       |       0.6       |      0.8       |
+---------+----------------+----------------+-----------------+-----------------+----------------+
| block-6 |   0.00003707   |   0.00013313   |    0.00027253   |    0.00050011   |   0.00086793   |
|         | (↓ 0.00000010) | (↓ 0.00000010) | (↓ -0.00000003) | (↓ -0.00000054) | (↓ 0.00000068) |
+---------+----------------+----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01024061   |   0.02105891   |   0.03796210   |   0.06261370   |   0.10113479   |
|         | (↓ 0.00010414) | (↓ 0.00012887) | (↓ 0.00012808) | (↓ 0.00016917) | (↓ 0.00013810) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 02:57:41,886 - block_trainer.py[357] - INFO: epoch 53 (174.656228s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020689   |    0.00021592   |    0.00024507   |    0.00044190   |    0.00142845   |
|         | (↓ -0.00000359) | (↓ -0.00000379) | (↓ -0.00000350) | (↓ -0.00000324) | (↓ -0.00000158) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-1 |   0.00003565   |   0.00004547   |   0.00015806   |    0.00059046   |    0.00212489   |
|         | (↓ 0.00000013) | (↓ 0.00000013) | (↓ 0.00000020) | (↓ -0.00000003) | (↓ -0.00000035) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005399   |   0.00012738   |   0.00030514   |   0.00069040   |   0.00192661   |
|         | (↓ 0.00000037) | (↓ 0.00000058) | (↓ 0.00000054) | (↓ 0.00000083) | (↓ 0.00000134) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005975   |   0.00021795   |   0.00062974   |   0.00143542   |   0.00332483   |
|         | (↓ 0.00000174) | (↓ 0.00000162) | (↓ 0.00000137) | (↓ 0.00000116) | (↓ 0.00000024) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-4 |   0.00009604   |   0.00031212   |   0.00066351   |   0.00125521   |    0.00240320   |
|         | (↓ 0.00000092) | (↓ 0.00000099) | (↓ 0.00000072) | (↓ 0.00000124) | (↓ -0.00000041) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007018   |   0.00007607   |   0.00032790   |   0.00091873   |   0.00220041   |
|         | (↓ 0.00000343) | (↓ 0.00000343) | (↓ 0.00000344) | (↓ 0.00000291) | (↓ 0.00000192) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003595   |   0.00013188   |   0.00027112   |   0.00049888   |   0.00086734   |
|         | (↓ 0.00000112) | (↓ 0.00000125) | (↓ 0.00000141) | (↓ 0.00000123) | (↓ 0.00000058) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01016442   |   0.02099074   |   0.03791484   |   0.06258327   |   0.10111267   |
|         | (↓ 0.00007619) | (↓ 0.00006818) | (↓ 0.00004727) | (↓ 0.00003043) | (↓ 0.00002212) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 03:00:38,361 - block_trainer.py[357] - INFO: epoch 54 (176.473432s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019855   |   0.00020751   |   0.00023704   |   0.00043340   |   0.00141786   |
|         | (↓ 0.00000834) | (↓ 0.00000841) | (↓ 0.00000803) | (↓ 0.00000850) | (↓ 0.00001059) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003517   |   0.00004498   |   0.00015717   |   0.00059026   |   0.00212423   |
|         | (↓ 0.00000049) | (↓ 0.00000048) | (↓ 0.00000089) | (↓ 0.00000021) | (↓ 0.00000066) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005637   |    0.00012958   |    0.00030714   |    0.00069199   |    0.00192813   |
|         | (↓ -0.00000237) | (↓ -0.00000220) | (↓ -0.00000200) | (↓ -0.00000159) | (↓ -0.00000151) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005867   |   0.00021668   |   0.00062848   |   0.00143404   |   0.00332305   |
|         | (↓ 0.00000107) | (↓ 0.00000128) | (↓ 0.00000126) | (↓ 0.00000138) | (↓ 0.00000178) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-4 |    0.00009833   |    0.00031429   |    0.00066518   |    0.00125622   |   0.00240205   |
|         | (↓ -0.00000229) | (↓ -0.00000218) | (↓ -0.00000167) | (↓ -0.00000101) | (↓ 0.00000115) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007325   |    0.00007913   |    0.00033089   |    0.00092206   |    0.00220266   |
|         | (↓ -0.00000307) | (↓ -0.00000307) | (↓ -0.00000300) | (↓ -0.00000334) | (↓ -0.00000224) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-6 |    0.00003657   |    0.00013214   |   0.00027103   |   0.00049881   |   0.00086717   |
|         | (↓ -0.00000062) | (↓ -0.00000026) | (↓ 0.00000009) | (↓ 0.00000007) | (↓ 0.00000017) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01013610   |   0.02092886   |   0.03785082   |   0.06251140   |   0.10096275   |
|         | (↓ 0.00002831) | (↓ 0.00006188) | (↓ 0.00006402) | (↓ 0.00007187) | (↓ 0.00014992) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 03:04:03,426 - block_trainer.py[357] - INFO: epoch 55 (205.064635s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019695   |   0.00020490   |   0.00023389   |   0.00043008   |   0.00141543   |
|         | (↓ 0.00000160) | (↓ 0.00000262) | (↓ 0.00000315) | (↓ 0.00000332) | (↓ 0.00000243) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00003616   |    0.00004603   |    0.00015785   |    0.00059060   |   0.00212256   |
|         | (↓ -0.00000100) | (↓ -0.00000104) | (↓ -0.00000068) | (↓ -0.00000035) | (↓ 0.00000168) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005372   |   0.00012714   |   0.00030477   |   0.00068968   |   0.00192456   |
|         | (↓ 0.00000265) | (↓ 0.00000244) | (↓ 0.00000237) | (↓ 0.00000231) | (↓ 0.00000356) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-3 |    0.00005991   |    0.00021765   |    0.00062930   |    0.00143441   |   0.00332238   |
|         | (↓ -0.00000124) | (↓ -0.00000097) | (↓ -0.00000082) | (↓ -0.00000037) | (↓ 0.00000067) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009550   |   0.00031157   |   0.00066284   |   0.00125386   |   0.00240091   |
|         | (↓ 0.00000283) | (↓ 0.00000272) | (↓ 0.00000234) | (↓ 0.00000236) | (↓ 0.00000114) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007499   |    0.00008088   |    0.00033220   |    0.00092285   |    0.00220327   |
|         | (↓ -0.00000174) | (↓ -0.00000175) | (↓ -0.00000131) | (↓ -0.00000079) | (↓ -0.00000062) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003586   |   0.00013172   |   0.00027098   |   0.00049879   |   0.00086657   |
|         | (↓ 0.00000071) | (↓ 0.00000042) | (↓ 0.00000005) | (↓ 0.00000001) | (↓ 0.00000060) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+
| block-7 |    0.01019110   |    0.02098080   |    0.03787600   |   0.06250193   |    0.10101056   |
|         | (↓ -0.00005500) | (↓ -0.00005194) | (↓ -0.00002519) | (↓ 0.00000947) | (↓ -0.00004781) |
+---------+-----------------+-----------------+-----------------+----------------+-----------------+

2024-10-15 03:06:53,241 - block_trainer.py[357] - INFO: epoch 56 (169.814640s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019640   |   0.00020437   |   0.00023338   |   0.00042994   |   0.00141484   |
|         | (↓ 0.00000055) | (↓ 0.00000053) | (↓ 0.00000051) | (↓ 0.00000013) | (↓ 0.00000058) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003427   |   0.00004409   |   0.00015560   |   0.00058897   |   0.00212240   |
|         | (↓ 0.00000190) | (↓ 0.00000193) | (↓ 0.00000226) | (↓ 0.00000163) | (↓ 0.00000016) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00004969   |   0.00012299   |   0.00030088   |   0.00068590   |   0.00192163   |
|         | (↓ 0.00000403) | (↓ 0.00000415) | (↓ 0.00000389) | (↓ 0.00000378) | (↓ 0.00000294) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006199   |    0.00022002   |    0.00063160   |    0.00143682   |    0.00332418   |
|         | (↓ -0.00000207) | (↓ -0.00000237) | (↓ -0.00000230) | (↓ -0.00000242) | (↓ -0.00000180) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009777   |    0.00031305   |    0.00066379   |    0.00125456   |    0.00240148   |
|         | (↓ -0.00000227) | (↓ -0.00000148) | (↓ -0.00000095) | (↓ -0.00000071) | (↓ -0.00000056) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007630   |    0.00008219   |    0.00033310   |    0.00092496   |    0.00220495   |
|         | (↓ -0.00000131) | (↓ -0.00000131) | (↓ -0.00000090) | (↓ -0.00000210) | (↓ -0.00000167) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+----------------+----------------+----------------+----------------+
|         |       0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+----------------+----------------+----------------+----------------+
| block-6 |    0.00003599   |   0.00013169   |   0.00027045   |   0.00049807   |   0.00086637   |
|         | (↓ -0.00000013) | (↓ 0.00000003) | (↓ 0.00000053) | (↓ 0.00000073) | (↓ 0.00000020) |
+---------+-----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+-----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+-----------------+----------------+
| block-7 |    0.01020099   |    0.02100975   |   0.03787368   |    0.06253468   |   0.10095925   |
|         | (↓ -0.00000989) | (↓ -0.00002895) | (↓ 0.00000232) | (↓ -0.00003276) | (↓ 0.00005131) |
+---------+-----------------+-----------------+----------------+-----------------+----------------+

2024-10-15 03:10:21,123 - block_trainer.py[357] - INFO: epoch 57 (207.881642s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020146   |    0.00021001   |    0.00023933   |    0.00043551   |    0.00141835   |
|         | (↓ -0.00000506) | (↓ -0.00000563) | (↓ -0.00000595) | (↓ -0.00000556) | (↓ -0.00000350) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-1 |    0.00003570   |    0.00004558   |    0.00015678   |    0.00058982   |   0.00212210   |
|         | (↓ -0.00000143) | (↓ -0.00000149) | (↓ -0.00000119) | (↓ -0.00000085) | (↓ 0.00000029) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005128   |    0.00012462   |    0.00030258   |    0.00068718   |    0.00192236   |
|         | (↓ -0.00000159) | (↓ -0.00000163) | (↓ -0.00000170) | (↓ -0.00000128) | (↓ -0.00000073) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005741   |   0.00021562   |   0.00062711   |   0.00143232   |   0.00332009   |
|         | (↓ 0.00000458) | (↓ 0.00000439) | (↓ 0.00000449) | (↓ 0.00000450) | (↓ 0.00000409) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009563   |   0.00031124   |   0.00066186   |   0.00125220   |   0.00239917   |
|         | (↓ 0.00000213) | (↓ 0.00000181) | (↓ 0.00000192) | (↓ 0.00000237) | (↓ 0.00000231) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007051   |   0.00007633   |   0.00032629   |   0.00091702   |   0.00219783   |
|         | (↓ 0.00000579) | (↓ 0.00000585) | (↓ 0.00000682) | (↓ 0.00000794) | (↓ 0.00000712) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003526   |   0.00013099   |   0.00026987   |   0.00049734   |   0.00086484   |
|         | (↓ 0.00000073) | (↓ 0.00000070) | (↓ 0.00000058) | (↓ 0.00000072) | (↓ 0.00000154) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01012375   |   0.02088087   |   0.03775062   |   0.06240373   |   0.10081417   |
|         | (↓ 0.00007724) | (↓ 0.00012888) | (↓ 0.00012306) | (↓ 0.00013095) | (↓ 0.00014507) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 03:13:50,881 - block_trainer.py[357] - INFO: epoch 58 (209.756992s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00020364   |    0.00021220   |    0.00024187   |    0.00043848   |    0.00142172   |
|         | (↓ -0.00000218) | (↓ -0.00000220) | (↓ -0.00000254) | (↓ -0.00000298) | (↓ -0.00000337) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003602   |    0.00004593   |    0.00015735   |    0.00059098   |    0.00212384   |
|         | (↓ -0.00000032) | (↓ -0.00000035) | (↓ -0.00000056) | (↓ -0.00000117) | (↓ -0.00000174) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005250   |    0.00012588   |    0.00030392   |    0.00068865   |    0.00192314   |
|         | (↓ -0.00000123) | (↓ -0.00000126) | (↓ -0.00000134) | (↓ -0.00000147) | (↓ -0.00000078) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006230   |    0.00022083   |    0.00063243   |    0.00143794   |    0.00332701   |
|         | (↓ -0.00000489) | (↓ -0.00000521) | (↓ -0.00000532) | (↓ -0.00000562) | (↓ -0.00000692) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009581   |    0.00031197   |    0.00066281   |    0.00125353   |    0.00239998   |
|         | (↓ -0.00000018) | (↓ -0.00000073) | (↓ -0.00000095) | (↓ -0.00000133) | (↓ -0.00000081) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007250   |    0.00007833   |    0.00032889   |    0.00092100   |    0.00220169   |
|         | (↓ -0.00000199) | (↓ -0.00000200) | (↓ -0.00000261) | (↓ -0.00000398) | (↓ -0.00000386) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003590   |    0.00013160   |    0.00027060   |    0.00049838   |    0.00086630   |
|         | (↓ -0.00000064) | (↓ -0.00000061) | (↓ -0.00000073) | (↓ -0.00000103) | (↓ -0.00000146) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01019788   |    0.02098352   |    0.03785158   |    0.06253226   |    0.10101042   |
|         | (↓ -0.00007414) | (↓ -0.00010265) | (↓ -0.00010096) | (↓ -0.00012852) | (↓ -0.00019625) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 03:16:58,615 - block_trainer.py[357] - INFO: epoch 59 (187.733969s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020052   |   0.00020932   |   0.00023912   |   0.00043541   |   0.00141697   |
|         | (↓ 0.00000312) | (↓ 0.00000288) | (↓ 0.00000275) | (↓ 0.00000307) | (↓ 0.00000475) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003472   |   0.00004456   |   0.00015527   |   0.00058953   |   0.00212258   |
|         | (↓ 0.00000129) | (↓ 0.00000137) | (↓ 0.00000208) | (↓ 0.00000145) | (↓ 0.00000126) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005456   |    0.00012768   |    0.00030556   |    0.00069015   |    0.00192484   |
|         | (↓ -0.00000205) | (↓ -0.00000181) | (↓ -0.00000164) | (↓ -0.00000150) | (↓ -0.00000170) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005879   |   0.00021678   |   0.00062837   |   0.00143363   |   0.00332279   |
|         | (↓ 0.00000351) | (↓ 0.00000405) | (↓ 0.00000406) | (↓ 0.00000431) | (↓ 0.00000422) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009869   |    0.00031439   |    0.00066433   |    0.00125455   |    0.00240113   |
|         | (↓ -0.00000288) | (↓ -0.00000242) | (↓ -0.00000152) | (↓ -0.00000102) | (↓ -0.00000115) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007228   |   0.00007813   |   0.00032781   |   0.00092088   |   0.00220114   |
|         | (↓ 0.00000023) | (↓ 0.00000020) | (↓ 0.00000108) | (↓ 0.00000012) | (↓ 0.00000055) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+----------------+----------------+-----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |       0.8       |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
| block-6 |    0.00003631   |    0.00013177   |   0.00027049   |   0.00049815   |    0.00086660   |
|         | (↓ -0.00000042) | (↓ -0.00000017) | (↓ 0.00000011) | (↓ 0.00000022) | (↓ -0.00000030) |
+---------+-----------------+-----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01009102   |   0.02085801   |   0.03768525   |   0.06226390   |   0.10069424   |
|         | (↓ 0.00010687) | (↓ 0.00012551) | (↓ 0.00016633) | (↓ 0.00026836) | (↓ 0.00031618) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 03:20:22,208 - block_trainer.py[357] - INFO: epoch 60 (203.591918s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00019422   |   0.00020298   |   0.00023267   |   0.00042858   |   0.00141083   |
|         | (↓ 0.00000630) | (↓ 0.00000633) | (↓ 0.00000646) | (↓ 0.00000683) | (↓ 0.00000615) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-1 |    0.00003529   |    0.00004509   |    0.00015567   |   0.00058948   |   0.00212191   |
|         | (↓ -0.00000056) | (↓ -0.00000052) | (↓ -0.00000041) | (↓ 0.00000005) | (↓ 0.00000067) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005158   |   0.00012485   |   0.00030287   |   0.00068719   |   0.00192098   |
|         | (↓ 0.00000298) | (↓ 0.00000284) | (↓ 0.00000269) | (↓ 0.00000296) | (↓ 0.00000386) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005734   |   0.00021573   |   0.00062742   |   0.00143315   |   0.00332235   |
|         | (↓ 0.00000145) | (↓ 0.00000106) | (↓ 0.00000095) | (↓ 0.00000049) | (↓ 0.00000044) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009332   |   0.00030966   |   0.00066006   |   0.00125026   |   0.00239602   |
|         | (↓ 0.00000537) | (↓ 0.00000473) | (↓ 0.00000427) | (↓ 0.00000429) | (↓ 0.00000511) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007452   |    0.00008038   |    0.00032971   |    0.00092191   |    0.00220145   |
|         | (↓ -0.00000225) | (↓ -0.00000225) | (↓ -0.00000190) | (↓ -0.00000103) | (↓ -0.00000030) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003549   |   0.00013116   |   0.00026980   |   0.00049719   |   0.00086480   |
|         | (↓ 0.00000083) | (↓ 0.00000061) | (↓ 0.00000069) | (↓ 0.00000096) | (↓ 0.00000180) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-7 |    0.01012814   |    0.02089145   |    0.03771589   |    0.06234409   |   0.10067611   |
|         | (↓ -0.00003712) | (↓ -0.00003343) | (↓ -0.00003063) | (↓ -0.00008019) | (↓ 0.00001814) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+

2024-10-15 03:23:19,261 - block_trainer.py[357] - INFO: epoch 61 (177.052366s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
| block-0 |    0.00019598   |    0.00020398   |    0.00023361   |    0.00042893   |   0.00140935   |
|         | (↓ -0.00000177) | (↓ -0.00000099) | (↓ -0.00000094) | (↓ -0.00000035) | (↓ 0.00000148) |
+---------+-----------------+-----------------+-----------------+-----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-1 |   0.00003440   |   0.00004423   |   0.00015499   |   0.00058898   |   0.00212083   |
|         | (↓ 0.00000089) | (↓ 0.00000086) | (↓ 0.00000068) | (↓ 0.00000050) | (↓ 0.00000108) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005028   |   0.00012342   |   0.00030151   |   0.00068580   |   0.00191973   |
|         | (↓ 0.00000130) | (↓ 0.00000143) | (↓ 0.00000136) | (↓ 0.00000138) | (↓ 0.00000124) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006289   |    0.00022089   |    0.00063271   |    0.00143770   |    0.00332476   |
|         | (↓ -0.00000556) | (↓ -0.00000516) | (↓ -0.00000529) | (↓ -0.00000456) | (↓ -0.00000241) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00009081   |   0.00030700   |   0.00065724   |   0.00124718   |   0.00239346   |
|         | (↓ 0.00000251) | (↓ 0.00000266) | (↓ 0.00000283) | (↓ 0.00000308) | (↓ 0.00000255) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007150   |   0.00007736   |   0.00032725   |   0.00092023   |   0.00220019   |
|         | (↓ 0.00000302) | (↓ 0.00000302) | (↓ 0.00000246) | (↓ 0.00000169) | (↓ 0.00000126) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+-----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |       0.6       |       0.8       |
+---------+----------------+----------------+----------------+-----------------+-----------------+
| block-6 |   0.00003512   |   0.00013084   |   0.00026965   |    0.00049732   |    0.00086486   |
|         | (↓ 0.00000037) | (↓ 0.00000032) | (↓ 0.00000015) | (↓ -0.00000013) | (↓ -0.00000006) |
+---------+----------------+----------------+----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01004724   |   0.02080695   |   0.03760656   |   0.06219728   |   0.10060846   |
|         | (↓ 0.00008090) | (↓ 0.00008449) | (↓ 0.00010932) | (↓ 0.00014681) | (↓ 0.00006765) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 03:26:38,193 - block_trainer.py[357] - INFO: epoch 62 (198.929897s, 40 blocks still need training), blocks loss: 
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-0 |    0.00021012   |    0.00021986   |    0.00024996   |    0.00044548   |    0.00142492   |
|         | (↓ -0.00001414) | (↓ -0.00001589) | (↓ -0.00001635) | (↓ -0.00001655) | (↓ -0.00001558) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003522   |    0.00004508   |    0.00015555   |    0.00058947   |    0.00212123   |
|         | (↓ -0.00000082) | (↓ -0.00000085) | (↓ -0.00000056) | (↓ -0.00000049) | (↓ -0.00000040) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-2 |    0.00005464   |    0.00012754   |    0.00030528   |    0.00068917   |    0.00192157   |
|         | (↓ -0.00000436) | (↓ -0.00000412) | (↓ -0.00000377) | (↓ -0.00000337) | (↓ -0.00000183) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005929   |   0.00021758   |   0.00062906   |   0.00143404   |   0.00332193   |
|         | (↓ 0.00000361) | (↓ 0.00000331) | (↓ 0.00000365) | (↓ 0.00000366) | (↓ 0.00000284) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009463   |    0.00030998   |    0.00065928   |    0.00124830   |    0.00239434   |
|         | (↓ -0.00000381) | (↓ -0.00000298) | (↓ -0.00000205) | (↓ -0.00000113) | (↓ -0.00000087) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+----------------+----------------+----------------+
|         |       0.0       |       0.2       |      0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+----------------+----------------+----------------+
| block-5 |    0.00007187   |    0.00007775   |   0.00032682   |   0.00091987   |   0.00219986   |
|         | (↓ -0.00000037) | (↓ -0.00000039) | (↓ 0.00000043) | (↓ 0.00000035) | (↓ 0.00000032) |
+---------+-----------------+-----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-6 |    0.00003570   |    0.00013114   |    0.00026966   |   0.00049686   |   0.00086443   |
|         | (↓ -0.00000058) | (↓ -0.00000030) | (↓ -0.00000000) | (↓ 0.00000047) | (↓ 0.00000042) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-7 |    0.01027949   |    0.02104669   |    0.03783102   |    0.06246857   |    0.10087347   |
|         | (↓ -0.00023224) | (↓ -0.00023974) | (↓ -0.00022446) | (↓ -0.00027129) | (↓ -0.00026501) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+

2024-10-15 03:29:55,815 - block_trainer.py[357] - INFO: epoch 63 (197.621232s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-0 |   0.00020245   |   0.00021123   |   0.00024112   |   0.00043645   |   0.00141556   |
|         | (↓ 0.00000767) | (↓ 0.00000864) | (↓ 0.00000884) | (↓ 0.00000903) | (↓ 0.00000936) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-1 |    0.00003637   |    0.00004615   |    0.00015648   |    0.00059068   |    0.00212160   |
|         | (↓ -0.00000115) | (↓ -0.00000107) | (↓ -0.00000093) | (↓ -0.00000121) | (↓ -0.00000037) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00005102   |   0.00012420   |   0.00030249   |   0.00068696   |   0.00192066   |
|         | (↓ 0.00000362) | (↓ 0.00000334) | (↓ 0.00000279) | (↓ 0.00000221) | (↓ 0.00000091) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-3 |    0.00006045   |    0.00021851   |    0.00063044   |    0.00143574   |    0.00332431   |
|         | (↓ -0.00000117) | (↓ -0.00000093) | (↓ -0.00000138) | (↓ -0.00000170) | (↓ -0.00000239) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-4 |   0.00008973   |   0.00030615   |   0.00065587   |   0.00124596   |   0.00239180   |
|         | (↓ 0.00000490) | (↓ 0.00000382) | (↓ 0.00000341) | (↓ 0.00000234) | (↓ 0.00000254) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-5 |   0.00007061   |   0.00007642   |   0.00032608   |   0.00091973   |   0.00219943   |
|         | (↓ 0.00000126) | (↓ 0.00000133) | (↓ 0.00000074) | (↓ 0.00000015) | (↓ 0.00000044) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-6 |   0.00003436   |   0.00013023   |   0.00026929   |   0.00049671   |   0.00086441   |
|         | (↓ 0.00000134) | (↓ 0.00000091) | (↓ 0.00000037) | (↓ 0.00000015) | (↓ 0.00000002) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-7 |   0.01002437   |   0.02078082   |   0.03759773   |   0.06221624   |   0.10068238   |
|         | (↓ 0.00025511) | (↓ 0.00026587) | (↓ 0.00023329) | (↓ 0.00025233) | (↓ 0.00019109) |
+---------+----------------+----------------+----------------+----------------+----------------+

2024-10-15 03:33:09,940 - block_trainer.py[357] - INFO: epoch 64 (194.124275s, 40 blocks still need training), blocks loss: 
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-0 |   0.00020099   |   0.00021000   |   0.00023955   |   0.00043542   |    0.00141576   |
|         | (↓ 0.00000146) | (↓ 0.00000123) | (↓ 0.00000157) | (↓ 0.00000103) | (↓ -0.00000020) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+-----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |       0.8       |
+---------+----------------+----------------+----------------+----------------+-----------------+
| block-1 |   0.00003575   |   0.00004558   |   0.00015606   |   0.00059030   |    0.00212216   |
|         | (↓ 0.00000062) | (↓ 0.00000057) | (↓ 0.00000042) | (↓ 0.00000038) | (↓ -0.00000056) |
+---------+----------------+----------------+----------------+----------------+-----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-2 |   0.00004983   |   0.00012303   |   0.00030124   |   0.00068538   |   0.00191815   |
|         | (↓ 0.00000119) | (↓ 0.00000117) | (↓ 0.00000125) | (↓ 0.00000158) | (↓ 0.00000250) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+----------------+----------------+----------------+----------------+----------------+
|         |      0.0       |      0.2       |      0.4       |      0.6       |      0.8       |
+---------+----------------+----------------+----------------+----------------+----------------+
| block-3 |   0.00005957   |   0.00021765   |   0.00062940   |   0.00143447   |   0.00332218   |
|         | (↓ 0.00000088) | (↓ 0.00000086) | (↓ 0.00000104) | (↓ 0.00000128) | (↓ 0.00000213) |
+---------+----------------+----------------+----------------+----------------+----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-4 |    0.00009473   |    0.00031089   |    0.00066035   |    0.00124982   |    0.00239564   |
|         | (↓ -0.00000500) | (↓ -0.00000474) | (↓ -0.00000448) | (↓ -0.00000386) | (↓ -0.00000384) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-5 |    0.00007185   |    0.00007775   |    0.00032679   |    0.00091989   |    0.00219944   |
|         | (↓ -0.00000124) | (↓ -0.00000133) | (↓ -0.00000071) | (↓ -0.00000016) | (↓ -0.00000001) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
|         |       0.0       |       0.2       |       0.4       |       0.6       |       0.8       |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
| block-6 |    0.00003530   |    0.00013083   |    0.00026961   |    0.00049690   |    0.00086449   |
|         | (↓ -0.00000094) | (↓ -0.00000060) | (↓ -0.00000033) | (↓ -0.00000019) | (↓ -0.00000008) |
+---------+-----------------+-----------------+-----------------+-----------------+-----------------+
+---------+-----------------+-----------------+-----------------+----------------+----------------+
|         |       0.0       |       0.2       |       0.4       |      0.6       |      0.8       |
+---------+-----------------+-----------------+-----------------+----------------+----------------+
| block-7 |    0.01012514   |    0.02086369   |    0.03759882   |   0.06217749   |   0.10047995   |
|         | (↓ -0.00010077) | (↓ -0.00008286) | (↓ -0.00000109) | (↓ 0.00003876) | (↓ 0.00020243) |
+---------+-----------------+-----------------+-----------------+----------------+----------------+

2024-10-15 03:33:09,982 - server_block_profiler.py[193] - INFO: raw block info: {"index": 0, "id": "block-0", "size": 315890, "FLOPs": 151781376.0, "param": 74112.0, "input_size": [64, 32, 32], "output_size": [64, 32, 32]}
2024-10-15 03:33:09,999 - server_block_profiler.py[193] - INFO: raw block info: {"index": 1, "id": "block-1", "size": 313409, "FLOPs": 151519232.0, "param": 73984.0, "input_size": [64, 32, 32], "output_size": [64, 32, 32]}
2024-10-15 03:33:10,015 - server_block_profiler.py[193] - INFO: raw block info: {"index": 2, "id": "block-2", "size": 899539, "FLOPs": 113377280.0, "param": 221440.0, "input_size": [64, 32, 32], "output_size": [128, 16, 16]}
2024-10-15 03:33:10,032 - server_block_profiler.py[193] - INFO: raw block info: {"index": 3, "id": "block-3", "size": 1200193, "FLOPs": 151257088.0, "param": 295424.0, "input_size": [128, 16, 16], "output_size": [128, 16, 16]}
2024-10-15 03:33:10,052 - server_block_profiler.py[193] - INFO: raw block info: {"index": 4, "id": "block-4", "size": 3555795, "FLOPs": 113311744.0, "param": 885248.0, "input_size": [128, 16, 16], "output_size": [256, 8, 8]}
2024-10-15 03:33:10,075 - server_block_profiler.py[193] - INFO: raw block info: {"index": 5, "id": "block-5", "size": 4743297, "FLOPs": 151126016.0, "param": 1180672.0, "input_size": [256, 8, 8], "output_size": [256, 8, 8]}
2024-10-15 03:33:10,118 - server_block_profiler.py[193] - INFO: raw block info: {"index": 6, "id": "block-6", "size": 14176723, "FLOPs": 113278976.0, "param": 3539968.0, "input_size": [256, 8, 8], "output_size": [512, 4, 4]}
2024-10-15 03:33:10,160 - server_block_profiler.py[193] - INFO: raw block info: {"index": 7, "id": "block-7", "size": 18907265, "FLOPs": 151060480.0, "param": 4720640.0, "input_size": [512, 4, 4], "output_size": [512, 4, 4]}
2024-10-15 03:33:13,164 - server_block_profiler.py[264] - INFO: profile blocks acc drop
2024-10-15 03:33:28,200 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:33:31,095 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:33:33,738 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:33:35,614 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:33:38,498 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:33:41,192 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:33:42,882 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:33:45,459 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:33:48,168 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:33:49,859 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:33:52,407 - server_block_profiler.py[70] - INFO: get -1-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:33:54,948 - server_block_profiler.py[70] - INFO: get -1-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:33:56,739 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:08,130 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:10,760 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2024-10-15 03:34:10,761 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:34:10,762 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2024-10-15 03:34:12,676 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:15,494 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2024-10-15 03:34:18,027 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2024-10-15 03:34:19,876 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:22,486 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2024-10-15 03:34:24,879 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2024-10-15 03:34:26,754 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:29,519 - server_block_profiler.py[70] - INFO: get 2--1-2-2-2-2-2-2 metrics in cache
2024-10-15 03:34:31,978 - server_block_profiler.py[70] - INFO: get 8--1-8-8-8-8-8-8 metrics in cache
2024-10-15 03:34:31,981 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:34:31,983 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:43,575 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:46,162 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2024-10-15 03:34:46,162 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:34:46,163 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2024-10-15 03:34:47,927 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:50,632 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2024-10-15 03:34:53,475 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2024-10-15 03:34:55,410 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:34:58,144 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2024-10-15 03:35:00,766 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2024-10-15 03:35:02,426 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:04,982 - server_block_profiler.py[70] - INFO: get 2-2--1-2-2-2-2-2 metrics in cache
2024-10-15 03:35:07,705 - server_block_profiler.py[70] - INFO: get 8-8--1-8-8-8-8-8 metrics in cache
2024-10-15 03:35:07,706 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:35:07,707 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:19,581 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:22,350 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2024-10-15 03:35:22,351 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:35:22,352 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2024-10-15 03:35:24,253 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:27,130 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2024-10-15 03:35:29,614 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2024-10-15 03:35:31,469 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:34,189 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2024-10-15 03:35:36,856 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2024-10-15 03:35:38,796 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:41,614 - server_block_profiler.py[70] - INFO: get 2-2-2--1-2-2-2-2 metrics in cache
2024-10-15 03:35:44,138 - server_block_profiler.py[70] - INFO: get 8-8-8--1-8-8-8-8 metrics in cache
2024-10-15 03:35:44,138 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:35:44,139 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:56,474 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:35:59,140 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2024-10-15 03:35:59,141 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:35:59,142 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2024-10-15 03:36:01,071 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:03,860 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2024-10-15 03:36:06,819 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2024-10-15 03:36:08,701 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:12,425 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2024-10-15 03:36:16,142 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2024-10-15 03:36:17,874 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:20,471 - server_block_profiler.py[70] - INFO: get 2-2-2-2--1-2-2-2 metrics in cache
2024-10-15 03:36:22,841 - server_block_profiler.py[70] - INFO: get 8-8-8-8--1-8-8-8 metrics in cache
2024-10-15 03:36:22,842 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:36:22,842 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:34,554 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:37,200 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2024-10-15 03:36:37,201 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:36:37,201 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2024-10-15 03:36:39,169 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:41,814 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2024-10-15 03:36:44,368 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2024-10-15 03:36:46,337 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:48,953 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2024-10-15 03:36:51,395 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2024-10-15 03:36:53,226 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:36:56,034 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2--1-2-2 metrics in cache
2024-10-15 03:36:58,472 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8--1-8-8 metrics in cache
2024-10-15 03:36:58,473 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:36:58,473 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:10,279 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:13,190 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2024-10-15 03:37:13,191 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:37:13,192 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2024-10-15 03:37:15,329 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:18,367 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2024-10-15 03:37:21,075 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2024-10-15 03:37:23,270 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:26,140 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2024-10-15 03:37:28,549 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2024-10-15 03:37:30,196 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:32,680 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2--1-2 metrics in cache
2024-10-15 03:37:35,376 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8--1-8 metrics in cache
2024-10-15 03:37:35,377 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:37:35,378 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:47,451 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:50,239 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2024-10-15 03:37:50,240 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2-2 metrics in cache
2024-10-15 03:37:50,240 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2024-10-15 03:37:52,137 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:37:55,047 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2024-10-15 03:37:57,569 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2024-10-15 03:37:59,079 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:38:01,705 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2024-10-15 03:38:04,443 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2024-10-15 03:38:06,246 - server_block_profiler.py[70] - INFO: get -1--1--1--1--1--1--1--1 metrics in cache
2024-10-15 03:38:08,640 - server_block_profiler.py[70] - INFO: get 2-2-2-2-2-2-2--1 metrics in cache
2024-10-15 03:38:10,949 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8--1 metrics in cache
2024-10-15 03:38:10,950 - server_block_profiler.py[70] - INFO: get 8-8-8-8-8-8-8-8 metrics in cache
2024-10-15 03:38:10,956 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.0) acc drop: 0.0005333423614501953
2024-10-15 03:38:10,978 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:10,978 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.2) acc drop: 0.00033334891001383465
2024-10-15 03:38:10,997 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.2) size drop: 55360B (0.053MB), FLOPs drop: 28.361M, param drop: 0.014M
2024-10-15 03:38:10,997 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.4) acc drop: 0.0006666779518127441
2024-10-15 03:38:11,009 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.4) size drop: 115520B (0.110MB), FLOPs drop: 59.085M, param drop: 0.029M
2024-10-15 03:38:11,009 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.6) acc drop: 0.0007666945457458496
2024-10-15 03:38:11,021 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.6) size drop: 175680B (0.168MB), FLOPs drop: 89.809M, param drop: 0.044M
2024-10-15 03:38:11,022 - server_block_profiler.py[307] - INFO: block block-0 (sparsity 0.8) acc drop: 0.002933343251546224
2024-10-15 03:38:11,033 - server_block_profiler.py[335] - INFO: block block-0 (sparsity 0.8) size drop: 235840B (0.225MB), FLOPs drop: 120.533M, param drop: 0.059M
2024-10-15 03:38:11,035 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.0) acc drop: 6.667772928873698e-05
2024-10-15 03:38:11,056 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,056 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.2) acc drop: 0.00026667118072509766
2024-10-15 03:38:11,067 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.2) size drop: 55360B (0.053MB), FLOPs drop: 28.361M, param drop: 0.014M
2024-10-15 03:38:11,067 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.4) acc drop: 0.0006000002225240072
2024-10-15 03:38:11,078 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.4) size drop: 115520B (0.110MB), FLOPs drop: 59.085M, param drop: 0.029M
2024-10-15 03:38:11,079 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.6) acc drop: 0.002133329709370931
2024-10-15 03:38:11,089 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.6) size drop: 175680B (0.168MB), FLOPs drop: 89.809M, param drop: 0.044M
2024-10-15 03:38:11,090 - server_block_profiler.py[307] - INFO: block block-1 (sparsity 0.8) acc drop: 0.0069666703542073565
2024-10-15 03:38:11,102 - server_block_profiler.py[335] - INFO: block block-1 (sparsity 0.8) size drop: 235840B (0.225MB), FLOPs drop: 120.533M, param drop: 0.059M
2024-10-15 03:38:11,104 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.0) acc drop: 0.0022333463033040366
2024-10-15 03:38:11,115 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,116 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.2) acc drop: 0.002266685167948405
2024-10-15 03:38:11,127 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.2) size drop: 173056B (0.165MB), FLOPs drop: 22.144M, param drop: 0.043M
2024-10-15 03:38:11,127 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.4) acc drop: 0.0032999912897745767
2024-10-15 03:38:11,137 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.4) size drop: 353280B (0.337MB), FLOPs drop: 45.174M, param drop: 0.088M
2024-10-15 03:38:11,138 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.6) acc drop: 0.005533337593078613
2024-10-15 03:38:11,148 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.6) size drop: 526336B (0.502MB), FLOPs drop: 67.318M, param drop: 0.131M
2024-10-15 03:38:11,148 - server_block_profiler.py[307] - INFO: block block-2 (sparsity 0.8) acc drop: 0.0105666716893514
2024-10-15 03:38:11,155 - server_block_profiler.py[335] - INFO: block block-2 (sparsity 0.8) size drop: 706560B (0.674MB), FLOPs drop: 90.348M, param drop: 0.176M
2024-10-15 03:38:11,156 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.0) acc drop: 0.0011333425839742024
2024-10-15 03:38:11,169 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,170 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.2) acc drop: 0.0005333423614501953
2024-10-15 03:38:11,181 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.2) size drop: 230720B (0.220MB), FLOPs drop: 29.517M, param drop: 0.058M
2024-10-15 03:38:11,181 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.4) acc drop: 0.0009666681289672852
2024-10-15 03:38:11,189 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.4) size drop: 470848B (0.449MB), FLOPs drop: 60.214M, param drop: 0.118M
2024-10-15 03:38:11,189 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.6) acc drop: 0.003533323605855306
2024-10-15 03:38:11,197 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.6) size drop: 701504B (0.669MB), FLOPs drop: 89.731M, param drop: 0.175M
2024-10-15 03:38:11,197 - server_block_profiler.py[307] - INFO: block block-3 (sparsity 0.8) acc drop: 0.009966671466827393
2024-10-15 03:38:11,206 - server_block_profiler.py[335] - INFO: block block-3 (sparsity 0.8) size drop: 941632B (0.898MB), FLOPs drop: 120.429M, param drop: 0.235M
2024-10-15 03:38:11,207 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.0) acc drop: 0.004700005054473877
2024-10-15 03:38:11,219 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,219 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.2) acc drop: 0.0044666727383931475
2024-10-15 03:38:11,230 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.2) size drop: 705792B (0.673MB), FLOPs drop: 22.574M, param drop: 0.176M
2024-10-15 03:38:11,230 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.4) acc drop: 0.0055999755859375
2024-10-15 03:38:11,241 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.4) size drop: 1411584B (1.346MB), FLOPs drop: 45.148M, param drop: 0.353M
2024-10-15 03:38:11,241 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.6) acc drop: 0.009966671466827393
2024-10-15 03:38:11,248 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.6) size drop: 2117376B (2.019MB), FLOPs drop: 67.721M, param drop: 0.529M
2024-10-15 03:38:11,249 - server_block_profiler.py[307] - INFO: block block-4 (sparsity 0.8) acc drop: 0.01976664861043294
2024-10-15 03:38:11,254 - server_block_profiler.py[335] - INFO: block block-4 (sparsity 0.8) size drop: 2823168B (2.692MB), FLOPs drop: 90.295M, param drop: 0.705M
2024-10-15 03:38:11,255 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.0) acc drop: 0.0001333157221476237
2024-10-15 03:38:11,271 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,271 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.2) acc drop: 0.00023333231608072916
2024-10-15 03:38:11,284 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.2) size drop: 940928B (0.897MB), FLOPs drop: 30.094M, param drop: 0.235M
2024-10-15 03:38:11,284 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.4) acc drop: 6.667772928873698e-05
2024-10-15 03:38:11,295 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.4) size drop: 1881728B (1.795MB), FLOPs drop: 60.188M, param drop: 0.470M
2024-10-15 03:38:11,295 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.6) acc drop: 0.0016333262125651042
2024-10-15 03:38:11,304 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.6) size drop: 2822528B (2.692MB), FLOPs drop: 90.282M, param drop: 0.705M
2024-10-15 03:38:11,304 - server_block_profiler.py[307] - INFO: block block-5 (sparsity 0.8) acc drop: 0.008399983247121176
2024-10-15 03:38:11,311 - server_block_profiler.py[335] - INFO: block block-5 (sparsity 0.8) size drop: 3763328B (3.589MB), FLOPs drop: 120.376M, param drop: 0.940M
2024-10-15 03:38:11,312 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.0) acc drop: 0.00366667906443278
2024-10-15 03:38:11,358 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,358 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.2) acc drop: 0.004633347193400065
2024-10-15 03:38:11,410 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.2) size drop: 2821632B (2.691MB), FLOPs drop: 22.567M, param drop: 0.705M
2024-10-15 03:38:11,410 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.4) acc drop: 0.006200015544891357
2024-10-15 03:38:11,443 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.4) size drop: 5643264B (5.382MB), FLOPs drop: 45.135M, param drop: 1.410M
2024-10-15 03:38:11,443 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.6) acc drop: 0.010500013828277588
2024-10-15 03:38:11,472 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.6) size drop: 8492800B (8.099MB), FLOPs drop: 67.923M, param drop: 2.123M
2024-10-15 03:38:11,472 - server_block_profiler.py[307] - INFO: block block-6 (sparsity 0.8) acc drop: 0.018233338991800945
2024-10-15 03:38:11,495 - server_block_profiler.py[335] - INFO: block block-6 (sparsity 0.8) size drop: 11314432B (10.790MB), FLOPs drop: 90.490M, param drop: 2.828M
2024-10-15 03:38:11,498 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.0) acc drop: 0.0011333028475443523
2024-10-15 03:38:11,565 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.0) size drop: 0B (0.000MB), FLOPs drop: 0.000M, param drop: 0.000M
2024-10-15 03:38:11,565 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.2) acc drop: 0.0009333292643229166
2024-10-15 03:38:11,629 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.2) size drop: 3761728B (3.587MB), FLOPs drop: 30.088M, param drop: 0.940M
2024-10-15 03:38:11,630 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.4) acc drop: 0.00236666202545166
2024-10-15 03:38:11,680 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.4) size drop: 7523392B (7.175MB), FLOPs drop: 60.175M, param drop: 1.880M
2024-10-15 03:38:11,681 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.6) acc drop: 0.0054999589920043945
2024-10-15 03:38:11,702 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.6) size drop: 11322240B (10.798MB), FLOPs drop: 90.558M, param drop: 2.830M
2024-10-15 03:38:11,702 - server_block_profiler.py[307] - INFO: block block-7 (sparsity 0.8) acc drop: 0.012866655985514322
2024-10-15 03:38:11,716 - server_block_profiler.py[335] - INFO: block block-7 (sparsity 0.8) size drop: 15083904B (14.385MB), FLOPs drop: 120.645M, param drop: 3.770M
2024-10-15 03:38:11,902 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 0, "id": "block-0", "latency": 0.0008595897638797762}
2024-10-15 03:38:12,070 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 1, "id": "block-1", "latency": 0.0007281142388284204}
2024-10-15 03:38:12,208 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 2, "id": "block-2", "latency": 0.0007484582383930677}
2024-10-15 03:38:12,422 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 3, "id": "block-3", "latency": 0.0009279280027747153}
2024-10-15 03:38:12,638 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 4, "id": "block-4", "latency": 0.000540043841600418}
2024-10-15 03:38:12,970 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 5, "id": "block-5", "latency": 0.0005993283215165139}
2024-10-15 03:38:13,168 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 6, "id": "block-6", "latency": 0.000693437118530273}
2024-10-15 03:38:13,416 - edge_block_profiler.py[64] - INFO: raw block info: {"index": 7, "id": "block-7", "latency": 0.0009790403223037725}
2024-10-15 03:38:13,421 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
2024-10-15 03:38:13,426 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.0) from file
2024-10-15 03:38:13,430 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:13,433 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:13,436 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.0) from file
2024-10-15 03:38:13,454 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.0) from file
2024-10-15 03:38:13,462 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.0) from file
2024-10-15 03:38:13,473 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2024-10-15 03:38:13,486 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.0) from file
2024-10-15 03:38:14,704 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2024-10-15 03:38:14,913 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.2) latency rel drop: -26.439% (0.001s -> 0.001s)
2024-10-15 03:38:15,157 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.4) latency rel drop: -23.098% (0.001s -> 0.001s)
2024-10-15 03:38:15,470 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.6) latency rel drop: 49.050% (0.001s -> 0.000s)
2024-10-15 03:38:15,708 - edge_block_profiler.py[126] - INFO: block block-0 (sparsity 0.8) latency rel drop: 0.274% (0.001s -> 0.001s)
2024-10-15 03:38:16,036 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2024-10-15 03:38:16,268 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.2) latency rel drop: -33.793% (0.001s -> 0.001s)
2024-10-15 03:38:16,469 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.4) latency rel drop: 19.317% (0.001s -> 0.001s)
2024-10-15 03:38:16,796 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.6) latency rel drop: 49.444% (0.001s -> 0.000s)
2024-10-15 03:38:16,949 - edge_block_profiler.py[126] - INFO: block block-1 (sparsity 0.8) latency rel drop: 0.382% (0.001s -> 0.001s)
2024-10-15 03:38:17,163 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2024-10-15 03:38:17,297 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.2) latency rel drop: -15.529% (0.001s -> 0.001s)
2024-10-15 03:38:17,457 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.4) latency rel drop: -26.401% (0.001s -> 0.001s)
2024-10-15 03:38:17,560 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.6) latency rel drop: 12.679% (0.001s -> 0.000s)
2024-10-15 03:38:17,693 - edge_block_profiler.py[126] - INFO: block block-2 (sparsity 0.8) latency rel drop: 20.487% (0.001s -> 0.000s)
2024-10-15 03:38:18,150 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.0) latency rel drop: 0.000% (0.000s -> 0.000s)
2024-10-15 03:38:18,301 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.2) latency rel drop: -70.242% (0.000s -> 0.001s)
2024-10-15 03:38:18,477 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.4) latency rel drop: -79.738% (0.000s -> 0.001s)
2024-10-15 03:38:18,703 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.6) latency rel drop: -113.177% (0.000s -> 0.001s)
2024-10-15 03:38:18,912 - edge_block_profiler.py[126] - INFO: block block-3 (sparsity 0.8) latency rel drop: -48.543% (0.000s -> 0.001s)
2024-10-15 03:38:19,363 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.0) latency rel drop: 0.000% (0.000s -> 0.000s)
2024-10-15 03:38:19,490 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.2) latency rel drop: -16.850% (0.000s -> 0.000s)
2024-10-15 03:38:19,608 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.4) latency rel drop: -10.551% (0.000s -> 0.000s)
2024-10-15 03:38:19,709 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.6) latency rel drop: -9.494% (0.000s -> 0.000s)
2024-10-15 03:38:19,862 - edge_block_profiler.py[126] - INFO: block block-4 (sparsity 0.8) latency rel drop: -82.003% (0.000s -> 0.001s)
2024-10-15 03:38:20,406 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2024-10-15 03:38:20,618 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.2) latency rel drop: 30.495% (0.001s -> 0.000s)
2024-10-15 03:38:20,790 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.4) latency rel drop: -18.916% (0.001s -> 0.001s)
2024-10-15 03:38:20,938 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.6) latency rel drop: -10.387% (0.001s -> 0.001s)
2024-10-15 03:38:21,151 - edge_block_profiler.py[126] - INFO: block block-5 (sparsity 0.8) latency rel drop: -70.594% (0.001s -> 0.001s)
2024-10-15 03:38:21,827 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2024-10-15 03:38:22,000 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.2) latency rel drop: -7.339% (0.001s -> 0.001s)
2024-10-15 03:38:22,125 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.4) latency rel drop: -2.417% (0.001s -> 0.001s)
2024-10-15 03:38:22,254 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.6) latency rel drop: 17.371% (0.001s -> 0.001s)
2024-10-15 03:38:22,414 - edge_block_profiler.py[126] - INFO: block block-6 (sparsity 0.8) latency rel drop: -27.859% (0.001s -> 0.001s)
2024-10-15 03:38:23,183 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.0) latency rel drop: 0.000% (0.001s -> 0.001s)
2024-10-15 03:38:23,375 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.2) latency rel drop: 5.746% (0.001s -> 0.001s)
2024-10-15 03:38:23,593 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.4) latency rel drop: 20.034% (0.001s -> 0.001s)
2024-10-15 03:38:23,815 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.6) latency rel drop: -19.137% (0.001s -> 0.001s)
2024-10-15 03:38:24,007 - edge_block_profiler.py[126] - INFO: block block-7 (sparsity 0.8) latency rel drop: 21.403% (0.001s -> 0.001s)
2024-10-15 03:38:24,008 - optimal_runtime.py[21] - INFO: init adaptive model runtime
2024-10-15 03:38:24,022 - optimal_runtime.py[147] - INFO: load blocks metrics
2024-10-15 03:38:24,036 - optimal_runtime.py[176] - INFO: load model metrics
2024-10-15 03:38:24,040 - optimal_runtime.py[187] - INFO: load sparest blocks for initializing model
2024-10-15 03:38:24,041 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:24,045 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.8) from file
2024-10-15 03:38:24,048 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.8) from file
2024-10-15 03:38:24,051 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.8) from file
2024-10-15 03:38:24,054 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.8) from file
2024-10-15 03:38:24,058 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.8) from file
2024-10-15 03:38:24,064 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.8) from file
2024-10-15 03:38:24,069 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.8) from file
2024-10-15 03:38:24,074 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.8) from file
2024-10-15 03:38:24,255 - gen_series_legodnn_models.py[17] - INFO: min model size: 0.908MB, max model size: 43.886MB
2024-10-15 03:38:24,256 - gen_series_legodnn_models.py[28] - INFO: target model size: 0.908MB
2024-10-15 03:38:24,256 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 951737.0B (0.908MB), try to adapt blocks
2024-10-15 03:38:24,259 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:24,297 - optimal_runtime.py[77] - INFO: infer time of current model: 0.03144729614257812
2024-10-15 03:38:24,297 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013484799675643442, 0.00012390400259755554, 0.00011500799935311078, 0.00016278400039300325, 0.00017139199934899807, 0.000267295996658504, 0.0003041919928509742, 0.0005108480113558471]
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.357
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.854
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.175
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.467
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.735
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.825
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.915
2024-10-15 03:38:24,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.506
2024-10-15 03:38:24,298 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5]),)
2024-10-15 03:38:24,298 - optimal_runtime.py[116] - INFO: avg ratio: 5.389102023354572
2024-10-15 03:38:24,298 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.000903973620744092
2024-10-15 03:38:24,299 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.35218194e-04 1.24379156e-04 1.44639991e-04 1.09587057e-04
 9.41698314e-05 1.56685130e-04 2.37912853e-04 6.49960364e-04]
2024-10-15 03:38:24,302 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:24,482 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:24,483 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:24,486 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.35218194e-04 1.24379156e-04 1.44639991e-04 1.09587057e-04
 9.41698314e-05 1.56685130e-04 2.37912853e-04 6.49960364e-04]
2024-10-15 03:38:24,488 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:24,669 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:24,670 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:24,677 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.35218194e-04 1.24379156e-04 1.44639991e-04 1.09587057e-04
 9.41698314e-05 1.56685130e-04 2.37912853e-04 6.49960364e-04]
2024-10-15 03:38:24,682 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:24,873 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:24,874 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:24,882 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.6) from file
2024-10-15 03:38:24,883 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 270471040.0,
  'blocks_sparsity': [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0009806707472604687,
  'esti_test_accuracy': 0.6812333464622498,
  'is_relaxed': True,
  'model_size': 9924493.0,
  'update_swap_mem_cost': 0,
  'update_swap_time_cost': 0.008624076843261719}
2024-10-15 03:38:24,908 - gen_series_legodnn_models.py[28] - INFO: target model size: 1.342MB
2024-10-15 03:38:24,908 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 1406947.8686868688B (1.342MB), try to adapt blocks
2024-10-15 03:38:24,910 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:24,939 - optimal_runtime.py[77] - INFO: infer time of current model: 0.02424115180969238
2024-10-15 03:38:24,940 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.004547808051109314, 0.0010829759761691094, 0.0005961280018091202, 0.0006918720048852265, 0.0005032640057615936, 0.0008212160158436746, 0.00030572800361551344, 0.0010800640084780752]
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.005 = 0.188
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.340
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.998
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.992
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.953
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.245
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.900
2024-10-15 03:38:24,940 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.712
2024-10-15 03:38:24,941 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5, 7]),)
2024-10-15 03:38:24,941 - optimal_runtime.py[116] - INFO: avg ratio: 1.3802111706458864
2024-10-15 03:38:24,941 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003529609216487806
2024-10-15 03:38:24,942 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00456029 0.00214211 0.00074972 0.00046577 0.00027651 0.00048139
 0.00023911 0.00137418]
2024-10-15 03:38:24,946 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:25,204 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:25,204 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:25,207 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00456029 0.00214211 0.00074972 0.00046577 0.00027651 0.00048139
 0.00023911 0.00137418]
2024-10-15 03:38:25,209 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:25,374 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:25,374 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:25,376 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00456029 0.00214211 0.00074972 0.00046577 0.00027651 0.00048139
 0.00023911 0.00137418]
2024-10-15 03:38:25,378 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:25,548 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:25,549 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:25,549 - gen_series_legodnn_models.py[28] - INFO: target model size: 1.776MB
2024-10-15 03:38:25,549 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 1862158.7373737374B (1.776MB), try to adapt blocks
2024-10-15 03:38:25,551 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:25,619 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0606374397277832
2024-10-15 03:38:25,620 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001396480039693415, 0.0001337599970865995, 0.00033942400151863695, 0.00036326400074176485, 0.00016950399801135064, 0.000272479995386675, 0.00030633599311113356, 0.0005184639885555954]
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.139
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 2.752
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.753
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.794
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.799
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.752
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.894
2024-10-15 03:38:25,620 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.484
2024-10-15 03:38:25,621 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 5, 6]),)
2024-10-15 03:38:25,621 - optimal_runtime.py[116] - INFO: avg ratio: 3.298241687260665
2024-10-15 03:38:25,621 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.001477031258026827
2024-10-15 03:38:25,621 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.40031378e-04 2.64575448e-04 4.26877130e-04 2.44551262e-04
 9.31324856e-05 1.59723917e-04 2.39589706e-04 6.59650297e-04]
2024-10-15 03:38:25,623 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:25,784 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:25,784 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:25,786 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.40031378e-04 2.64575448e-04 4.26877130e-04 2.44551262e-04
 9.31324856e-05 1.59723917e-04 2.39589706e-04 6.59650297e-04]
2024-10-15 03:38:25,788 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:25,969 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:25,969 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:25,971 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.40031378e-04 2.64575448e-04 4.26877130e-04 2.44551262e-04
 9.31324856e-05 1.59723917e-04 2.39589706e-04 6.59650297e-04]
2024-10-15 03:38:25,973 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:26,202 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:26,203 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:26,204 - gen_series_legodnn_models.py[28] - INFO: target model size: 2.210MB
2024-10-15 03:38:26,204 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 2317369.606060606B (2.210MB), try to adapt blocks
2024-10-15 03:38:26,208 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:26,246 - optimal_runtime.py[77] - INFO: infer time of current model: 0.03133030319213867
2024-10-15 03:38:26,246 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.006706496190279723, 0.0003920959974639118, 0.00035952000040560963, 0.0002886719955131411, 0.00034809601446613667, 0.0006330559886991978, 0.0004843199970200658, 0.0008373760338872673]
2024-10-15 03:38:26,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.007 = 0.128
2024-10-15 03:38:26,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 0.939
2024-10-15 03:38:26,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.655
2024-10-15 03:38:26,247 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.775
2024-10-15 03:38:26,248 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.824
2024-10-15 03:38:26,248 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.615
2024-10-15 03:38:26,248 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.831
2024-10-15 03:38:26,249 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.919
2024-10-15 03:38:26,249 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:26,250 - optimal_runtime.py[116] - INFO: avg ratio: 1.6304041398913587
2024-10-15 03:38:26,250 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002987974545339269
2024-10-15 03:38:26,251 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00672491 0.00077556 0.00045215 0.00019434 0.00019126 0.00037109
 0.00037879 0.00106541]
2024-10-15 03:38:26,254 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:26,443 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:26,444 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:26,446 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00672491 0.00077556 0.00045215 0.00019434 0.00019126 0.00037109
 0.00037879 0.00106541]
2024-10-15 03:38:26,448 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:26,609 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:26,609 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:26,616 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00672491 0.00077556 0.00045215 0.00019434 0.00019126 0.00037109
 0.00037879 0.00106541]
2024-10-15 03:38:26,619 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:26,785 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:26,786 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:26,787 - gen_series_legodnn_models.py[28] - INFO: target model size: 2.644MB
2024-10-15 03:38:26,787 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 2772580.474747475B (2.644MB), try to adapt blocks
2024-10-15 03:38:26,791 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:26,814 - optimal_runtime.py[77] - INFO: infer time of current model: 0.015520031929016114
2024-10-15 03:38:26,814 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0003284799973480403, 0.00013567999517545104, 0.00012707200273871422, 0.0004005759945139288, 0.00017327999812550844, 0.0002771199969574809, 0.00031168000120669604, 0.0005314240059815347]
2024-10-15 03:38:26,814 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.610
2024-10-15 03:38:26,814 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 2.713
2024-10-15 03:38:26,814 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.683
2024-10-15 03:38:26,815 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.441
2024-10-15 03:38:26,815 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.672
2024-10-15 03:38:26,815 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.689
2024-10-15 03:38:26,815 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.845
2024-10-15 03:38:26,815 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.448
2024-10-15 03:38:26,815 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 5, 6]),)
2024-10-15 03:38:26,815 - optimal_runtime.py[116] - INFO: avg ratio: 3.059568942022134
2024-10-15 03:38:26,815 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0015922524253993101
2024-10-15 03:38:26,816 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [3.29381770e-04 2.68373178e-04 1.59812304e-04 2.69669895e-04
 9.52071758e-05 1.62443820e-04 2.43769331e-04 6.76139542e-04]
2024-10-15 03:38:26,817 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:27,001 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:27,001 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:27,008 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [3.29381770e-04 2.68373178e-04 1.59812304e-04 2.69669895e-04
 9.52071758e-05 1.62443820e-04 2.43769331e-04 6.76139542e-04]
2024-10-15 03:38:27,011 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:27,175 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:27,175 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:27,181 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [3.29381770e-04 2.68373178e-04 1.59812304e-04 2.69669895e-04
 9.52071758e-05 1.62443820e-04 2.43769331e-04 6.76139542e-04]
2024-10-15 03:38:27,185 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:27,442 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:27,443 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:27,443 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.078MB
2024-10-15 03:38:27,443 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 3227791.3434343436B (3.078MB), try to adapt blocks
2024-10-15 03:38:27,446 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:27,471 - optimal_runtime.py[77] - INFO: infer time of current model: 0.018118911743164063
2024-10-15 03:38:27,471 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00026755200210027395, 0.0001219840010162443, 0.00011788800172507762, 0.0002864000035915524, 0.00032342399656772617, 0.0005129920095205307, 0.00045244799181818956, 0.0007455040030181408]
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.204
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 3.018
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.048
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.813
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.039
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.993
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.960
2024-10-15 03:38:27,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.032
2024-10-15 03:38:27,472 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5, 6]),)
2024-10-15 03:38:27,472 - optimal_runtime.py[116] - INFO: avg ratio: 2.642674246014554
2024-10-15 03:38:27,472 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0018434379780096115
2024-10-15 03:38:27,473 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00026829 0.00024128 0.00014826 0.00019281 0.0001777  0.00030071
 0.00035387 0.00094852]
2024-10-15 03:38:27,475 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:27,630 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:27,631 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:27,633 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00026829 0.00024128 0.00014826 0.00019281 0.0001777  0.00030071
 0.00035387 0.00094852]
2024-10-15 03:38:27,634 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:27,792 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:27,793 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:27,800 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00026829 0.00024128 0.00014826 0.00019281 0.0001777  0.00030071
 0.00035387 0.00094852]
2024-10-15 03:38:27,802 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:27,969 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:27,970 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:27,971 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.512MB
2024-10-15 03:38:27,971 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 3683002.212121212B (3.512MB), try to adapt blocks
2024-10-15 03:38:27,977 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:27,999 - optimal_runtime.py[77] - INFO: infer time of current model: 0.016898431777954102
2024-10-15 03:38:28,000 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0004911999984178693, 0.00013894399954006076, 0.00011363199818879365, 0.0003552000056952238, 0.0003596479918342084, 0.00045967999240383505, 0.0003129599913954735, 0.0005104639893397689]
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.745
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 2.649
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.237
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.881
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.733
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.224
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.833
2024-10-15 03:38:28,000 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.507
2024-10-15 03:38:28,001 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 4, 5, 6]),)
2024-10-15 03:38:28,001 - optimal_runtime.py[116] - INFO: avg ratio: 2.677537561447713
2024-10-15 03:38:28,001 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0018194351925270935
2024-10-15 03:38:28,001 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00049255 0.00027483 0.00014291 0.00023912 0.00019761 0.00026946
 0.00024477 0.00064947]
2024-10-15 03:38:28,003 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:28,175 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:28,175 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:28,177 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00049255 0.00027483 0.00014291 0.00023912 0.00019761 0.00026946
 0.00024477 0.00064947]
2024-10-15 03:38:28,179 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:28,342 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:28,342 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:28,344 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00049255 0.00027483 0.00014291 0.00023912 0.00019761 0.00026946
 0.00024477 0.00064947]
2024-10-15 03:38:28,346 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:28,625 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:28,626 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:28,626 - gen_series_legodnn_models.py[28] - INFO: target model size: 3.947MB
2024-10-15 03:38:28,626 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 4138213.0808080807B (3.947MB), try to adapt blocks
2024-10-15 03:38:28,630 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:28,657 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0190296630859375
2024-10-15 03:38:28,658 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007077759942039848, 0.0009581759907305241, 0.0003277760129421949, 0.00041459200624376536, 0.0005500480071641505, 0.0007411839962005616, 0.0005064959852024912, 0.0010416000070981681]
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.211
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.384
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.816
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.325
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.787
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.379
2024-10-15 03:38:28,658 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.750
2024-10-15 03:38:28,659 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.739
2024-10-15 03:38:28,659 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:28,659 - optimal_runtime.py[116] - INFO: avg ratio: 1.447073005858161
2024-10-15 03:38:28,659 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0033665240446677566
2024-10-15 03:38:28,660 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070972 0.00189526 0.00041223 0.00027911 0.00030222 0.00043447
 0.00039614 0.00132524]
2024-10-15 03:38:28,663 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:28,847 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:28,848 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:28,850 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070972 0.00189526 0.00041223 0.00027911 0.00030222 0.00043447
 0.00039614 0.00132524]
2024-10-15 03:38:28,851 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:29,014 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:29,015 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:29,022 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00070972 0.00189526 0.00041223 0.00027911 0.00030222 0.00043447
 0.00039614 0.00132524]
2024-10-15 03:38:29,025 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:29,187 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:29,188 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:29,188 - gen_series_legodnn_models.py[28] - INFO: target model size: 4.381MB
2024-10-15 03:38:29,189 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 4593423.94949495B (4.381MB), try to adapt blocks
2024-10-15 03:38:29,192 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:29,220 - optimal_runtime.py[77] - INFO: infer time of current model: 0.021127872467041016
2024-10-15 03:38:29,221 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0012513600140810013, 0.0010224960315972566, 0.00030803199764341114, 0.0008721279995515943, 0.0005662720263935625, 0.0005273600011132657, 0.00046822400530800224, 0.0010632639818359167]
2024-10-15 03:38:29,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.685
2024-10-15 03:38:29,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.360
2024-10-15 03:38:29,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.932
2024-10-15 03:38:29,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.580
2024-10-15 03:38:29,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.736
2024-10-15 03:38:29,221 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.939
2024-10-15 03:38:29,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.894
2024-10-15 03:38:29,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.724
2024-10-15 03:38:29,222 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5, 6]),)
2024-10-15 03:38:29,222 - optimal_runtime.py[116] - INFO: avg ratio: 1.8161104781981727
2024-10-15 03:38:29,223 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0026824392717806666
2024-10-15 03:38:29,223 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0012548  0.00202248 0.0003874  0.00058712 0.00031113 0.00030913
 0.0003662  0.00135281]
2024-10-15 03:38:29,226 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:29,408 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:29,408 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:29,411 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0012548  0.00202248 0.0003874  0.00058712 0.00031113 0.00030913
 0.0003662  0.00135281]
2024-10-15 03:38:29,412 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:29,676 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:29,677 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:29,681 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0012548  0.00202248 0.0003874  0.00058712 0.00031113 0.00030913
 0.0003662  0.00135281]
2024-10-15 03:38:29,684 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:29,853 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:29,855 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:29,856 - gen_series_legodnn_models.py[28] - INFO: target model size: 4.815MB
2024-10-15 03:38:29,856 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5048634.818181818B (4.815MB), try to adapt blocks
2024-10-15 03:38:29,860 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:29,897 - optimal_runtime.py[77] - INFO: infer time of current model: 0.03201433563232422
2024-10-15 03:38:29,898 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001229760004207492, 0.00013331200089305637, 0.000267040001694113, 0.00022057599877007306, 0.00020534399710595607, 0.0005999359940178692, 0.000450047992169857, 0.0007179519948549569]
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.971
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 2.761
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.229
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.249
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.787
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.704
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.970
2024-10-15 03:38:29,898 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.072
2024-10-15 03:38:29,899 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6]),)
2024-10-15 03:38:29,899 - optimal_runtime.py[116] - INFO: avg ratio: 2.6901412499465414
2024-10-15 03:38:29,899 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0018109108838459515
2024-10-15 03:38:29,899 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012331 0.00026369 0.00033584 0.00014849 0.00011282 0.00035167
 0.00035199 0.00091346]
2024-10-15 03:38:29,901 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:30,062 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:30,062 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:30,065 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012331 0.00026369 0.00033584 0.00014849 0.00011282 0.00035167
 0.00035199 0.00091346]
2024-10-15 03:38:30,066 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:30,226 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:30,227 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:30,230 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012331 0.00026369 0.00033584 0.00014849 0.00011282 0.00035167
 0.00035199 0.00091346]
2024-10-15 03:38:30,231 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:30,403 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:30,404 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:30,404 - gen_series_legodnn_models.py[28] - INFO: target model size: 5.249MB
2024-10-15 03:38:30,404 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5503845.686868687B (5.249MB), try to adapt blocks
2024-10-15 03:38:30,406 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:30,424 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012318304061889648
2024-10-15 03:38:30,424 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0009796479865908623, 0.0006967360004782677, 0.00038422400504350664, 0.00040128000080585485, 0.0003246400021016598, 0.0005048320069909096, 0.0004404160045087338, 0.0007506880015134812]
2024-10-15 03:38:30,424 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.875
2024-10-15 03:38:30,424 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.528
2024-10-15 03:38:30,424 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.549
2024-10-15 03:38:30,424 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.435
2024-10-15 03:38:30,425 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.028
2024-10-15 03:38:30,425 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.025
2024-10-15 03:38:30,425 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.013
2024-10-15 03:38:30,425 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.025
2024-10-15 03:38:30,425 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 5, 6, 7]),)
2024-10-15 03:38:30,425 - optimal_runtime.py[116] - INFO: avg ratio: 1.4974806089001784
2024-10-15 03:38:30,425 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003253201436904806
2024-10-15 03:38:30,426 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00098234 0.00137813 0.00048322 0.00027014 0.00017837 0.00029593
 0.00034446 0.00095511]
2024-10-15 03:38:30,427 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:30,609 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:30,609 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:30,614 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00098234 0.00137813 0.00048322 0.00027014 0.00017837 0.00029593
 0.00034446 0.00095511]
2024-10-15 03:38:30,617 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:30,864 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:30,864 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:30,872 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00098234 0.00137813 0.00048322 0.00027014 0.00017837 0.00029593
 0.00034446 0.00095511]
2024-10-15 03:38:30,874 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:31,038 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:31,039 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:31,039 - gen_series_legodnn_models.py[28] - INFO: target model size: 5.683MB
2024-10-15 03:38:31,039 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 5959056.555555556B (5.683MB), try to adapt blocks
2024-10-15 03:38:31,041 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:31,070 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0199998722076416
2024-10-15 03:38:31,070 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001348159967456013, 0.00013660800084471701, 0.000645984006114304, 0.0003171839942224324, 0.0005275839902460576, 0.0006231040060520172, 0.0004419519943185151, 0.0009027840099297464]
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.359
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 2.695
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.921
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.346
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.863
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.641
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.006
2024-10-15 03:38:31,071 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.852
2024-10-15 03:38:31,071 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6, 7]),)
2024-10-15 03:38:31,071 - optimal_runtime.py[116] - INFO: avg ratio: 2.046274912833677
2024-10-15 03:38:31,071 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0023807192464989735
2024-10-15 03:38:31,072 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00013519 0.00027021 0.00081242 0.00021353 0.00028988 0.00036525
 0.00034566 0.00114863]
2024-10-15 03:38:31,074 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:31,236 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:31,236 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:31,238 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00013519 0.00027021 0.00081242 0.00021353 0.00028988 0.00036525
 0.00034566 0.00114863]
2024-10-15 03:38:31,240 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:31,405 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:31,406 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:31,412 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00013519 0.00027021 0.00081242 0.00021353 0.00028988 0.00036525
 0.00034566 0.00114863]
2024-10-15 03:38:31,415 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:31,581 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:31,583 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:31,584 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.117MB
2024-10-15 03:38:31,584 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 6414267.424242424B (6.117MB), try to adapt blocks
2024-10-15 03:38:31,589 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:31,606 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010989664077758789
2024-10-15 03:38:31,606 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.001385983996093273, 0.00040278399363160135, 0.0002945280037820339, 0.0004113919958472252, 0.00032742400839924814, 0.0005009599998593331, 0.000452928002923727, 0.0007399039939045906]
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.619
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 0.914
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.021
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.351
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.002
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.041
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.958
2024-10-15 03:38:31,607 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.040
2024-10-15 03:38:31,607 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 5, 6, 7]),)
2024-10-15 03:38:31,607 - optimal_runtime.py[116] - INFO: avg ratio: 1.764760660129626
2024-10-15 03:38:31,607 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0027604910845266195
2024-10-15 03:38:31,608 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00138979 0.0007967  0.00037041 0.00027695 0.0001799  0.00029366
 0.00035424 0.00094139]
2024-10-15 03:38:31,610 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:31,865 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:31,865 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:31,869 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00138979 0.0007967  0.00037041 0.00027695 0.0001799  0.00029366
 0.00035424 0.00094139]
2024-10-15 03:38:31,872 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:32,032 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:32,033 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:32,035 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00138979 0.0007967  0.00037041 0.00027695 0.0001799  0.00029366
 0.00035424 0.00094139]
2024-10-15 03:38:32,037 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:32,201 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:32,202 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:32,203 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.551MB
2024-10-15 03:38:32,203 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 6869478.292929293B (6.551MB), try to adapt blocks
2024-10-15 03:38:32,207 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:32,319 - optimal_runtime.py[77] - INFO: infer time of current model: 0.10152790069580078
2024-10-15 03:38:32,319 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00012271999847143886, 0.00014064000034704803, 0.00014825599640607833, 0.00033007999649271364, 0.0001805440024472773, 0.0002950400048866868, 0.0003131839935667813, 0.0005233919844031333]
2024-10-15 03:38:32,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.985
2024-10-15 03:38:32,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 2.617
2024-10-15 03:38:32,320 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.014
2024-10-15 03:38:32,320 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.176
2024-10-15 03:38:32,320 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.444
2024-10-15 03:38:32,320 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.465
2024-10-15 03:38:32,320 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.831
2024-10-15 03:38:32,320 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.470
2024-10-15 03:38:32,320 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6]),)
2024-10-15 03:38:32,320 - optimal_runtime.py[116] - INFO: avg ratio: 3.7579749594113925
2024-10-15 03:38:32,320 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0012963380866630838
2024-10-15 03:38:32,321 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.23056900e-04 2.78184001e-04 1.86454387e-04 2.22211613e-04
 9.91983192e-05 1.72948275e-04 2.44945624e-04 6.65920268e-04]
2024-10-15 03:38:32,322 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:32,496 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:32,497 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:32,504 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.23056900e-04 2.78184001e-04 1.86454387e-04 2.22211613e-04
 9.91983192e-05 1.72948275e-04 2.44945624e-04 6.65920268e-04]
2024-10-15 03:38:32,506 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:32,675 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:32,676 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:32,678 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.23056900e-04 2.78184001e-04 1.86454387e-04 2.22211613e-04
 9.91983192e-05 1.72948275e-04 2.44945624e-04 6.65920268e-04]
2024-10-15 03:38:32,680 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:32,869 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:32,870 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:32,871 - gen_series_legodnn_models.py[28] - INFO: target model size: 6.985MB
2024-10-15 03:38:32,871 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 7324689.161616161B (6.985MB), try to adapt blocks
2024-10-15 03:38:32,882 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:32,934 - optimal_runtime.py[77] - INFO: infer time of current model: 0.04039680099487305
2024-10-15 03:38:32,934 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000908608004450798, 0.0005728959999978542, 0.0004466240033507347, 0.0006528000012040139, 0.00046956799924373626, 0.0007221439853310586, 0.0009369279965758324, 0.000947007991373539]
2024-10-15 03:38:32,934 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.943
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.643
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.332
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.111
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.093
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.416
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.946
2024-10-15 03:38:32,935 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.813
2024-10-15 03:38:32,936 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 5, 6, 7]),)
2024-10-15 03:38:32,936 - optimal_runtime.py[116] - INFO: avg ratio: 1.0901248975172577
2024-10-15 03:38:32,936 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004468851302915978
2024-10-15 03:38:32,937 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0009111  0.00113318 0.0005617  0.00043947 0.000258   0.00042331
 0.00073278 0.00120489]
2024-10-15 03:38:32,941 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:33,158 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:33,158 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:33,160 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0009111  0.00113318 0.0005617  0.00043947 0.000258   0.00042331
 0.00073278 0.00120489]
2024-10-15 03:38:33,162 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:33,321 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:33,322 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:33,329 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0009111  0.00113318 0.0005617  0.00043947 0.000258   0.00042331
 0.00073278 0.00120489]
2024-10-15 03:38:33,332 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:33,510 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:33,511 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:33,511 - gen_series_legodnn_models.py[28] - INFO: target model size: 7.419MB
2024-10-15 03:38:33,511 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 7779900.03030303B (7.419MB), try to adapt blocks
2024-10-15 03:38:33,513 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:33,531 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013082304000854493
2024-10-15 03:38:33,531 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0009527359977364539, 0.0006652159988880157, 0.00044240000098943707, 0.0006457279920578003, 0.00040908799320459364, 0.0005224640034139157, 0.0004586240015923977, 0.0007538559883832932]
2024-10-15 03:38:33,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.900
2024-10-15 03:38:33,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.553
2024-10-15 03:38:33,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.345
2024-10-15 03:38:33,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.135
2024-10-15 03:38:33,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.403
2024-10-15 03:38:33,531 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.957
2024-10-15 03:38:33,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.933
2024-10-15 03:38:33,532 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.021
2024-10-15 03:38:33,532 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 5, 6, 7]),)
2024-10-15 03:38:33,532 - optimal_runtime.py[116] - INFO: avg ratio: 1.6781397938906282
2024-10-15 03:38:33,532 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029029798866259697
2024-10-15 03:38:33,533 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00095535 0.00131579 0.00055639 0.00043471 0.00022477 0.00030626
 0.0003587  0.00095914]
2024-10-15 03:38:33,534 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:33,699 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:33,700 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:33,706 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00095535 0.00131579 0.00055639 0.00043471 0.00022477 0.00030626
 0.0003587  0.00095914]
2024-10-15 03:38:33,710 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:33,888 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:33,889 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:33,897 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00095535 0.00131579 0.00055639 0.00043471 0.00022477 0.00030626
 0.0003587  0.00095914]
2024-10-15 03:38:33,900 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:34,159 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:34,160 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:34,160 - gen_series_legodnn_models.py[28] - INFO: target model size: 7.854MB
2024-10-15 03:38:34,160 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 8235110.898989899B (7.854MB), try to adapt blocks
2024-10-15 03:38:34,162 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:34,176 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009971743583679199
2024-10-15 03:38:34,176 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006740479781292379, 0.00030704000266268844, 0.00027849600091576577, 0.0005967360178474337, 0.00033868799358606336, 0.0005383679978549481, 0.00045884799957275385, 0.0006287040116731078]
2024-10-15 03:38:34,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.272
2024-10-15 03:38:34,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.199
2024-10-15 03:38:34,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.137
2024-10-15 03:38:34,176 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.310
2024-10-15 03:38:34,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.902
2024-10-15 03:38:34,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.899
2024-10-15 03:38:34,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.932
2024-10-15 03:38:34,177 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.224
2024-10-15 03:38:34,177 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 5, 6]),)
2024-10-15 03:38:34,177 - optimal_runtime.py[116] - INFO: avg ratio: 2.0695389100441104
2024-10-15 03:38:34,177 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002353957224465671
2024-10-15 03:38:34,178 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006759  0.00060732 0.00035025 0.00040173 0.00018609 0.00031558
 0.00035887 0.00079991]
2024-10-15 03:38:34,179 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:34,342 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:34,342 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:34,345 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006759  0.00060732 0.00035025 0.00040173 0.00018609 0.00031558
 0.00035887 0.00079991]
2024-10-15 03:38:34,346 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:34,503 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:34,504 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:34,506 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0006759  0.00060732 0.00035025 0.00040173 0.00018609 0.00031558
 0.00035887 0.00079991]
2024-10-15 03:38:34,508 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:34,669 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:34,669 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:34,670 - gen_series_legodnn_models.py[28] - INFO: target model size: 8.288MB
2024-10-15 03:38:34,670 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 8690321.767676767B (8.288MB), try to adapt blocks
2024-10-15 03:38:34,671 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:34,690 - optimal_runtime.py[77] - INFO: infer time of current model: 0.014453887939453125
2024-10-15 03:38:34,690 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007651199894025923, 0.0007468160092830658, 0.0004941760003566743, 0.0006823040023446083, 0.00047756798565387723, 0.0006958080045878887, 0.0004649280048906803, 0.0007426559999585151]
2024-10-15 03:38:34,690 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.120
2024-10-15 03:38:34,690 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.493
2024-10-15 03:38:34,690 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.204
2024-10-15 03:38:34,690 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.020
2024-10-15 03:38:34,691 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.058
2024-10-15 03:38:34,691 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.469
2024-10-15 03:38:34,691 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.907
2024-10-15 03:38:34,691 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.036
2024-10-15 03:38:34,691 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 5, 6, 7]),)
2024-10-15 03:38:34,691 - optimal_runtime.py[116] - INFO: avg ratio: 1.34744205438189
2024-10-15 03:38:34,691 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0036154475457914137
2024-10-15 03:38:34,692 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076722 0.00147719 0.0006215  0.00045933 0.0002624  0.00040787
 0.00036363 0.00094489]
2024-10-15 03:38:34,693 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:34,861 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:34,861 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:34,868 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076722 0.00147719 0.0006215  0.00045933 0.0002624  0.00040787
 0.00036363 0.00094489]
2024-10-15 03:38:34,871 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:35,032 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:35,032 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:35,034 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00076722 0.00147719 0.0006215  0.00045933 0.0002624  0.00040787
 0.00036363 0.00094489]
2024-10-15 03:38:35,036 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:35,292 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:35,293 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:35,294 - gen_series_legodnn_models.py[28] - INFO: target model size: 8.722MB
2024-10-15 03:38:35,294 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 9145532.636363637B (8.722MB), try to adapt blocks
2024-10-15 03:38:35,298 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:35,317 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012946880340576172
2024-10-15 03:38:35,318 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000814815990626812, 0.0005571520067751408, 0.00038963199406862265, 0.0005534720048308373, 0.0004291519932448864, 0.000686400018632412, 0.0005956159979104995, 0.0008744640052318573]
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.052
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.661
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.527
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.490
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.290
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.490
2024-10-15 03:38:35,318 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.489
2024-10-15 03:38:35,319 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.880
2024-10-15 03:38:35,319 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 5, 6]),)
2024-10-15 03:38:35,319 - optimal_runtime.py[116] - INFO: avg ratio: 1.389393854096546
2024-10-15 03:38:35,319 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035062815732540492
2024-10-15 03:38:35,320 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00081705 0.00110204 0.00049002 0.0003726  0.00023579 0.00040236
 0.00046584 0.00111259]
2024-10-15 03:38:35,323 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:35,538 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:35,539 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:35,544 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00081705 0.00110204 0.00049002 0.0003726  0.00023579 0.00040236
 0.00046584 0.00111259]
2024-10-15 03:38:35,547 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:35,706 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:35,707 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:35,713 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00081705 0.00110204 0.00049002 0.0003726  0.00023579 0.00040236
 0.00046584 0.00111259]
2024-10-15 03:38:35,716 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:35,885 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:35,887 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:35,888 - gen_series_legodnn_models.py[28] - INFO: target model size: 9.156MB
2024-10-15 03:38:35,888 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 9600743.505050505B (9.156MB), try to adapt blocks
2024-10-15 03:38:35,892 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:35,911 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01062502384185791
2024-10-15 03:38:35,911 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006153600066900254, 0.0004407040029764176, 0.0005935679934918881, 0.00042550399899482727, 0.0005195840075612069, 0.0004065600018948317, 0.000459391999989748, 0.0007660160039085895]
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.393
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 0.835
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.003
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.239
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.892
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.515
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.930
2024-10-15 03:38:35,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.005
2024-10-15 03:38:35,912 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 6, 7]),)
2024-10-15 03:38:35,912 - optimal_runtime.py[116] - INFO: avg ratio: 1.4443817163507702
2024-10-15 03:38:35,912 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003372796826118275
2024-10-15 03:38:35,912 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061705 0.00087171 0.0007465  0.00028645 0.00028548 0.00023832
 0.0003593  0.00097461]
2024-10-15 03:38:35,914 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:36,078 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:36,079 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9863821B (9.407MB) and continue finding solution
2024-10-15 03:38:36,084 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061705 0.00087171 0.0007465  0.00028645 0.00028548 0.00023832
 0.0003593  0.00097461]
2024-10-15 03:38:36,088 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:36,244 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:36,245 - optimal_runtime.py[312] - INFO: no solution found, relax the memory constraint to 9968678.6B (9.507MB) and continue finding solution
2024-10-15 03:38:36,252 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061705 0.00087171 0.0007465  0.00028645 0.00028548 0.00023832
 0.0003593  0.00097461]
2024-10-15 03:38:36,255 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:36,546 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:36,548 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.8, 0.6, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:36,548 - gen_series_legodnn_models.py[28] - INFO: target model size: 9.590MB
2024-10-15 03:38:36,548 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10055954.373737374B (9.590MB), try to adapt blocks
2024-10-15 03:38:36,552 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:36,570 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009717215538024902
2024-10-15 03:38:36,570 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0004542079968377948, 0.00041500799357891083, 0.00028140799701213833, 0.0004010239988565445, 0.00032144000008702277, 0.0005337600037455559, 0.0004691839925944805, 0.0007737280018627644]
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.887
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 0.887
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.115
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.437
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.058
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.916
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.890
2024-10-15 03:38:36,570 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.995
2024-10-15 03:38:36,571 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 5, 6]),)
2024-10-15 03:38:36,571 - optimal_runtime.py[116] - INFO: avg ratio: 1.9518345427897235
2024-10-15 03:38:36,571 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0024959113909564495
2024-10-15 03:38:36,571 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00045545 0.00082088 0.00035391 0.00026997 0.00017661 0.00031288
 0.00036696 0.00098443]
2024-10-15 03:38:36,573 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:36,747 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:36,748 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:36,806 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:36,855 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2024-10-15 03:38:36,855 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 331919232.0,
  'blocks_sparsity': [0.6, 0.4, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.002429726330954195,
  'esti_test_accuracy': 0.6849333246548971,
  'is_relaxed': False,
  'model_size': 10044813.0,
  'update_swap_mem_cost': 555878.0,
  'update_swap_time_cost': 0.10686206817626953}
2024-10-15 03:38:36,879 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.024MB
2024-10-15 03:38:36,879 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10511165.242424242B (10.024MB), try to adapt blocks
2024-10-15 03:38:36,881 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:36,908 - optimal_runtime.py[77] - INFO: infer time of current model: 0.020116319656372072
2024-10-15 03:38:36,908 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013331199903041124, 0.00013635200308635833, 0.00011459200317040086, 0.00034204800007864837, 0.00017782399710267782, 0.00027353599248453975, 0.0003113919945899397, 0.0005203519915230572]
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 3.285
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.308
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.193
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.030
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.527
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.738
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.847
2024-10-15 03:38:36,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.479
2024-10-15 03:38:36,909 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 3, 5, 6]),)
2024-10-15 03:38:36,909 - optimal_runtime.py[116] - INFO: avg ratio: 3.64170603483606
2024-10-15 03:38:36,909 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0013377263354070947
2024-10-15 03:38:36,909 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [2.61651627e-04 1.68996644e-04 1.44116813e-04 2.30268537e-04
 9.77038362e-05 1.60342927e-04 2.43544077e-04 6.62052435e-04]
2024-10-15 03:38:36,911 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:37,082 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:37,084 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:37,092 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2024-10-15 03:38:37,100 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.6) from file
2024-10-15 03:38:37,101 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 385646464.0,
  'blocks_sparsity': [0.6, 0.4, 0.6, 0.6, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.001538540147524199,
  'esti_test_accuracy': 0.696400006612142,
  'is_relaxed': False,
  'model_size': 10465165.0,
  'update_swap_mem_cost': 1323432.0,
  'update_swap_time_cost': 0.016374826431274414}
2024-10-15 03:38:37,122 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.458MB
2024-10-15 03:38:37,122 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 10966376.111111112B (10.458MB), try to adapt blocks
2024-10-15 03:38:37,124 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:37,138 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01021951961517334
2024-10-15 03:38:37,138 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00043756800657138227, 0.000389759998768568, 0.0012119360156357289, 0.0004266880005598068, 0.0003197440057992935, 0.0005281920060515404, 0.00045488000288605685, 0.0007529600150883198]
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.001
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.507
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.539
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.636
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.074
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.936
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.949
2024-10-15 03:38:37,138 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.022
2024-10-15 03:38:37,139 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5, 6, 7]),)
2024-10-15 03:38:37,139 - optimal_runtime.py[116] - INFO: avg ratio: 1.7481579962596279
2024-10-15 03:38:37,139 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0027867081116434954
2024-10-15 03:38:37,139 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00085882 0.00048307 0.00138791 0.00020016 0.00017568 0.00030962
 0.00035577 0.000958  ]
2024-10-15 03:38:37,141 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:37,316 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:37,318 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.2, 0.4, 0.4, 0.8, 0.8, 0.8, 0.8]
2024-10-15 03:38:37,329 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:37,334 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.4) from file
2024-10-15 03:38:37,340 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:37,341 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 468031360.0,
  'blocks_sparsity': [0.6, 0.2, 0.4, 0.4, 0.8, 0.8, 0.8, 0.8],
  'esti_latency': 0.0033114324231201453,
  'esti_test_accuracy': 0.7015333374341329,
  'is_relaxed': False,
  'model_size': 10929037.0,
  'update_swap_mem_cost': 2603434.0,
  'update_swap_time_cost': 0.022878408432006836}
2024-10-15 03:38:37,362 - gen_series_legodnn_models.py[28] - INFO: target model size: 10.892MB
2024-10-15 03:38:37,362 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 11421586.97979798B (10.892MB), try to adapt blocks
2024-10-15 03:38:37,364 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:37,396 - optimal_runtime.py[77] - INFO: infer time of current model: 0.028106847763061524
2024-10-15 03:38:37,396 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.003045151993632317, 0.0004341759877279401, 0.0003268159935250879, 0.0001972799994982779, 0.0001712640030309558, 0.000271712000714615, 0.00031424000579863786, 0.0005120320001151413]
2024-10-15 03:38:37,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.003 = 0.144
2024-10-15 03:38:37,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.244
2024-10-15 03:38:37,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.895
2024-10-15 03:38:37,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 8.454
2024-10-15 03:38:37,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.739
2024-10-15 03:38:37,396 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.763
2024-10-15 03:38:37,397 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.821
2024-10-15 03:38:37,397 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.503
2024-10-15 03:38:37,397 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:37,398 - optimal_runtime.py[116] - INFO: avg ratio: 3.1607879550516915
2024-10-15 03:38:37,398 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0015412631716800738
2024-10-15 03:38:37,398 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [5.97672362e-03 3.24514282e-04 2.58555028e-04 1.09759519e-04
 9.40995049e-05 1.59273729e-04 2.45771546e-04 6.51466772e-04]
2024-10-15 03:38:37,401 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:37,669 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:37,670 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.6, 0.4, 0.6, 0.8, 0.8, 0.8]
2024-10-15 03:38:37,680 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2024-10-15 03:38:37,685 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2024-10-15 03:38:37,689 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.6) from file
2024-10-15 03:38:37,690 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 437737088.0,
  'blocks_sparsity': [0.6, 0.4, 0.6, 0.4, 0.6, 0.8, 0.8, 0.8],
  'esti_latency': -0.0013478502364915148,
  'esti_test_accuracy': 0.7087666392326355,
  'is_relaxed': False,
  'model_size': 11401613.0,
  'update_swap_mem_cost': 3546446.0,
  'update_swap_time_cost': 0.019018888473510742}
2024-10-15 03:38:37,710 - gen_series_legodnn_models.py[28] - INFO: target model size: 11.327MB
2024-10-15 03:38:37,710 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 11876797.848484848B (11.327MB), try to adapt blocks
2024-10-15 03:38:37,712 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:37,764 - optimal_runtime.py[77] - INFO: infer time of current model: 0.049594528198242185
2024-10-15 03:38:37,765 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007303359983488918, 0.0004676800053566694, 0.0003484479957260192, 0.00026886400533840057, 0.00021251199953258037, 0.0002816320052370429, 0.0003042559970635921, 0.0005140480035915971]
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.600
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.256
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.876
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.203
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.782
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.630
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.914
2024-10-15 03:38:37,765 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.497
2024-10-15 03:38:37,766 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:37,766 - optimal_runtime.py[116] - INFO: avg ratio: 2.3259314614598177
2024-10-15 03:38:37,766 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002094475331424251
2024-10-15 03:38:37,766 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00143343 0.00057965 0.00039904 0.00014959 0.00019409 0.00016509
 0.00023796 0.00065403]
2024-10-15 03:38:37,768 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:37,942 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:37,943 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.0, 0.2, 0.4, 0.6, 0.8, 0.8, 0.8]
2024-10-15 03:38:37,991 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:38,017 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:38,017 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 541995648.0,
  'blocks_sparsity': [0.6, 0.0, 0.2, 0.4, 0.6, 0.8, 0.8, 0.8],
  'esti_latency': 0.0016339049132086444,
  'esti_test_accuracy': 0.712566614151001,
  'is_relaxed': False,
  'model_size': 11870413.0,
  'update_swap_mem_cost': 1610984.0,
  'update_swap_time_cost': 0.07366943359375}
2024-10-15 03:38:38,039 - gen_series_legodnn_models.py[28] - INFO: target model size: 11.761MB
2024-10-15 03:38:38,039 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 12332008.717171717B (11.761MB), try to adapt blocks
2024-10-15 03:38:38,041 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:38,058 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013852191925048827
2024-10-15 03:38:38,058 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00031523200031369924, 0.00013184000039473176, 0.00016195200104266404, 0.0003788800025358796, 0.00040268800221383567, 0.0004487360096536577, 0.00030777599732391533, 0.0005063040091190487]
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.389
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.523
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.339
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.402
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.468
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.278
2024-10-15 03:38:38,058 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.881
2024-10-15 03:38:38,059 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.520
2024-10-15 03:38:38,059 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([3, 4, 5, 6, 7]),)
2024-10-15 03:38:38,059 - optimal_runtime.py[116] - INFO: avg ratio: 2.50989030105064
2024-10-15 03:38:38,059 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0019409637411531054
2024-10-15 03:38:38,060 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061871 0.00013184 0.00014018 0.0002108  0.00036777 0.00026304
 0.00024072 0.00064418]
2024-10-15 03:38:38,061 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:38,236 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:38,238 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.4, 0.4, 0.4, 0.8, 0.8, 0.8]
2024-10-15 03:38:38,249 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2024-10-15 03:38:38,253 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.4) from file
2024-10-15 03:38:38,257 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:38,257 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 482454912.0,
  'blocks_sparsity': [0.6, 0.4, 0.4, 0.4, 0.4, 0.8, 0.8, 0.8],
  'esti_latency': 0.001970797655412007,
  'esti_test_accuracy': 0.7153666814168295,
  'is_relaxed': False,
  'model_size': 12280461.0,
  'update_swap_mem_cost': 5366670.0,
  'update_swap_time_cost': 0.019206523895263672}
2024-10-15 03:38:38,281 - gen_series_legodnn_models.py[28] - INFO: target model size: 12.195MB
2024-10-15 03:38:38,281 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 12787219.585858585B (12.195MB), try to adapt blocks
2024-10-15 03:38:38,283 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:38,295 - optimal_runtime.py[77] - INFO: infer time of current model: 0.008469535827636718
2024-10-15 03:38:38,295 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005553280003368854, 0.00039523200318217276, 0.00029983999580144883, 0.000437728002667427, 0.0004005119986832142, 0.0005093440040946008, 0.00045692799985408775, 0.0007434880062937737]
2024-10-15 03:38:38,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.789
2024-10-15 03:38:38,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.486
2024-10-15 03:38:38,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.155
2024-10-15 03:38:38,295 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.810
2024-10-15 03:38:38,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.491
2024-10-15 03:38:38,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.007
2024-10-15 03:38:38,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.940
2024-10-15 03:38:38,296 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.035
2024-10-15 03:38:38,296 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 4, 5, 6, 7]),)
2024-10-15 03:38:38,296 - optimal_runtime.py[116] - INFO: avg ratio: 1.591945689818282
2024-10-15 03:38:38,296 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030601584587770896
2024-10-15 03:38:38,297 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00108994 0.00048986 0.00023721 0.00024354 0.00036229 0.00029857
 0.00035737 0.00094595]
2024-10-15 03:38:38,298 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:38,470 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:38,471 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.2, 0.2, 0.4, 0.6, 0.6, 0.8, 0.8]
2024-10-15 03:38:38,482 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:38,489 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:38,493 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.6) from file
2024-10-15 03:38:38,500 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2024-10-15 03:38:38,501 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 543729024.0,
  'blocks_sparsity': [0.6, 0.2, 0.2, 0.4, 0.6, 0.6, 0.8, 0.8],
  'esti_latency': 0.00288460832541713,
  'esti_test_accuracy': 0.7191332777341207,
  'is_relaxed': False,
  'model_size': 12755853.0,
  'update_swap_mem_cost': 8212048.0,
  'update_swap_time_cost': 0.029004812240600586}
2024-10-15 03:38:38,537 - gen_series_legodnn_models.py[28] - INFO: target model size: 12.629MB
2024-10-15 03:38:38,537 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 13242430.454545455B (12.629MB), try to adapt blocks
2024-10-15 03:38:38,541 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:38,562 - optimal_runtime.py[77] - INFO: infer time of current model: 0.015673503875732422
2024-10-15 03:38:38,562 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005645439871586859, 0.00012825600011274219, 0.00032697600009851157, 0.0001997440014965832, 0.0003918400115799159, 0.000318239992717281, 0.0004943680064752698, 0.0005072000147774815]
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.776
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.595
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.645
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 8.350
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.509
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.079
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.793
2024-10-15 03:38:38,563 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.517
2024-10-15 03:38:38,564 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:38,564 - optimal_runtime.py[116] - INFO: avg ratio: 1.719800337771195
2024-10-15 03:38:38,564 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002832657932213565
2024-10-15 03:38:38,565 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [1.10803119e-03 9.58618278e-05 2.83024242e-04 1.11130401e-04
 3.57865279e-04 2.88295561e-04 3.86652199e-04 6.45318957e-04]
2024-10-15 03:38:38,568 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:38,807 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:38,809 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.4, 0.4, 0.4, 0.4, 0.6, 0.8, 0.8]
2024-10-15 03:38:38,818 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.4) from file
2024-10-15 03:38:38,824 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.4) from file
2024-10-15 03:38:38,828 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:38,829 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 512548992.0,
  'blocks_sparsity': [0.6, 0.4, 0.4, 0.4, 0.4, 0.6, 0.8, 0.8],
  'esti_latency': 0.002471286669731937,
  'esti_test_accuracy': 0.7221333384513855,
  'is_relaxed': False,
  'model_size': 13221261.0,
  'update_swap_mem_cost': 5311310.0,
  'update_swap_time_cost': 0.019777297973632812}
2024-10-15 03:38:38,850 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.063MB
2024-10-15 03:38:38,850 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 13697641.323232323B (13.063MB), try to adapt blocks
2024-10-15 03:38:38,852 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:38,911 - optimal_runtime.py[77] - INFO: infer time of current model: 0.05142659378051758
2024-10-15 03:38:38,911 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001299840030260384, 0.00013126399810425938, 0.00014185600401833654, 0.00020483200205489993, 0.000537472013151273, 0.00031657599913887676, 0.0005511360131204129, 0.0008498240178450942]
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 3.369
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.475
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.669
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 8.142
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.111
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.090
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.609
2024-10-15 03:38:38,911 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.905
2024-10-15 03:38:38,912 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5, 6]),)
2024-10-15 03:38:38,912 - optimal_runtime.py[116] - INFO: avg ratio: 2.530823499015883
2024-10-15 03:38:38,912 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0019249094496338762
2024-10-15 03:38:38,912 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00025512 0.00016269 0.00011223 0.00011396 0.00048618 0.00028679
 0.00043105 0.00108125]
2024-10-15 03:38:38,914 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:39,080 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:39,082 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.4, 0.4, 0.6, 0.8, 0.8]
2024-10-15 03:38:39,151 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:39,167 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:39,171 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:39,171 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 656111744.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.4, 0.4, 0.6, 0.8, 0.8],
  'esti_latency': 0.0020704066749138404,
  'esti_test_accuracy': 0.724133312702179,
  'is_relaxed': False,
  'model_size': 13637325.0,
  'update_swap_mem_cost': 2184780.0,
  'update_swap_time_cost': 0.08942437171936035}
2024-10-15 03:38:39,193 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.497MB
2024-10-15 03:38:39,194 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 14152852.191919193B (13.497MB), try to adapt blocks
2024-10-15 03:38:39,195 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:39,214 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01492585563659668
2024-10-15 03:38:39,214 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00037660799827426674, 0.00015686400048434737, 0.00016163199581205846, 0.00036185600189492104, 0.0002467199983075261, 0.00032518399902619423, 0.000318496004678309, 0.0006918079885654151]
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.886
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.642
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.350
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.609
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.420
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.034
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.784
2024-10-15 03:38:39,214 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.112
2024-10-15 03:38:39,215 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 4, 5, 6]),)
2024-10-15 03:38:39,215 - optimal_runtime.py[116] - INFO: avg ratio: 2.9466259145568943
2024-10-15 03:38:39,215 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.001653282842774334
2024-10-15 03:38:39,215 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00029786 0.00015686 0.00013991 0.00020132 0.00022317 0.00029459
 0.0002491  0.0008802 ]
2024-10-15 03:38:39,217 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:39,390 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:39,392 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.4, 0.6, 0.8, 0.8]
2024-10-15 03:38:39,402 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:39,408 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:39,408 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 708953216.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.4, 0.6, 0.8, 0.8],
  'esti_latency': 0.0018085966054922121,
  'esti_test_accuracy': 0.7245999773343405,
  'is_relaxed': False,
  'model_size': 14050509.0,
  'update_swap_mem_cost': 3324840.0,
  'update_swap_time_cost': 0.016123294830322266}
2024-10-15 03:38:39,432 - gen_series_legodnn_models.py[28] - INFO: target model size: 13.931MB
2024-10-15 03:38:39,432 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 14608063.06060606B (13.931MB), try to adapt blocks
2024-10-15 03:38:39,434 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:39,446 - optimal_runtime.py[77] - INFO: infer time of current model: 0.008277695655822754
2024-10-15 03:38:39,446 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006843520081602037, 0.0004009919948875904, 0.00033478400483727454, 0.00045436800271272666, 0.00040303999185562135, 0.0005520960018038749, 0.0004498239941895008, 0.0007373440079391002]
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.588
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.816
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.236
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.477
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.481
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.198
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.971
2024-10-15 03:38:39,447 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.044
2024-10-15 03:38:39,447 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6]),)
2024-10-15 03:38:39,450 - optimal_runtime.py[116] - INFO: avg ratio: 1.715036970120959
2024-10-15 03:38:39,450 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0028405253959438307
2024-10-15 03:38:39,450 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00054125 0.00040099 0.00033478 0.0002669  0.00036457 0.00050015
 0.00035181 0.00093813]
2024-10-15 03:38:39,452 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:39,624 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:39,625 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.4, 0.4, 0.4, 0.8, 0.8]
2024-10-15 03:38:39,636 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:39,657 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:39,667 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2024-10-15 03:38:39,668 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 686205824.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.4, 0.4, 0.4, 0.8, 0.8],
  'esti_latency': 0.003278725796400991,
  'esti_test_accuracy': 0.7256999611854553,
  'is_relaxed': False,
  'model_size': 14578125.0,
  'update_swap_mem_cost': 8107178.0,
  'update_swap_time_cost': 0.041968584060668945}
2024-10-15 03:38:39,699 - gen_series_legodnn_models.py[28] - INFO: target model size: 14.365MB
2024-10-15 03:38:39,699 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15063273.92929293B (14.365MB), try to adapt blocks
2024-10-15 03:38:39,703 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:39,735 - optimal_runtime.py[77] - INFO: infer time of current model: 0.025802560806274414
2024-10-15 03:38:39,735 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0004522559959441423, 0.0012038080093916504, 0.002803647965192795, 0.003771648019552231, 0.00034195200633257625, 0.0003511680029332637, 0.0004585280101746321, 0.0005069759960751981]
2024-10-15 03:38:39,736 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.403
2024-10-15 03:38:39,736 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.605
2024-10-15 03:38:39,736 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.003 = 0.308
2024-10-15 03:38:39,736 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.004 = 0.442
2024-10-15 03:38:39,737 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.746
2024-10-15 03:38:39,737 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.029
2024-10-15 03:38:39,737 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.934
2024-10-15 03:38:39,737 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.518
2024-10-15 03:38:39,738 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([4, 5, 6, 7]),)
2024-10-15 03:38:39,738 - optimal_runtime.py[116] - INFO: avg ratio: 1.8067134507950255
2024-10-15 03:38:39,739 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0026963910997991653
2024-10-15 03:38:39,740 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00035769 0.00120381 0.00242678 0.00209841 0.00030932 0.00029531
 0.00035862 0.00064503]
2024-10-15 03:38:39,743 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:39,973 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:39,975 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.4, 0.4, 0.8, 0.8]
2024-10-15 03:38:39,986 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:39,993 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:39,994 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 739047296.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.4, 0.4, 0.8, 0.8],
  'esti_latency': 0.004315265186735392,
  'esti_test_accuracy': 0.7261666258176168,
  'is_relaxed': False,
  'model_size': 14991309.0,
  'update_swap_mem_cost': 3324840.0,
  'update_swap_time_cost': 0.018517017364501953}
2024-10-15 03:38:40,017 - gen_series_legodnn_models.py[28] - INFO: target model size: 14.800MB
2024-10-15 03:38:40,018 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15518484.797979798B (14.800MB), try to adapt blocks
2024-10-15 03:38:40,019 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:40,062 - optimal_runtime.py[77] - INFO: infer time of current model: 0.03650431823730469
2024-10-15 03:38:40,062 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00014566400181502105, 0.00015286400006152688, 0.00034486401081085206, 0.0004397119963541627, 0.00039420799165964127, 0.0005224320071283727, 0.0006850880039855837, 0.0010789440097287298]
2024-10-15 03:38:40,062 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.461
2024-10-15 03:38:40,062 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.763
2024-10-15 03:38:40,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.170
2024-10-15 03:38:40,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.593
2024-10-15 03:38:40,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.514
2024-10-15 03:38:40,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.364
2024-10-15 03:38:40,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.294
2024-10-15 03:38:40,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.713
2024-10-15 03:38:40,063 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6, 7]),)
2024-10-15 03:38:40,063 - optimal_runtime.py[116] - INFO: avg ratio: 2.2017299767044736
2024-10-15 03:38:40,063 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0022126264892404807
2024-10-15 03:38:40,064 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0001152  0.00015286 0.00034486 0.00025829 0.00035659 0.00043933
 0.00053582 0.00137276]
2024-10-15 03:38:40,066 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:40,244 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:40,246 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.8, 0.8]
2024-10-15 03:38:40,295 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:40,318 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:40,323 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:40,324 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 711116416.0,
  'blocks_sparsity': [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.8, 0.8],
  'esti_latency': 0.0025283650535383967,
  'esti_test_accuracy': 0.7270665963490804,
  'is_relaxed': False,
  'model_size': 15468685.0,
  'update_swap_mem_cost': 7191694.0,
  'update_swap_time_cost': 0.07796239852905273}
2024-10-15 03:38:40,347 - gen_series_legodnn_models.py[28] - INFO: target model size: 15.234MB
2024-10-15 03:38:40,347 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 15973695.666666666B (15.234MB), try to adapt blocks
2024-10-15 03:38:40,349 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:40,365 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012961119651794433
2024-10-15 03:38:40,366 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00014070399664342404, 0.0005401599947363138, 0.0002015040018595755, 0.0006327680014073849, 0.0002980479993857443, 0.00035916799097321925, 0.0005395520003512502, 0.0007709120041690768]
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.724
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.803
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.291
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.497
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.117
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.984
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.643
2024-10-15 03:38:40,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.998
2024-10-15 03:38:40,366 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6, 7]),)
2024-10-15 03:38:40,367 - optimal_runtime.py[116] - INFO: avg ratio: 2.1905882041935034
2024-10-15 03:38:40,367 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002223880352904893
2024-10-15 03:38:40,367 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011128 0.00040373 0.00017442 0.00037169 0.00025507 0.00030204
 0.00042199 0.00098084]
2024-10-15 03:38:40,369 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:40,569 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:40,570 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.2, 0.6, 0.4, 0.4, 0.6, 0.6, 0.8]
2024-10-15 03:38:40,585 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:40,590 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.6) from file
2024-10-15 03:38:40,596 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:40,602 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:40,609 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2024-10-15 03:38:40,621 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.6) from file
2024-10-15 03:38:40,621 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 543696384.0,
  'blocks_sparsity': [0.6, 0.2, 0.6, 0.4, 0.4, 0.6, 0.6, 0.8],
  'esti_latency': 0.0023550385565501994,
  'esti_test_accuracy': 0.7279666463534037,
  'is_relaxed': False,
  'model_size': 15929997.0,
  'update_swap_mem_cost': 21522010.0,
  'update_swap_time_cost': 0.050978899002075195}
2024-10-15 03:38:40,654 - gen_series_legodnn_models.py[28] - INFO: target model size: 15.668MB
2024-10-15 03:38:40,654 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 16428906.535353536B (15.668MB), try to adapt blocks
2024-10-15 03:38:40,657 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:40,673 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011805983543395996
2024-10-15 03:38:40,673 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007385600060224532, 0.0005273279994726181, 0.0003693760000169277, 0.0005693439953029155, 0.0004831039980053902, 0.0006883839964866638, 0.0006123840063810349, 0.0008938880041241645]
2024-10-15 03:38:40,673 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.593
2024-10-15 03:38:40,673 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.847
2024-10-15 03:38:40,673 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.769
2024-10-15 03:38:40,674 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.929
2024-10-15 03:38:40,674 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.236
2024-10-15 03:38:40,674 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.961
2024-10-15 03:38:40,674 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.936
2024-10-15 03:38:40,674 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.861
2024-10-15 03:38:40,674 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:40,674 - optimal_runtime.py[116] - INFO: avg ratio: 1.2683474149481073
2024-10-15 03:38:40,674 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003840908264720561
2024-10-15 03:38:40,675 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00144957 0.00039414 0.00042301 0.00031676 0.000437   0.00062361
 0.00074112 0.00113731]
2024-10-15 03:38:40,677 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:40,881 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:40,882 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6, 0.8]
2024-10-15 03:38:40,892 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:40,899 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:40,900 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 650318336.0,
  'blocks_sparsity': [0.2, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6, 0.8],
  'esti_latency': 0.004414344750835924,
  'esti_test_accuracy': 0.731666644414266,
  'is_relaxed': False,
  'model_size': 16403597.0,
  'update_swap_mem_cost': 1500426.0,
  'update_swap_time_cost': 0.01713275909423828}
2024-10-15 03:38:40,941 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.102MB
2024-10-15 03:38:40,942 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 16884117.404040404B (16.102MB), try to adapt blocks
2024-10-15 03:38:40,945 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:40,966 - optimal_runtime.py[77] - INFO: infer time of current model: 0.015138431549072266
2024-10-15 03:38:40,966 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006631360035389661, 0.00013116799877025187, 0.00033011200674809517, 0.00021196800330653786, 0.0004214399983175099, 0.0006884480102453379, 0.0005587840068619699, 0.0005092480005696417]
2024-10-15 03:38:40,967 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.639
2024-10-15 03:38:40,967 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.427
2024-10-15 03:38:40,967 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.619
2024-10-15 03:38:40,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.868
2024-10-15 03:38:40,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.417
2024-10-15 03:38:40,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.961
2024-10-15 03:38:40,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.025
2024-10-15 03:38:40,968 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.511
2024-10-15 03:38:40,969 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:40,969 - optimal_runtime.py[116] - INFO: avg ratio: 1.528731982449669
2024-10-15 03:38:40,969 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031866972919640177
2024-10-15 03:38:40,980 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [5.24470194e-04 9.80383304e-05 2.85738710e-04 1.17931397e-04
 3.81218694e-04 6.23669275e-04 6.76255088e-04 6.47924644e-04]
2024-10-15 03:38:40,983 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:41,185 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:41,186 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.4, 0.6, 0.6, 0.8]
2024-10-15 03:38:41,197 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:41,203 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:41,207 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:41,208 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 731520512.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.4, 0.6, 0.6, 0.8],
  'esti_latency': 0.003257052583753645,
  'esti_test_accuracy': 0.7323333024978638,
  'is_relaxed': False,
  'model_size': 16872141.0,
  'update_swap_mem_cost': 3896298.0,
  'update_swap_time_cost': 0.021495580673217773}
2024-10-15 03:38:41,231 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.536MB
2024-10-15 03:38:41,231 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 17339328.272727273B (16.536MB), try to adapt blocks
2024-10-15 03:38:41,233 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:41,296 - optimal_runtime.py[77] - INFO: infer time of current model: 0.05636505508422852
2024-10-15 03:38:41,296 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013385599851608278, 0.0001493760012090206, 0.00018665599916130305, 0.00023420799849554897, 0.0003214399958960712, 0.0003837760044261813, 0.0005339839842636138, 0.0010347519617062062]
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.120
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.874
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.010
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.745
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.857
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.724
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.073
2024-10-15 03:38:41,297 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.744
2024-10-15 03:38:41,297 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6]),)
2024-10-15 03:38:41,297 - optimal_runtime.py[116] - INFO: avg ratio: 2.7076868139780506
2024-10-15 03:38:41,298 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0017991763461941634
2024-10-15 03:38:41,298 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010587 0.00014938 0.00018666 0.00013757 0.00029076 0.00034767
 0.00064624 0.00131653]
2024-10-15 03:38:41,300 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:41,472 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:41,474 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.4, 0.2, 0.6, 0.6, 0.8]
2024-10-15 03:38:41,514 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:41,538 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:41,538 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 723396864.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.4, 0.2, 0.6, 0.6, 0.8],
  'esti_latency': 0.0016279317625823994,
  'esti_test_accuracy': 0.733033279577891,
  'is_relaxed': False,
  'model_size': 17337805.0,
  'update_swap_mem_cost': 6693032.0,
  'update_swap_time_cost': 0.06458210945129395}
2024-10-15 03:38:41,565 - gen_series_legodnn_models.py[28] - INFO: target model size: 16.970MB
2024-10-15 03:38:41,565 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 17794539.141414143B (16.970MB), try to adapt blocks
2024-10-15 03:38:41,567 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:41,584 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0136878080368042
2024-10-15 03:38:41,584 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00014742399845272302, 0.00014364799903705716, 0.00040025598439387975, 0.00019840000011026856, 0.00030003199726343153, 0.00032220799243077637, 0.00038911999482661486, 0.000516511982306838]
2024-10-15 03:38:41,584 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.372
2024-10-15 03:38:41,584 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.069
2024-10-15 03:38:41,584 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.870
2024-10-15 03:38:41,584 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 8.406
2024-10-15 03:38:41,584 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.103
2024-10-15 03:38:41,585 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.053
2024-10-15 03:38:41,585 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.473
2024-10-15 03:38:41,585 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.490
2024-10-15 03:38:41,585 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:41,585 - optimal_runtime.py[116] - INFO: avg ratio: 2.342915339327042
2024-10-15 03:38:41,585 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002079292404142277
2024-10-15 03:38:41,586 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0001166  0.00014365 0.00040026 0.00011038 0.00025677 0.00029189
 0.00047092 0.00065717]
2024-10-15 03:38:41,587 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:41,759 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:41,759 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.8]
2024-10-15 03:38:41,770 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:41,776 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:41,782 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:41,788 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2024-10-15 03:38:41,788 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 739470592.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.8],
  'esti_latency': 0.002109656957381657,
  'esti_test_accuracy': 0.7338666121164957,
  'is_relaxed': False,
  'model_size': 17639885.0,
  'update_swap_mem_cost': 13101392.0,
  'update_swap_time_cost': 0.028586864471435547}
2024-10-15 03:38:41,814 - gen_series_legodnn_models.py[28] - INFO: target model size: 17.404MB
2024-10-15 03:38:41,814 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 18249750.01010101B (17.404MB), try to adapt blocks
2024-10-15 03:38:41,816 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:41,828 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00956550407409668
2024-10-15 03:38:41,829 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00043379199877381327, 0.00039369600266218186, 0.00031196799874305724, 0.000452160008251667, 0.0004004799984395504, 0.0005788160003721714, 0.0005266559980809689, 0.0007456319890916347]
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.505
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.849
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.772
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.494
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.491
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.231
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.088
2024-10-15 03:38:41,829 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.032
2024-10-15 03:38:41,829 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5]),)
2024-10-15 03:38:41,829 - optimal_runtime.py[116] - INFO: avg ratio: 1.9697405422439804
2024-10-15 03:38:41,830 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0024732222158870133
2024-10-15 03:38:41,830 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00034308 0.0003937  0.00027003 0.0002656  0.00036226 0.00048675
 0.00063737 0.00094868]
2024-10-15 03:38:41,832 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:42,004 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:42,006 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.0, 0.2, 0.2, 0.2, 0.4, 0.6, 0.8]
2024-10-15 03:38:42,019 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:42,026 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:42,027 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 700596224.0,
  'blocks_sparsity': [0.6, 0.0, 0.2, 0.2, 0.2, 0.4, 0.6, 0.8],
  'esti_latency': 0.0023727817306810704,
  'esti_test_accuracy': 0.7345665693283081,
  'is_relaxed': False,
  'model_size': 18225357.0,
  'update_swap_mem_cost': 5394954.0,
  'update_swap_time_cost': 0.020787954330444336}
2024-10-15 03:38:42,234 - gen_series_legodnn_models.py[28] - INFO: target model size: 17.838MB
2024-10-15 03:38:42,234 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 18704960.87878788B (17.838MB), try to adapt blocks
2024-10-15 03:38:42,238 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:42,255 - optimal_runtime.py[77] - INFO: infer time of current model: 0.011653216361999511
2024-10-15 03:38:42,256 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006867840029299259, 0.0004915839917957783, 0.0003805119954049587, 0.0005563200004398823, 0.0005055040046572685, 0.0006938239932060242, 0.0005954879932105541, 0.0008468160033226012]
2024-10-15 03:38:42,256 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.638
2024-10-15 03:38:42,256 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.481
2024-10-15 03:38:42,257 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.272
2024-10-15 03:38:42,257 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.840
2024-10-15 03:38:42,257 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.248
2024-10-15 03:38:42,257 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.027
2024-10-15 03:38:42,258 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.962
2024-10-15 03:38:42,258 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.909
2024-10-15 03:38:42,259 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 4, 5, 6, 7]),)
2024-10-15 03:38:42,259 - optimal_runtime.py[116] - INFO: avg ratio: 1.125518304408782
2024-10-15 03:38:42,259 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004328322382255815
2024-10-15 03:38:42,260 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00134795 0.00049158 0.00032936 0.00032678 0.00043261 0.00058346
 0.00072068 0.00107742]
2024-10-15 03:38:42,263 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:42,446 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:42,447 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.6, 0.8]
2024-10-15 03:38:42,478 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:42,494 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:42,494 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 784188416.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.6, 0.8],
  'esti_latency': 0.004741717228356429,
  'esti_test_accuracy': 0.7350332538286845,
  'is_relaxed': False,
  'model_size': 18518733.0,
  'update_swap_mem_cost': 2026762.0,
  'update_swap_time_cost': 0.04734039306640625}
2024-10-15 03:38:42,519 - gen_series_legodnn_models.py[28] - INFO: target model size: 18.273MB
2024-10-15 03:38:42,519 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 19160171.74747475B (18.273MB), try to adapt blocks
2024-10-15 03:38:42,521 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:42,644 - optimal_runtime.py[77] - INFO: infer time of current model: 0.11802419281005859
2024-10-15 03:38:42,644 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00012780799996107818, 0.00013180799945257605, 0.00018371199816465377, 0.00022489600139670077, 0.0002886079975869506, 0.0003626559958793223, 0.00040041599748656155, 0.0005271040075458586]
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.504
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.524
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.074
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.024
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.186
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.965
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.431
2024-10-15 03:38:42,644 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.460
2024-10-15 03:38:42,645 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:42,645 - optimal_runtime.py[116] - INFO: avg ratio: 3.4374599977406035
2024-10-15 03:38:42,645 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00141721098480075
2024-10-15 03:38:42,646 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010108 0.00013181 0.00018371 0.0001321  0.00024699 0.00030497
 0.00048459 0.00067064]
2024-10-15 03:38:42,647 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:42,814 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:42,816 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.2, 0.2, 0.4, 0.4, 0.6, 0.4, 0.8]
2024-10-15 03:38:42,829 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:42,834 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:42,837 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:42,842 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:42,846 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:42,851 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2024-10-15 03:38:42,861 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.4) from file
2024-10-15 03:38:42,861 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 611658688.0,
  'blocks_sparsity': [0.6, 0.2, 0.2, 0.4, 0.4, 0.6, 0.4, 0.8],
  'esti_latency': 0.0014719461519384644,
  'esti_test_accuracy': 0.7355332970619202,
  'is_relaxed': False,
  'model_size': 19132813.0,
  'update_swap_mem_cost': 28290972.0,
  'update_swap_time_cost': 0.04546999931335449}
2024-10-15 03:38:42,886 - gen_series_legodnn_models.py[28] - INFO: target model size: 18.707MB
2024-10-15 03:38:42,887 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 19615382.616161615B (18.707MB), try to adapt blocks
2024-10-15 03:38:42,888 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:42,902 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01074995231628418
2024-10-15 03:38:42,903 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005298559926450253, 0.0003759039975702763, 0.00034748798981308935, 0.0004301759973168373, 0.00041891201213002205, 0.0025692799277603627, 0.0006216959953308105, 0.0007489599920809268]
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.827
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.592
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.488
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.877
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.425
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.003 = 0.257
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.142
2024-10-15 03:38:42,903 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.027
2024-10-15 03:38:42,903 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 6, 7]),)
2024-10-15 03:38:42,904 - optimal_runtime.py[116] - INFO: avg ratio: 1.5835718578751987
2024-10-15 03:38:42,904 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030763403911128833
2024-10-15 03:38:42,904 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00103995 0.00028096 0.00030078 0.00023933 0.00037893 0.00232753
 0.00060703 0.00095291]
2024-10-15 03:38:42,906 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:43,080 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:43,081 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.4, 0.6, 0.4, 0.8]
2024-10-15 03:38:43,093 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:43,100 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:43,106 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:43,106 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 732165056.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.4, 0.6, 0.4, 0.8],
  'esti_latency': 0.003658566366230622,
  'esti_test_accuracy': 0.7365999619166056,
  'is_relaxed': False,
  'model_size': 19548621.0,
  'update_swap_mem_cost': 2671016.0,
  'update_swap_time_cost': 0.024773359298706055}
2024-10-15 03:38:43,131 - gen_series_legodnn_models.py[28] - INFO: target model size: 19.141MB
2024-10-15 03:38:43,131 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20070593.484848484B (19.141MB), try to adapt blocks
2024-10-15 03:38:43,133 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:43,150 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013538816452026366
2024-10-15 03:38:43,150 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001289280029013753, 0.00013638399890623988, 0.00016825599875301122, 0.000226624004309997, 0.0002513919919729233, 0.0003120640013366938, 0.000467328011058271, 0.0005098240114748478]
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.430
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.339
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.139
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.971
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.375
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.120
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.520
2024-10-15 03:38:43,150 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.509
2024-10-15 03:38:43,151 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:43,151 - optimal_runtime.py[116] - INFO: avg ratio: 3.743177343532393
2024-10-15 03:38:43,151 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0013014628005879802
2024-10-15 03:38:43,151 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010197 0.00013638 0.00014564 0.00013312 0.0002274  0.0002827
 0.0004563  0.00064866]
2024-10-15 03:38:43,153 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:43,369 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:43,370 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6, 0.6]
2024-10-15 03:38:43,379 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:43,385 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:43,392 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:43,401 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.6) from file
2024-10-15 03:38:43,411 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.6) from file
2024-10-15 03:38:43,412 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 618957696.0,
  'blocks_sparsity': [0.6, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6, 0.6],
  'esti_latency': 0.0015245261544995596,
  'esti_test_accuracy': 0.7385999957720438,
  'is_relaxed': False,
  'model_size': 20044941.0,
  'update_swap_mem_cost': 28296784.0,
  'update_swap_time_cost': 0.04134321212768555}
2024-10-15 03:38:43,445 - gen_series_legodnn_models.py[28] - INFO: target model size: 19.575MB
2024-10-15 03:38:43,446 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20525804.353535354B (19.575MB), try to adapt blocks
2024-10-15 03:38:43,449 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:43,468 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012382399559020997
2024-10-15 03:38:43,468 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00041033601434901354, 0.0004339199995156378, 0.00037600000202655794, 0.000544191986322403, 0.0003720320002175867, 0.0006677439995110035, 0.0005950079932808876, 0.0007606399932410568]
2024-10-15 03:38:43,469 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 1.067
2024-10-15 03:38:43,469 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.245
2024-10-15 03:38:43,469 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.300
2024-10-15 03:38:43,469 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 3.065
2024-10-15 03:38:43,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.605
2024-10-15 03:38:43,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.991
2024-10-15 03:38:43,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.963
2024-10-15 03:38:43,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.533
2024-10-15 03:38:43,471 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 7]),)
2024-10-15 03:38:43,472 - optimal_runtime.py[116] - INFO: avg ratio: 1.7500534273401225
2024-10-15 03:38:43,472 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00278368991055057
2024-10-15 03:38:43,473 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00080537 0.00032432 0.00032546 0.00030277 0.00033653 0.00060491
 0.00072009 0.00063846]
2024-10-15 03:38:43,476 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:43,685 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:43,687 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.4, 0.6, 0.6, 0.6]
2024-10-15 03:38:43,751 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:43,758 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:43,766 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:43,766 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 739464064.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.4, 0.6, 0.6, 0.6],
  'esti_latency': 0.0033552675789031735,
  'esti_test_accuracy': 0.7396666606267294,
  'is_relaxed': False,
  'model_size': 20460749.0,
  'update_swap_mem_cost': 2671016.0,
  'update_swap_time_cost': 0.07895517349243164}
2024-10-15 03:38:43,795 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.009MB
2024-10-15 03:38:43,795 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 20981015.222222224B (20.009MB), try to adapt blocks
2024-10-15 03:38:43,797 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:43,862 - optimal_runtime.py[77] - INFO: infer time of current model: 0.05781753540039063
2024-10-15 03:38:43,862 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001491840030066669, 0.00013408000278286635, 0.00016160000022500754, 0.00021932799927890304, 0.000251903998432681, 0.0003113920013420284, 0.00039228799566626553, 0.0008376960074529051]
2024-10-15 03:38:43,863 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.285
2024-10-15 03:38:43,863 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.430
2024-10-15 03:38:43,863 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.351
2024-10-15 03:38:43,864 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.203
2024-10-15 03:38:43,864 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.370
2024-10-15 03:38:43,864 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.125
2024-10-15 03:38:43,864 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.461
2024-10-15 03:38:43,864 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.392
2024-10-15 03:38:43,865 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:43,866 - optimal_runtime.py[116] - INFO: avg ratio: 3.8189668217039703
2024-10-15 03:38:43,866 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0012756345619251807
2024-10-15 03:38:43,867 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011799 0.00013408 0.00013988 0.00012883 0.00022786 0.00028209
 0.00047476 0.00070314]
2024-10-15 03:38:43,872 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:44,059 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:44,060 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.4, 0.2, 0.6, 0.6, 0.6]
2024-10-15 03:38:44,073 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:44,079 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:44,079 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 731340416.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.4, 0.2, 0.6, 0.6, 0.6],
  'esti_latency': 0.0015510670932253195,
  'esti_test_accuracy': 0.7403666377067566,
  'is_relaxed': False,
  'model_size': 20926413.0,
  'update_swap_mem_cost': 6693032.0,
  'update_swap_time_cost': 0.018455982208251953}
2024-10-15 03:38:44,105 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.443MB
2024-10-15 03:38:44,106 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 21436226.09090909B (20.443MB), try to adapt blocks
2024-10-15 03:38:44,107 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:44,119 - optimal_runtime.py[77] - INFO: infer time of current model: 0.008693568229675293
2024-10-15 03:38:44,120 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005452160015702248, 0.0003934400007128715, 0.00031849600002169606, 0.0004423040077090263, 0.00044233598932623863, 0.0005549120046198368, 0.0005312639996409417, 0.0008218239918351174]
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.993
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.851
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.715
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.771
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.427
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.192
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.079
2024-10-15 03:38:44,120 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.419
2024-10-15 03:38:44,120 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 7]),)
2024-10-15 03:38:44,121 - optimal_runtime.py[116] - INFO: avg ratio: 1.766184742175524
2024-10-15 03:38:44,121 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002758265289173811
2024-10-15 03:38:44,121 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00043121 0.00039344 0.00027568 0.00024608 0.00037855 0.0005027
 0.00064295 0.00068981]
2024-10-15 03:38:44,123 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:44,294 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:44,296 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6]
2024-10-15 03:38:44,308 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:44,314 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:44,321 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2024-10-15 03:38:44,321 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 769558144.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6, 0.6],
  'esti_latency': 0.003243290971705968,
  'esti_test_accuracy': 0.7412333091100057,
  'is_relaxed': False,
  'model_size': 21401549.0,
  'update_swap_mem_cost': 11475370.0,
  'update_swap_time_cost': 0.02499866485595703}
2024-10-15 03:38:44,346 - gen_series_legodnn_models.py[28] - INFO: target model size: 20.877MB
2024-10-15 03:38:44,347 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 21891436.95959596B (20.877MB), try to adapt blocks
2024-10-15 03:38:44,348 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:44,365 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013403615951538085
2024-10-15 03:38:44,365 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001456959992647171, 0.00032000000472180544, 0.00015488000097684565, 0.0004002239995170385, 0.00024527999269776047, 0.0005444799978286029, 0.0006128960002679378, 0.0005911360098980366]
2024-10-15 03:38:44,365 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.460
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.275
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.583
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.947
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.434
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.309
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.935
2024-10-15 03:38:44,366 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.973
2024-10-15 03:38:44,366 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 3, 4, 5, 7]),)
2024-10-15 03:38:44,366 - optimal_runtime.py[116] - INFO: avg ratio: 2.387718420453742
2024-10-15 03:38:44,366 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0020402766200904817
2024-10-15 03:38:44,367 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011523 0.00032    0.00013406 0.00023509 0.00022187 0.00045787
 0.00074174 0.00049618]
2024-10-15 03:38:44,368 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:44,577 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:44,578 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.4, 0.2, 0.4, 0.6, 0.6]
2024-10-15 03:38:44,596 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:44,605 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:44,606 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 761434496.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.4, 0.2, 0.4, 0.6, 0.6],
  'esti_latency': 0.0023691213774016478,
  'esti_test_accuracy': 0.741933286190033,
  'is_relaxed': False,
  'model_size': 21867213.0,
  'update_swap_mem_cost': 6693032.0,
  'update_swap_time_cost': 0.026931285858154297}
2024-10-15 03:38:44,646 - gen_series_legodnn_models.py[28] - INFO: target model size: 21.311MB
2024-10-15 03:38:44,646 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 22346647.82828283B (21.311MB), try to adapt blocks
2024-10-15 03:38:44,650 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:44,686 - optimal_runtime.py[77] - INFO: infer time of current model: 0.020190752029418946
2024-10-15 03:38:44,687 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007794879898428916, 0.0005659519955515861, 0.00042390399426221845, 0.0026441919058561325, 0.0005577279925346374, 0.0007567359879612923, 0.0006473920121788979, 0.0009959040135145186]
2024-10-15 03:38:44,687 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.394
2024-10-15 03:38:44,687 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.287
2024-10-15 03:38:44,687 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.040
2024-10-15 03:38:44,688 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.003 = 0.631
2024-10-15 03:38:44,688 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.131
2024-10-15 03:38:44,688 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.942
2024-10-15 03:38:44,689 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.885
2024-10-15 03:38:44,689 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.171
2024-10-15 03:38:44,690 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5, 6, 7]),)
2024-10-15 03:38:44,690 - optimal_runtime.py[116] - INFO: avg ratio: 1.1350602306852047
2024-10-15 03:38:44,690 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004291936178285702
2024-10-15 03:38:44,691 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00061649 0.00056595 0.00036692 0.00147113 0.0004773  0.00063636
 0.00078349 0.00083593]
2024-10-15 03:38:44,695 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:44,861 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:44,861 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.6, 0.6]
2024-10-15 03:38:44,869 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:44,904 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:44,904 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 814275968.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.6, 0.6],
  'esti_latency': 0.005712954122527354,
  'esti_test_accuracy': 0.7423999508221945,
  'is_relaxed': False,
  'model_size': 22280397.0,
  'update_swap_mem_cost': 3324840.0,
  'update_swap_time_cost': 0.042474985122680664}
2024-10-15 03:38:44,935 - gen_series_legodnn_models.py[28] - INFO: target model size: 21.746MB
2024-10-15 03:38:44,935 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 22801858.696969695B (21.746MB), try to adapt blocks
2024-10-15 03:38:44,942 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:44,974 - optimal_runtime.py[77] - INFO: infer time of current model: 0.022879743576049806
2024-10-15 03:38:44,974 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001374719967134297, 0.0001440640026703477, 0.00018470400059595704, 0.0002364480011165142, 0.000665535998530686, 0.00036204800265841186, 0.00039225600776262584, 0.0006003520078957081]
2024-10-15 03:38:44,974 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.906
2024-10-15 03:38:44,974 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.054
2024-10-15 03:38:44,974 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.052
2024-10-15 03:38:44,974 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.681
2024-10-15 03:38:44,974 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.948
2024-10-15 03:38:44,975 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.969
2024-10-15 03:38:44,975 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.461
2024-10-15 03:38:44,975 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.943
2024-10-15 03:38:44,975 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 5, 6, 7]),)
2024-10-15 03:38:44,975 - optimal_runtime.py[116] - INFO: avg ratio: 2.8956820301702
2024-10-15 03:38:44,975 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0016823691337148662
2024-10-15 03:38:44,976 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010873 0.00014406 0.0001847  0.00013889 0.00056957 0.00030446
 0.00047472 0.00050392]
2024-10-15 03:38:44,978 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:45,164 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:45,166 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.6, 0.6]
2024-10-15 03:38:45,167 - gen_series_legodnn_models.py[28] - INFO: target model size: 22.180MB
2024-10-15 03:38:45,167 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 23257069.565656565B (22.180MB), try to adapt blocks
2024-10-15 03:38:45,172 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:45,191 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012621824264526366
2024-10-15 03:38:45,191 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000520191996358335, 0.00046083199605345725, 0.0006423359848558903, 0.00037699200306087733, 0.0004931840039789677, 0.0006978879943490029, 0.0005086720013059675, 0.0007153919984120877]
2024-10-15 03:38:45,191 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.089
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.580
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.165
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.190
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.280
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.021
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.126
2024-10-15 03:38:45,192 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.630
2024-10-15 03:38:45,192 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:45,192 - optimal_runtime.py[116] - INFO: avg ratio: 1.4131649401668605
2024-10-15 03:38:45,192 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003447301818877509
2024-10-15 03:38:45,193 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00041142 0.00046083 0.00064234 0.00022144 0.00042207 0.00058688
 0.00061561 0.00060048]
2024-10-15 03:38:45,195 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:45,366 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:45,369 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.2, 0.2, 0.2, 0.4, 0.6, 0.4, 0.6]
2024-10-15 03:38:45,381 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:45,387 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:45,393 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:45,403 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.6) from file
2024-10-15 03:38:45,411 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.4) from file
2024-10-15 03:38:45,412 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 733891904.0,
  'blocks_sparsity': [0.2, 0.2, 0.2, 0.2, 0.4, 0.6, 0.4, 0.6],
  'esti_latency': 0.004202382220656255,
  'esti_test_accuracy': 0.7437666654586792,
  'is_relaxed': False,
  'model_size': 23254925.0,
  'update_swap_mem_cost': 26191414.0,
  'update_swap_time_cost': 0.042746543884277344}
2024-10-15 03:38:45,443 - gen_series_legodnn_models.py[28] - INFO: target model size: 22.614MB
2024-10-15 03:38:45,443 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 23712280.434343435B (22.614MB), try to adapt blocks
2024-10-15 03:38:45,446 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:45,467 - optimal_runtime.py[77] - INFO: infer time of current model: 0.015610527992248536
2024-10-15 03:38:45,467 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007064959853887559, 0.00013999999780207873, 0.0001573119992390275, 0.0004001920018345118, 0.0007213119985535741, 0.00031727999704889956, 0.0004759359918534756, 0.0008206719963345676]
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.538
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.958
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.497
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.947
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.828
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.085
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.492
2024-10-15 03:38:45,467 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.421
2024-10-15 03:38:45,468 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 3, 5, 6, 7]),)
2024-10-15 03:38:45,468 - optimal_runtime.py[116] - INFO: avg ratio: 2.0968860677708907
2024-10-15 03:38:45,468 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0023232573974750754
2024-10-15 03:38:45,468 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00055876 0.00010464 0.00013617 0.00023507 0.00065247 0.00028743
 0.00046471 0.00068885]
2024-10-15 03:38:45,470 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:45,650 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:45,653 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.0, 0.2, 0.4, 0.2, 0.6, 0.4, 0.6]
2024-10-15 03:38:45,671 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:45,678 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:45,685 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:45,692 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:45,693 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 692680768.0,
  'blocks_sparsity': [0.6, 0.0, 0.2, 0.4, 0.2, 0.6, 0.4, 0.6],
  'esti_latency': 0.0025406245980546384,
  'esti_test_accuracy': 0.7442332903544108,
  'is_relaxed': False,
  'model_size': 23655629.0,
  'update_swap_mem_cost': 7665230.0,
  'update_swap_time_cost': 0.03987240791320801}
2024-10-15 03:38:45,745 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.048MB
2024-10-15 03:38:45,745 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 24167491.303030305B (23.048MB), try to adapt blocks
2024-10-15 03:38:45,749 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:45,770 - optimal_runtime.py[77] - INFO: infer time of current model: 0.014147071838378907
2024-10-15 03:38:45,770 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007920640036463738, 0.0005594559982419014, 0.00042870400846004486, 0.000618304006755352, 0.0005511360019445419, 0.0007314879968762398, 0.0007350079715251923, 0.0009895679950714111]
2024-10-15 03:38:45,771 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.553
2024-10-15 03:38:45,771 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.301
2024-10-15 03:38:45,771 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.017
2024-10-15 03:38:45,771 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.697
2024-10-15 03:38:45,772 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.145
2024-10-15 03:38:45,772 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.904
2024-10-15 03:38:45,772 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.966
2024-10-15 03:38:45,773 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.179
2024-10-15 03:38:45,773 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 4, 5, 6, 7]),)
2024-10-15 03:38:45,774 - optimal_runtime.py[116] - INFO: avg ratio: 1.099163462109449
2024-10-15 03:38:45,774 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004432103355457111
2024-10-15 03:38:45,775 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00155459 0.00055946 0.00037108 0.000344   0.00047166 0.00066266
 0.00071766 0.00083061]
2024-10-15 03:38:45,778 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:46,008 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:46,009 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.2, 0.6, 0.4, 0.6]
2024-10-15 03:38:46,074 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:46,109 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:46,109 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 784826432.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.2, 0.6, 0.4, 0.6],
  'esti_latency': 0.005466985372560284,
  'esti_test_accuracy': 0.7450999617576599,
  'is_relaxed': False,
  'model_size': 24016077.0,
  'update_swap_mem_cost': 2099558.0,
  'update_swap_time_cost': 0.09989643096923828}
2024-10-15 03:38:46,141 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.482MB
2024-10-15 03:38:46,141 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 24622702.17171717B (23.482MB), try to adapt blocks
2024-10-15 03:38:46,143 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:46,217 - optimal_runtime.py[77] - INFO: infer time of current model: 0.07023820495605469
2024-10-15 03:38:46,217 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001519040004350245, 0.00014275199687108396, 0.00016073599783703686, 0.00022399999923072755, 0.0002967359977774322, 0.0003245119950734079, 0.00048140799393877384, 0.0006124160059262066]
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.155
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.101
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.380
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.052
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.127
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.039
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.475
2024-10-15 03:38:46,218 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.905
2024-10-15 03:38:46,219 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 7]),)
2024-10-15 03:38:46,219 - optimal_runtime.py[116] - INFO: avg ratio: 3.3099989233511935
2024-10-15 03:38:46,219 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.001471784789488363
2024-10-15 03:38:46,219 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012014 0.00014275 0.00013913 0.00013158 0.00025395 0.00029398
 0.00047005 0.00051404]
2024-10-15 03:38:46,222 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:46,396 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:46,398 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.0, 0.2, 0.4, 0.2, 0.4, 0.4, 0.6]
2024-10-15 03:38:46,410 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:46,417 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:46,424 - pure_runtime.py[42] - DEBUG: load 5th block (block-5) (sparsity 0.4) from file
2024-10-15 03:38:46,424 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 722774848.0,
  'blocks_sparsity': [0.6, 0.0, 0.2, 0.4, 0.2, 0.4, 0.4, 0.6],
  'esti_latency': 0.001747510306928771,
  'esti_test_accuracy': 0.7457999388376871,
  'is_relaxed': False,
  'model_size': 24596429.0,
  'update_swap_mem_cost': 6881896.0,
  'update_swap_time_cost': 0.026519775390625}
2024-10-15 03:38:46,456 - gen_series_legodnn_models.py[28] - INFO: target model size: 23.916MB
2024-10-15 03:38:46,456 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25077913.04040404B (23.916MB), try to adapt blocks
2024-10-15 03:38:46,458 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:46,471 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009978752136230468
2024-10-15 03:38:46,472 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006341120004653931, 0.0004362559989094734, 0.0003403199948370457, 0.0004938240014016628, 0.0004929600059986114, 0.0006334079951047897, 0.0006329279914498329, 0.0008570559956133367]
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.001 = 0.691
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.669
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.541
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.377
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.280
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.125
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.122
2024-10-15 03:38:46,472 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.361
2024-10-15 03:38:46,473 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 4, 5, 6, 7]),)
2024-10-15 03:38:46,473 - optimal_runtime.py[116] - INFO: avg ratio: 1.3114608979915974
2024-10-15 03:38:46,473 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0037146407308610106
2024-10-15 03:38:46,473 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00124457 0.00043626 0.00029457 0.00027475 0.00042188 0.00053265
 0.00061799 0.00071939]
2024-10-15 03:38:46,475 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:46,659 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:46,661 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.2, 0.4, 0.4, 0.6]
2024-10-15 03:38:46,673 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:46,680 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:46,680 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 814920512.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.2, 0.4, 0.4, 0.6],
  'esti_latency': 0.004606872960890409,
  'esti_test_accuracy': 0.7466666102409363,
  'is_relaxed': False,
  'model_size': 24956877.0,
  'update_swap_mem_cost': 2099558.0,
  'update_swap_time_cost': 0.019440650939941406}
2024-10-15 03:38:46,709 - gen_series_legodnn_models.py[28] - INFO: target model size: 24.350MB
2024-10-15 03:38:46,709 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25533123.90909091B (24.350MB), try to adapt blocks
2024-10-15 03:38:46,711 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:46,729 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0142291841506958
2024-10-15 03:38:46,729 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013168000080622733, 0.0001522239986807108, 0.0003765120133757591, 0.00022931200172752144, 0.00028703999891877176, 0.0005377600055653601, 0.00046627200860530136, 0.0006008319798856973]
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.254
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.783
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.297
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.889
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.198
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.325
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.523
2024-10-15 03:38:46,729 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.941
2024-10-15 03:38:46,730 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:46,730 - optimal_runtime.py[116] - INFO: avg ratio: 2.344656846754231
2024-10-15 03:38:46,730 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0020777479976888877
2024-10-15 03:38:46,730 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010414 0.00015222 0.0003259  0.0001347  0.00024565 0.00045222
 0.00045527 0.00050432]
2024-10-15 03:38:46,732 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:46,999 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:47,000 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6]
2024-10-15 03:38:47,007 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:47,008 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 837064512.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6],
  'esti_latency': 0.0024343438292481825,
  'esti_test_accuracy': 0.7466999491055807,
  'is_relaxed': False,
  'model_size': 25129933.0,
  'update_swap_mem_cost': 1626022.0,
  'update_swap_time_cost': 0.0069501399993896484}
2024-10-15 03:38:47,047 - gen_series_legodnn_models.py[28] - INFO: target model size: 24.784MB
2024-10-15 03:38:47,048 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 25988334.77777778B (24.784MB), try to adapt blocks
2024-10-15 03:38:47,049 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:47,063 - optimal_runtime.py[77] - INFO: infer time of current model: 0.007959519863128662
2024-10-15 03:38:47,063 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00033615999855101113, 0.00038755199685692787, 0.0003193599991500378, 0.0004466240033507347, 0.00045020799338817597, 0.0006000960022211075, 0.0006051839888095857, 0.000808415997773409]
2024-10-15 03:38:47,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.233
2024-10-15 03:38:47,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.879
2024-10-15 03:38:47,063 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.344
2024-10-15 03:38:47,064 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.537
2024-10-15 03:38:47,064 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.402
2024-10-15 03:38:47,064 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.188
2024-10-15 03:38:47,064 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.174
2024-10-15 03:38:47,064 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.443
2024-10-15 03:38:47,064 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:47,064 - optimal_runtime.py[116] - INFO: avg ratio: 1.5713354338662195
2024-10-15 03:38:47,064 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0031002967053474486
2024-10-15 03:38:47,065 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00026587 0.00038755 0.00031936 0.00026235 0.00038529 0.00050464
 0.0005909  0.00067856]
2024-10-15 03:38:47,067 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:47,232 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:47,232 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6]
2024-10-15 03:38:47,233 - gen_series_legodnn_models.py[28] - INFO: target model size: 25.219MB
2024-10-15 03:38:47,233 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 26443545.646464646B (25.219MB), try to adapt blocks
2024-10-15 03:38:47,235 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:47,286 - optimal_runtime.py[77] - INFO: infer time of current model: 0.039938430786132816
2024-10-15 03:38:47,286 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013183999946340917, 0.00014976000087335708, 0.00018544000154361128, 0.0002167360014282167, 0.00029804799892008306, 0.0003805760047398508, 0.0004890559930354357, 0.000610207997262478]
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.244
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.862
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.036
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.289
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.117
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.873
2024-10-15 03:38:47,286 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.452
2024-10-15 03:38:47,287 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.911
2024-10-15 03:38:47,287 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 7]),)
2024-10-15 03:38:47,287 - optimal_runtime.py[116] - INFO: avg ratio: 2.9598784239384845
2024-10-15 03:38:47,287 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0016458804622552265
2024-10-15 03:38:47,288 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010427 0.00014976 0.00018544 0.00012731 0.00025507 0.00032004
 0.00047752 0.00051219]
2024-10-15 03:38:47,289 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:47,459 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:47,460 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6]
2024-10-15 03:38:47,461 - gen_series_legodnn_models.py[28] - INFO: target model size: 25.653MB
2024-10-15 03:38:47,461 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 26898756.515151516B (25.653MB), try to adapt blocks
2024-10-15 03:38:47,465 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:47,526 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0524815673828125
2024-10-15 03:38:47,526 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001460480005480349, 0.00015068799583241345, 0.00017542399559170008, 0.00042627199832350013, 0.0004603199884295464, 0.0006037119925022125, 0.0006167359910905361, 0.0008074240200221539]
2024-10-15 03:38:47,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.442
2024-10-15 03:38:47,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.832
2024-10-15 03:38:47,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.267
2024-10-15 03:38:47,526 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.706
2024-10-15 03:38:47,527 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.371
2024-10-15 03:38:47,527 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.181
2024-10-15 03:38:47,527 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.152
2024-10-15 03:38:47,527 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.445
2024-10-15 03:38:47,527 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6, 7]),)
2024-10-15 03:38:47,527 - optimal_runtime.py[116] - INFO: avg ratio: 2.5645611939673114
2024-10-15 03:38:47,527 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0018995865959723474
2024-10-15 03:38:47,528 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011551 0.00015069 0.00017542 0.00025039 0.00039394 0.00050768
 0.00060218 0.00067773]
2024-10-15 03:38:47,529 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:47,696 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:47,697 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.6]
2024-10-15 03:38:47,698 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.087MB
2024-10-15 03:38:47,698 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 27353967.383838385B (26.087MB), try to adapt blocks
2024-10-15 03:38:47,703 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:47,719 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00934620761871338
2024-10-15 03:38:47,720 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005702720023691654, 0.000416192002594471, 0.0003362560085952282, 0.00047161599621176726, 0.000453695997595787, 0.0005937279835343361, 0.0006078400015830994, 0.0008294080086052417]
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.906
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.749
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.226
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.350
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.391
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.200
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.168
2024-10-15 03:38:47,720 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.406
2024-10-15 03:38:47,721 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:47,721 - optimal_runtime.py[116] - INFO: avg ratio: 1.5781633247578493
2024-10-15 03:38:47,721 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030868833359555072
2024-10-15 03:38:47,721 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00045102 0.00041619 0.00033626 0.00027703 0.00038827 0.00049929
 0.0005935  0.00069618]
2024-10-15 03:38:47,723 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:47,935 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:47,937 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.4, 0.4, 0.2, 0.6]
2024-10-15 03:38:47,948 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:47,960 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.2) from file
2024-10-15 03:38:47,961 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 837057984.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.4, 0.4, 0.2, 0.6],
  'esti_latency': 0.0037129135858828327,
  'esti_test_accuracy': 0.7471333146095276,
  'is_relaxed': False,
  'model_size': 27245773.0,
  'update_swap_mem_cost': 24882764.0,
  'update_swap_time_cost': 0.023789405822753906}
2024-10-15 03:38:47,987 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.521MB
2024-10-15 03:38:47,987 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 27809178.25252525B (26.521MB), try to adapt blocks
2024-10-15 03:38:47,989 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:48,013 - optimal_runtime.py[77] - INFO: infer time of current model: 0.020602176666259766
2024-10-15 03:38:48,013 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.003539328038692474, 0.0008154240027070046, 0.0005168960094451905, 0.0006227199956774712, 0.00047011199221014976, 0.0006978560090065003, 0.0007528639882802963, 0.0009314560107886792]
2024-10-15 03:38:48,013 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.004 = 0.307
2024-10-15 03:38:48,013 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.893
2024-10-15 03:38:48,013 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.448
2024-10-15 03:38:48,013 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.537
2024-10-15 03:38:48,013 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.270
2024-10-15 03:38:48,013 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.021
2024-10-15 03:38:48,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.989
2024-10-15 03:38:48,014 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.252
2024-10-15 03:38:48,014 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:48,014 - optimal_runtime.py[116] - INFO: avg ratio: 1.1455051550878301
2024-10-15 03:38:48,014 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004252801523392202
2024-10-15 03:38:48,015 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00279923 0.00081542 0.0005169  0.00036579 0.00042525 0.00058685
 0.00070139 0.00078183]
2024-10-15 03:38:48,018 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:48,278 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:48,279 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.2, 0.4, 0.2, 0.6]
2024-10-15 03:38:48,289 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:48,296 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:48,296 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 837487808.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.2, 0.4, 0.2, 0.6],
  'esti_latency': 0.00571385662276061,
  'esti_test_accuracy': 0.7482332785924276,
  'is_relaxed': False,
  'model_size': 27778509.0,
  'update_swap_mem_cost': 6620236.0,
  'update_swap_time_cost': 0.016799211502075195}
2024-10-15 03:38:48,324 - gen_series_legodnn_models.py[28] - INFO: target model size: 26.955MB
2024-10-15 03:38:48,325 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 28264389.12121212B (26.955MB), try to adapt blocks
2024-10-15 03:38:48,326 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:48,347 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01721183967590332
2024-10-15 03:38:48,347 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00015702400030568242, 0.00019203199865296485, 0.00037343999929726125, 0.0002361600031144917, 0.00030144000146538016, 0.00036332798935472964, 0.0005506880055181682, 0.000593887985451147]
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.922
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.792
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.315
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.689
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.093
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.962
2024-10-15 03:38:48,347 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.352
2024-10-15 03:38:48,348 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.964
2024-10-15 03:38:48,348 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:48,348 - optimal_runtime.py[116] - INFO: avg ratio: 2.2462888041418196
2024-10-15 03:38:48,348 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0021687354091017297
2024-10-15 03:38:48,348 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012419 0.00019203 0.00032324 0.00013872 0.00025797 0.00030553
 0.00051304 0.00049849]
2024-10-15 03:38:48,350 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:48,524 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:48,525 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.4, 0.4, 0.4, 0.4]
2024-10-15 03:38:48,546 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:48,552 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:48,564 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.4) from file
2024-10-15 03:38:48,595 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.4) from file
2024-10-15 03:38:48,596 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 844873216.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.4, 0.4, 0.4, 0.4],
  'esti_latency': 0.0022965505675242586,
  'esti_test_accuracy': 0.748699943224589,
  'is_relaxed': False,
  'model_size': 28222989.0,
  'update_swap_mem_cost': 45477684.0,
  'update_swap_time_cost': 0.07009124755859375}
2024-10-15 03:38:48,625 - gen_series_legodnn_models.py[28] - INFO: target model size: 27.389MB
2024-10-15 03:38:48,625 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 28719599.98989899B (27.389MB), try to adapt blocks
2024-10-15 03:38:48,627 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:48,700 - optimal_runtime.py[77] - INFO: infer time of current model: 0.06721129608154297
2024-10-15 03:38:48,700 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001365759982727468, 0.00014598399982787672, 0.00017795200226828457, 0.00023289600247517226, 0.00026092800125479695, 0.0005613120021298527, 0.0006165120080113411, 0.0009009599909186364]
2024-10-15 03:38:48,700 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.958
2024-10-15 03:38:48,700 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.988
2024-10-15 03:38:48,700 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.206
2024-10-15 03:38:48,700 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.783
2024-10-15 03:38:48,700 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.288
2024-10-15 03:38:48,700 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.270
2024-10-15 03:38:48,701 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.152
2024-10-15 03:38:48,701 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.869
2024-10-15 03:38:48,701 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6]),)
2024-10-15 03:38:48,701 - optimal_runtime.py[116] - INFO: avg ratio: 2.780662255157276
2024-10-15 03:38:48,701 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0017519589297750233
2024-10-15 03:38:48,702 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010802 0.00014598 0.00017795 0.0001368  0.00023603 0.00047203
 0.00060196 0.00112668]
2024-10-15 03:38:48,703 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:48,873 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:48,874 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4]
2024-10-15 03:38:48,888 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.2) from file
2024-10-15 03:38:48,893 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:48,898 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:48,898 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 816942336.0,
  'blocks_sparsity': [0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4],
  'esti_latency': 0.0018714571424036156,
  'esti_test_accuracy': 0.7495999137560526,
  'is_relaxed': False,
  'model_size': 28700365.0,
  'update_swap_mem_cost': 7191694.0,
  'update_swap_time_cost': 0.02443075180053711}
2024-10-15 03:38:48,928 - gen_series_legodnn_models.py[28] - INFO: target model size: 27.823MB
2024-10-15 03:38:48,928 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 29174810.85858586B (27.823MB), try to adapt blocks
2024-10-15 03:38:48,930 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:48,953 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01947065544128418
2024-10-15 03:38:48,953 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001428799997083843, 0.00014105599792674182, 0.0001644800007343292, 0.00022342400113120674, 0.00029081600136123594, 0.000367743996437639, 0.0004738239911384881, 0.0006737599871121347]
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.607
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.906
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.257
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.071
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.170
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.938
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.499
2024-10-15 03:38:48,953 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.162
2024-10-15 03:38:48,954 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 4, 5]),)
2024-10-15 03:38:48,954 - optimal_runtime.py[116] - INFO: avg ratio: 3.1216727360573073
2024-10-15 03:38:48,954 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0015605755248911883
2024-10-15 03:38:48,954 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.000113   0.00010543 0.00014237 0.00013124 0.00024888 0.00030925
 0.00046264 0.00084256]
2024-10-15 03:38:48,956 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:49,135 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:49,140 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.4]
2024-10-15 03:38:49,150 - pure_runtime.py[42] - DEBUG: load 1th block (block-1) (sparsity 0.0) from file
2024-10-15 03:38:49,154 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:49,155 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 867447040.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.4],
  'esti_latency': 0.0016254480248049097,
  'esti_test_accuracy': 0.7498332460721334,
  'is_relaxed': False,
  'model_size': 28928781.0,
  'update_swap_mem_cost': 2197480.0,
  'update_swap_time_cost': 0.014684200286865234}
2024-10-15 03:38:49,199 - gen_series_legodnn_models.py[28] - INFO: target model size: 28.257MB
2024-10-15 03:38:49,199 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 29630021.727272727B (28.257MB), try to adapt blocks
2024-10-15 03:38:49,202 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:49,221 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012767231941223145
2024-10-15 03:38:49,221 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000687968011945486, 0.000505247998982668, 0.00039948799833655364, 0.0004440000066533685, 0.0006086400039494038, 0.0006819200068712236, 0.0006663039810955525, 0.001002367988228798]
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.580
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.441
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.874
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.558
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.037
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.045
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.066
2024-10-15 03:38:49,222 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.781
2024-10-15 03:38:49,223 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:49,223 - optimal_runtime.py[116] - INFO: avg ratio: 1.260472646577369
2024-10-15 03:38:49,223 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003864904234010381
2024-10-15 03:38:49,224 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00054411 0.00050525 0.00039949 0.00026081 0.00052087 0.00057345
 0.00065058 0.0012535 ]
2024-10-15 03:38:49,226 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:49,516 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:49,517 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.4]
2024-10-15 03:38:49,517 - gen_series_legodnn_models.py[28] - INFO: target model size: 28.692MB
2024-10-15 03:38:49,518 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30085232.595959596B (28.692MB), try to adapt blocks
2024-10-15 03:38:49,520 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:49,645 - optimal_runtime.py[77] - INFO: infer time of current model: 0.11809996795654297
2024-10-15 03:38:49,646 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000141120002605021, 0.00014495999878272412, 0.00018227199697867035, 0.00022105600265786052, 0.0002828800058923662, 0.0006347199867013843, 0.000799776028841734, 0.0013732159859500825]
2024-10-15 03:38:49,646 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.702
2024-10-15 03:38:49,646 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.023
2024-10-15 03:38:49,646 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.106
2024-10-15 03:38:49,646 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.146
2024-10-15 03:38:49,646 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.231
2024-10-15 03:38:49,647 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.123
2024-10-15 03:38:49,647 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.888
2024-10-15 03:38:49,647 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.570
2024-10-15 03:38:49,647 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:49,648 - optimal_runtime.py[116] - INFO: avg ratio: 3.1206880233049623
2024-10-15 03:38:49,648 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0015610679543198534
2024-10-15 03:38:49,648 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011161 0.00014496 0.00018227 0.00012985 0.00024209 0.00053376
 0.0007809  0.00171726]
2024-10-15 03:38:49,652 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:49,820 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:49,821 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.4]
2024-10-15 03:38:49,822 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.126MB
2024-10-15 03:38:49,823 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30540443.464646466B (29.126MB), try to adapt blocks
2024-10-15 03:38:49,827 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:49,882 - optimal_runtime.py[77] - INFO: infer time of current model: 0.045107200622558595
2024-10-15 03:38:49,882 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00015980799915269017, 0.00014428799971938133, 0.00017795199993997813, 0.0005424639955163001, 0.00048118399828672416, 0.000649248007684946, 0.0006545280218124389, 0.000958912018686533]
2024-10-15 03:38:49,882 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 6.801
2024-10-15 03:38:49,882 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.046
2024-10-15 03:38:49,882 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.206
2024-10-15 03:38:49,883 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.912
2024-10-15 03:38:49,883 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.311
2024-10-15 03:38:49,883 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.098
2024-10-15 03:38:49,883 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.085
2024-10-15 03:38:49,883 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.816
2024-10-15 03:38:49,883 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 3, 4, 5, 6]),)
2024-10-15 03:38:49,883 - optimal_runtime.py[116] - INFO: avg ratio: 2.122456683626651
2024-10-15 03:38:49,883 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002295267604843181
2024-10-15 03:38:49,884 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012639 0.00014429 0.00017795 0.00031864 0.0004118  0.00054597
 0.00063908 0.00119916]
2024-10-15 03:38:49,885 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:50,054 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:50,054 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.4, 0.4]
2024-10-15 03:38:50,055 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.560MB
2024-10-15 03:38:50,055 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 30995654.333333332B (29.560MB), try to adapt blocks
2024-10-15 03:38:50,058 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:50,092 - optimal_runtime.py[77] - INFO: infer time of current model: 0.02271516799926758
2024-10-15 03:38:50,092 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00031507200794294476, 0.00013148799887858332, 0.00044271999131888153, 0.00021596800023689867, 0.0005674240160733461, 0.0003539839959703386, 0.00046489599999040363, 0.000657119995681569]
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.450
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.537
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.691
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.315
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.112
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.013
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.528
2024-10-15 03:38:50,093 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.191
2024-10-15 03:38:50,093 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:50,094 - optimal_runtime.py[116] - INFO: avg ratio: 1.8307769633747641
2024-10-15 03:38:50,094 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0026609500589471397
2024-10-15 03:38:50,094 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00024919 0.00013149 0.00044272 0.00012686 0.0004856  0.00029768
 0.00045393 0.00082175]
2024-10-15 03:38:50,096 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:50,278 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:50,279 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.4, 0.4, 0.2, 0.4]
2024-10-15 03:38:50,288 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:50,294 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.4) from file
2024-10-15 03:38:50,305 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.2) from file
2024-10-15 03:38:50,306 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 845296512.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.4, 0.4, 0.2, 0.4],
  'esti_latency': 0.0028609155094637103,
  'esti_test_accuracy': 0.7502332727114359,
  'is_relaxed': False,
  'model_size': 30871565.0,
  'update_swap_mem_cost': 26508786.0,
  'update_swap_time_cost': 0.026225805282592773}
2024-10-15 03:38:50,335 - gen_series_legodnn_models.py[28] - INFO: target model size: 29.994MB
2024-10-15 03:38:50,335 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 31450865.2020202B (29.994MB), try to adapt blocks
2024-10-15 03:38:50,337 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:50,359 - optimal_runtime.py[77] - INFO: infer time of current model: 0.018666847229003906
2024-10-15 03:38:50,360 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007183040156960487, 0.0005033279992640019, 0.00037936000153422357, 0.0005559359975159168, 0.00046585598587989805, 0.0011434879824519157, 0.0010105599858798086, 0.0022718399763107296]
2024-10-15 03:38:50,361 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.513
2024-10-15 03:38:50,361 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.447
2024-10-15 03:38:50,361 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.279
2024-10-15 03:38:50,361 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.842
2024-10-15 03:38:50,361 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.282
2024-10-15 03:38:50,361 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.623
2024-10-15 03:38:50,362 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.737
2024-10-15 03:38:50,362 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.002 = 0.345
2024-10-15 03:38:50,363 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5, 6]),)
2024-10-15 03:38:50,363 - optimal_runtime.py[116] - INFO: avg ratio: 1.1202127806868352
2024-10-15 03:38:50,363 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00434882207434218
2024-10-15 03:38:50,364 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005681  0.00050333 0.00032837 0.00032656 0.0004214  0.0009616
 0.00094147 0.00284102]
2024-10-15 03:38:50,367 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:50,635 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:50,636 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.4, 0.2, 0.4, 0.2, 0.4]
2024-10-15 03:38:50,644 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:50,651 - pure_runtime.py[42] - DEBUG: load 4th block (block-4) (sparsity 0.2) from file
2024-10-15 03:38:50,651 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 837172864.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.4, 0.2, 0.4, 0.2, 0.4],
  'esti_latency': 0.0045632167530747746,
  'esti_test_accuracy': 0.7509332497914633,
  'is_relaxed': False,
  'model_size': 31337229.0,
  'update_swap_mem_cost': 6693032.0,
  'update_swap_time_cost': 0.015319108963012695}
2024-10-15 03:38:50,693 - gen_series_legodnn_models.py[28] - INFO: target model size: 30.428MB
2024-10-15 03:38:50,693 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 31906076.07070707B (30.428MB), try to adapt blocks
2024-10-15 03:38:50,696 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:50,744 - optimal_runtime.py[77] - INFO: infer time of current model: 0.04254972839355469
2024-10-15 03:38:50,745 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005054719969630241, 0.0003715840019285679, 0.00029283200204372405, 0.0004308479949831963, 0.0004411519952118397, 0.0006262720045633616, 0.0005481279972009361, 0.0006603520042262972]
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.150
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.959
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.953
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.871
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.430
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.138
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.358
2024-10-15 03:38:50,745 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.186
2024-10-15 03:38:50,746 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5, 6, 7]),)
2024-10-15 03:38:50,746 - optimal_runtime.py[116] - INFO: avg ratio: 1.5369374267158153
2024-10-15 03:38:50,746 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003169684063860018
2024-10-15 03:38:50,746 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00039977 0.00037158 0.00025347 0.00023971 0.00037754 0.00052665
 0.00051065 0.00082579]
2024-10-15 03:38:50,748 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:50,914 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:50,915 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.4]
2024-10-15 03:38:50,922 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:50,931 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:50,931 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 890014336.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.4],
  'esti_latency': 0.0034790241836075895,
  'esti_test_accuracy': 0.7513999144236246,
  'is_relaxed': False,
  'model_size': 31750413.0,
  'update_swap_mem_cost': 3324840.0,
  'update_swap_time_cost': 0.016173362731933594}
2024-10-15 03:38:50,973 - gen_series_legodnn_models.py[28] - INFO: target model size: 30.862MB
2024-10-15 03:38:50,973 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 32361286.93939394B (30.862MB), try to adapt blocks
2024-10-15 03:38:50,975 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:51,071 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0906219482421875
2024-10-15 03:38:51,072 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00014720000093802808, 0.00014553599990904328, 0.00019337600190192462, 0.0002347840021830052, 0.00030243199877440924, 0.0003725119940936565, 0.0005523199955932796, 0.0008559680068865417]
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.384
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.003
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.870
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.728
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.087
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.913
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.348
2024-10-15 03:38:51,072 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.915
2024-10-15 03:38:51,073 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6]),)
2024-10-15 03:38:51,073 - optimal_runtime.py[116] - INFO: avg ratio: 2.8441738074928655
2024-10-15 03:38:51,073 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.001712836977746257
2024-10-15 03:38:51,073 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011642 0.00014554 0.00019338 0.00013791 0.00025882 0.00031326
 0.00051456 0.00107042]
2024-10-15 03:38:51,075 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:51,241 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:51,242 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.4]
2024-10-15 03:38:51,242 - gen_series_legodnn_models.py[28] - INFO: target model size: 31.296MB
2024-10-15 03:38:51,242 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 32816497.808080807B (31.296MB), try to adapt blocks
2024-10-15 03:38:51,244 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:51,263 - optimal_runtime.py[77] - INFO: infer time of current model: 0.014587615966796875
2024-10-15 03:38:51,263 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0008596799969673157, 0.0006328959912061691, 0.00045964799821376803, 0.0006749120131134987, 0.0005674559995532036, 0.0006538239903748035, 0.0006997119858860969, 0.0009071040116250514]
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.264
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.150
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.628
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.341
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.112
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.090
2024-10-15 03:38:51,263 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.064
2024-10-15 03:38:51,264 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.863
2024-10-15 03:38:51,264 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6]),)
2024-10-15 03:38:51,264 - optimal_runtime.py[116] - INFO: avg ratio: 1.2181487394933264
2024-10-15 03:38:51,264 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0039991882031068125
2024-10-15 03:38:51,265 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00067992 0.0006329  0.00045965 0.00039644 0.00048563 0.00054982
 0.00065187 0.00113437]
2024-10-15 03:38:51,266 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:51,440 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:51,441 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.4]
2024-10-15 03:38:51,442 - gen_series_legodnn_models.py[28] - INFO: target model size: 31.730MB
2024-10-15 03:38:51,442 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 33271708.676767677B (31.730MB), try to adapt blocks
2024-10-15 03:38:51,447 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:51,469 - optimal_runtime.py[77] - INFO: infer time of current model: 0.0155513916015625
2024-10-15 03:38:51,470 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0003528319990728051, 0.00013110400293953717, 0.0001878080014139414, 0.0002165760016068816, 0.0002805119983386249, 0.0003671680002007633, 0.0005416319840587675, 0.0006638400077354162]
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.080
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.554
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.985
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.294
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.250
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.941
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.374
2024-10-15 03:38:51,470 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.179
2024-10-15 03:38:51,470 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 4, 5, 6]),)
2024-10-15 03:38:51,471 - optimal_runtime.py[116] - INFO: avg ratio: 2.5261016374916645
2024-10-15 03:38:51,471 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00192850754550339
2024-10-15 03:38:51,471 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00027905 0.0001311  0.00018781 0.00012722 0.00024006 0.00030876
 0.0005046  0.00083016]
2024-10-15 03:38:51,473 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:51,743 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:51,744 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.4]
2024-10-15 03:38:51,745 - gen_series_legodnn_models.py[28] - INFO: target model size: 32.164MB
2024-10-15 03:38:51,745 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 33726919.54545455B (32.164MB), try to adapt blocks
2024-10-15 03:38:51,748 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:51,767 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012057855606079101
2024-10-15 03:38:51,768 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007363519929349422, 0.0005419200025498867, 0.0003974399976432323, 0.0005855040028691292, 0.0005100160017609596, 0.000605760008096695, 0.0006914880201220512, 0.0008969279900193215]
2024-10-15 03:38:51,768 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.476
2024-10-15 03:38:51,768 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.344
2024-10-15 03:38:51,768 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.883
2024-10-15 03:38:51,768 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.698
2024-10-15 03:38:51,768 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.237
2024-10-15 03:38:51,768 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.177
2024-10-15 03:38:51,769 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.076
2024-10-15 03:38:51,769 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.873
2024-10-15 03:38:51,769 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6]),)
2024-10-15 03:38:51,769 - optimal_runtime.py[116] - INFO: avg ratio: 1.3655040363436273
2024-10-15 03:38:51,769 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035676248029670498
2024-10-15 03:38:51,770 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00058238 0.00054192 0.00039744 0.00034392 0.00043647 0.0005094
 0.00064421 0.00112164]
2024-10-15 03:38:51,771 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:51,936 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:51,937 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.4]
2024-10-15 03:38:51,937 - gen_series_legodnn_models.py[28] - INFO: target model size: 32.599MB
2024-10-15 03:38:51,937 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 34182130.41414142B (32.599MB), try to adapt blocks
2024-10-15 03:38:51,939 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:52,055 - optimal_runtime.py[77] - INFO: infer time of current model: 0.10504208374023437
2024-10-15 03:38:52,055 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013072000071406365, 0.00014649600209668277, 0.00017612799862399696, 0.00022819199878722427, 0.00029907200345769523, 0.0003645440104883164, 0.0005605119932442904, 0.0007017600079998373]
2024-10-15 03:38:52,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.314
2024-10-15 03:38:52,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.970
2024-10-15 03:38:52,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.250
2024-10-15 03:38:52,055 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.923
2024-10-15 03:38:52,056 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.110
2024-10-15 03:38:52,056 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.955
2024-10-15 03:38:52,056 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.328
2024-10-15 03:38:52,056 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.116
2024-10-15 03:38:52,056 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:52,056 - optimal_runtime.py[116] - INFO: avg ratio: 3.321183867810327
2024-10-15 03:38:52,056 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0014668281740820987
2024-10-15 03:38:52,057 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010339 0.0001465  0.00017613 0.00013404 0.00025595 0.00030656
 0.00052219 0.00087758]
2024-10-15 03:38:52,058 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:52,223 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:52,223 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.4, 0.2, 0.4, 0.0, 0.4]
2024-10-15 03:38:52,240 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:52,269 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:52,292 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2024-10-15 03:38:52,292 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 859740160.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.4, 0.2, 0.4, 0.0, 0.4],
  'esti_latency': 0.0015536913686527748,
  'esti_test_accuracy': 0.7518999179204305,
  'is_relaxed': False,
  'model_size': 34158861.0,
  'update_swap_mem_cost': 28856654.0,
  'update_swap_time_cost': 0.06856179237365723}
2024-10-15 03:38:52,322 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.033MB
2024-10-15 03:38:52,323 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 34637341.28282829B (33.033MB), try to adapt blocks
2024-10-15 03:38:52,324 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:52,338 - optimal_runtime.py[77] - INFO: infer time of current model: 0.00984995174407959
2024-10-15 03:38:52,338 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005520959906280041, 0.00032940799929201604, 0.0003168640024960041, 0.0004413759931921959, 0.0004448639936745167, 0.0006612480040639638, 0.0007713279873132707, 0.0009299200028181076]
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.969
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.210
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.729
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.779
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.419
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.078
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.899
2024-10-15 03:38:52,338 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.842
2024-10-15 03:38:52,339 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5]),)
2024-10-15 03:38:52,339 - optimal_runtime.py[116] - INFO: avg ratio: 1.8808350019247313
2024-10-15 03:38:52,339 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002590129417852093
2024-10-15 03:38:52,340 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00043665 0.00032941 0.00027427 0.00024557 0.00038071 0.00055607
 0.00077133 0.0011629 ]
2024-10-15 03:38:52,341 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:52,526 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:52,527 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.4]
2024-10-15 03:38:52,537 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:52,548 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:52,549 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 912581632.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.4],
  'esti_latency': 0.0028144185020620577,
  'esti_test_accuracy': 0.7523665825525919,
  'is_relaxed': False,
  'model_size': 34572045.0,
  'update_swap_mem_cost': 3324840.0,
  'update_swap_time_cost': 0.021248817443847656}
2024-10-15 03:38:52,581 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.467MB
2024-10-15 03:38:52,581 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 35092552.15151515B (33.467MB), try to adapt blocks
2024-10-15 03:38:52,583 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:52,600 - optimal_runtime.py[77] - INFO: infer time of current model: 0.014037407875061036
2024-10-15 03:38:52,601 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00015059200348332524, 0.00014137600269168614, 0.00017232000036165117, 0.00021411199984140694, 0.00028630399727262555, 0.00035120000108145174, 0.0006167679869104177, 0.0006811520173214376]
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.217
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.150
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.343
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.378
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.204
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.029
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.124
2024-10-15 03:38:52,601 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.149
2024-10-15 03:38:52,602 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:52,602 - optimal_runtime.py[116] - INFO: avg ratio: 3.4317551470353704
2024-10-15 03:38:52,602 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0014195669154367363
2024-10-15 03:38:52,602 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0001191  0.00014138 0.00017232 0.00012577 0.00024502 0.00029534
 0.00061677 0.00085181]
2024-10-15 03:38:52,604 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:52,775 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:52,776 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.4]
2024-10-15 03:38:52,777 - gen_series_legodnn_models.py[28] - INFO: target model size: 33.901MB
2024-10-15 03:38:52,777 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 35547763.02020202B (33.901MB), try to adapt blocks
2024-10-15 03:38:52,781 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:52,802 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013719039916992188
2024-10-15 03:38:52,802 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007203199975192547, 0.0010579199874773623, 0.0004847680092789233, 0.0005655680000782014, 0.0005032319910824299, 0.0006864319853484631, 0.0008424319997429848, 0.0010154559910297394]
2024-10-15 03:38:52,803 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.509
2024-10-15 03:38:52,803 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.688
2024-10-15 03:38:52,803 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.544
2024-10-15 03:38:52,803 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.793
2024-10-15 03:38:52,804 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.254
2024-10-15 03:38:52,804 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.038
2024-10-15 03:38:52,804 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.823
2024-10-15 03:38:52,804 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.771
2024-10-15 03:38:52,805 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:52,805 - optimal_runtime.py[116] - INFO: avg ratio: 1.0896296777799321
2024-10-15 03:38:52,806 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004470882326311822
2024-10-15 03:38:52,806 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0005697  0.00105792 0.00048477 0.00033221 0.00043067 0.00057724
 0.00084243 0.00126987]
2024-10-15 03:38:52,809 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:53,058 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:53,060 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.2]
2024-10-15 03:38:53,073 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.2) from file
2024-10-15 03:38:53,091 - pure_runtime.py[42] - DEBUG: load 7th block (block-7) (sparsity 0.2) from file
2024-10-15 03:38:53,092 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 920101888.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.2],
  'esti_latency': 0.0050254718654111005,
  'esti_test_accuracy': 0.7528332471847534,
  'is_relaxed': False,
  'model_size': 35512077.0,
  'update_swap_mem_cost': 52061224.0,
  'update_swap_time_cost': 0.03206443786621094}
2024-10-15 03:38:53,123 - gen_series_legodnn_models.py[28] - INFO: target model size: 34.335MB
2024-10-15 03:38:53,123 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36002973.88888889B (34.335MB), try to adapt blocks
2024-10-15 03:38:53,125 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:53,199 - optimal_runtime.py[77] - INFO: infer time of current model: 0.06742486572265625
2024-10-15 03:38:53,199 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013011200167238713, 0.00014831999922171234, 0.00018684799736365675, 0.0002179839969612658, 0.0002866240050643683, 0.0003606080021709204, 0.0005459520034492016, 0.0007643840040545911]
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.353
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.909
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.006
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.247
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.202
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.976
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.363
2024-10-15 03:38:53,199 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.207
2024-10-15 03:38:53,200 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6]),)
2024-10-15 03:38:53,200 - optimal_runtime.py[116] - INFO: avg ratio: 2.8912281859913174
2024-10-15 03:38:53,200 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.001684960769341979
2024-10-15 03:38:53,200 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0001029  0.00014832 0.00018685 0.00012804 0.00024529 0.00030325
 0.00050862 0.00081098]
2024-10-15 03:38:53,202 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:53,370 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:53,371 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.2]
2024-10-15 03:38:53,372 - gen_series_legodnn_models.py[28] - INFO: target model size: 34.769MB
2024-10-15 03:38:53,372 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36458184.75757576B (34.769MB), try to adapt blocks
2024-10-15 03:38:53,376 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:53,437 - optimal_runtime.py[77] - INFO: infer time of current model: 0.051069377899169925
2024-10-15 03:38:53,438 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00015187200158834458, 0.00013446399942040443, 0.00017670399532653393, 0.00036556800547987223, 0.00045596799626946443, 0.0006046080105006694, 0.0006998079940676689, 0.0009417279744520782]
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.156
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.415
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.236
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.321
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.384
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.179
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.064
2024-10-15 03:38:53,438 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.980
2024-10-15 03:38:53,439 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6]),)
2024-10-15 03:38:53,439 - optimal_runtime.py[116] - INFO: avg ratio: 2.933037488341995
2024-10-15 03:38:53,439 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0016609423125256387
2024-10-15 03:38:53,439 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00012011 0.00013446 0.0001767  0.00021473 0.00039022 0.00050843
 0.00065196 0.00099914]
2024-10-15 03:38:53,441 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:53,611 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:53,612 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.2]
2024-10-15 03:38:53,613 - gen_series_legodnn_models.py[28] - INFO: target model size: 35.203MB
2024-10-15 03:38:53,613 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 36913395.62626263B (35.203MB), try to adapt blocks
2024-10-15 03:38:53,618 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:53,635 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009979167938232421
2024-10-15 03:38:53,635 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0004520639972761273, 0.00041500799730420114, 0.00033791999518871307, 0.000464479997754097, 0.0004468800015747547, 0.0005887680053710938, 0.0006998400017619133, 0.000939680012408644]
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.404
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.754
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.215
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.401
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.412
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.210
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.064
2024-10-15 03:38:53,636 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.982
2024-10-15 03:38:53,636 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6]),)
2024-10-15 03:38:53,637 - optimal_runtime.py[116] - INFO: avg ratio: 1.6766209295791568
2024-10-15 03:38:53,637 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029056097193263302
2024-10-15 03:38:53,637 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00035753 0.00041501 0.00033792 0.00027284 0.00038244 0.00049511
 0.00065199 0.00099697]
2024-10-15 03:38:53,639 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:53,822 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:53,823 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.2]
2024-10-15 03:38:53,824 - gen_series_legodnn_models.py[28] - INFO: target model size: 35.637MB
2024-10-15 03:38:53,824 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 37368606.4949495B (35.637MB), try to adapt blocks
2024-10-15 03:38:53,828 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:53,845 - optimal_runtime.py[77] - INFO: infer time of current model: 0.009490015983581544
2024-10-15 03:38:53,845 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005598079971969127, 0.00044259199500083925, 0.000343872006982565, 0.0004666239991784096, 0.0004426879957318306, 0.0005838079936802388, 0.0006902720108628274, 0.0009729279913008213]
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.941
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.645
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.177
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.385
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.425
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.221
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.078
2024-10-15 03:38:53,846 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.948
2024-10-15 03:38:53,846 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6]),)
2024-10-15 03:38:53,846 - optimal_runtime.py[116] - INFO: avg ratio: 1.5812854794362412
2024-10-15 03:38:53,846 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003080788467334795
2024-10-15 03:38:53,847 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00044275 0.00044259 0.00034387 0.00027409 0.00037885 0.00049094
 0.00064308 0.00103224]
2024-10-15 03:38:53,848 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:54,111 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:54,112 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.2, 0.2]
2024-10-15 03:38:54,112 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.072MB
2024-10-15 03:38:54,113 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 37823817.36363637B (36.072MB), try to adapt blocks
2024-10-15 03:38:54,116 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:54,136 - optimal_runtime.py[77] - INFO: infer time of current model: 0.012477503776550294
2024-10-15 03:38:54,136 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007204159945249557, 0.00046271999925374984, 0.00035356800630688667, 0.0003307199999690056, 0.0005165119953453541, 0.0006941120028495788, 0.0006854079961776733, 0.0009774080216884613]
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.509
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.574
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.117
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.777
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.222
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.027
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.086
2024-10-15 03:38:54,136 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.944
2024-10-15 03:38:54,137 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:54,137 - optimal_runtime.py[116] - INFO: avg ratio: 1.3539515091814847
2024-10-15 03:38:54,137 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0035980653927231232
2024-10-15 03:38:54,137 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00056977 0.00046272 0.00035357 0.00019426 0.00044203 0.0005837
 0.00063855 0.001037  ]
2024-10-15 03:38:54,139 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:54,312 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:54,314 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.6, 0.0, 0.2, 0.4, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:54,328 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.6) from file
2024-10-15 03:38:54,333 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.2) from file
2024-10-15 03:38:54,339 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.4) from file
2024-10-15 03:38:54,353 - pure_runtime.py[42] - DEBUG: load 6th block (block-6) (sparsity 0.0) from file
2024-10-15 03:38:54,354 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 828379520.0,
  'blocks_sparsity': [0.6, 0.0, 0.2, 0.4, 0.2, 0.4, 0.0, 0.2],
  'esti_latency': 0.0036537077387212564,
  'esti_test_accuracy': 0.7528999050458273,
  'is_relaxed': False,
  'model_size': 37800205.0,
  'update_swap_mem_cost': 29257394.0,
  'update_swap_time_cost': 0.03955268859863281}
2024-10-15 03:38:54,388 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.506MB
2024-10-15 03:38:54,388 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 38279028.23232323B (36.506MB), try to adapt blocks
2024-10-15 03:38:54,389 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:54,411 - optimal_runtime.py[77] - INFO: infer time of current model: 0.015280768394470215
2024-10-15 03:38:54,412 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001457919990643859, 0.00013801600178703667, 0.00035046400059945883, 0.00045337600121274585, 0.0007969920039176941, 0.0005200639925897121, 0.0009630719982087612, 0.0009946559946984053]
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.000 / 0.000 = 3.004
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.276
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.467
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.679
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.792
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.370
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.720
2024-10-15 03:38:54,412 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.928
2024-10-15 03:38:54,413 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5, 7]),)
2024-10-15 03:38:54,413 - optimal_runtime.py[116] - INFO: avg ratio: 2.0399878487370757
2024-10-15 03:38:54,413 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0023880564149571177
2024-10-15 03:38:54,413 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00028615 0.00013802 0.00030336 0.00025224 0.00068207 0.00043734
 0.00096307 0.00105529]
2024-10-15 03:38:54,415 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:54,583 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:54,584 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.2, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:54,591 - pure_runtime.py[42] - DEBUG: load 0th block (block-0) (sparsity 0.2) from file
2024-10-15 03:38:54,600 - pure_runtime.py[42] - DEBUG: load 3th block (block-3) (sparsity 0.2) from file
2024-10-15 03:38:54,601 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 920525184.0,
  'blocks_sparsity': [0.2, 0.0, 0.2, 0.2, 0.2, 0.4, 0.0, 0.2],
  'esti_latency': 0.0028250124745796087,
  'esti_test_accuracy': 0.7537665764490763,
  'is_relaxed': False,
  'model_size': 38160653.0,
  'update_swap_mem_cost': 2099558.0,
  'update_swap_time_cost': 0.016687870025634766}
2024-10-15 03:38:54,635 - gen_series_legodnn_models.py[28] - INFO: target model size: 36.940MB
2024-10-15 03:38:54,635 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 38734239.1010101B (36.940MB), try to adapt blocks
2024-10-15 03:38:54,637 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:54,651 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010962944030761718
2024-10-15 03:38:54,651 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005290239974856377, 0.0003835840001702309, 0.00031887999922037126, 0.0004604799970984459, 0.0004347520023584366, 0.0005879360102117062, 0.0007612479850649833, 0.0009414400258101523]
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.054
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.898
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.712
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.431
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.451
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.212
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.911
2024-10-15 03:38:54,652 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.980
2024-10-15 03:38:54,652 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5]),)
2024-10-15 03:38:54,652 - optimal_runtime.py[116] - INFO: avg ratio: 1.654084659212223
2024-10-15 03:38:54,652 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0029451975396055626
2024-10-15 03:38:54,653 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0004184  0.00038358 0.00027602 0.00027049 0.00037206 0.00049441
 0.00076125 0.00099883]
2024-10-15 03:38:54,655 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:54,827 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:54,827 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:54,832 - pure_runtime.py[42] - DEBUG: load 2th block (block-2) (sparsity 0.0) from file
2024-10-15 03:38:54,832 - gen_series_legodnn_models.py[33] - INFO: update info: 
{ 'FLOPs': 942669184.0,
  'blocks_sparsity': [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2],
  'esti_latency': 0.003344632065954178,
  'esti_test_accuracy': 0.7537999153137207,
  'is_relaxed': False,
  'model_size': 38333709.0,
  'update_swap_mem_cost': 1626022.0,
  'update_swap_time_cost': 0.004683971405029297}
2024-10-15 03:38:54,870 - gen_series_legodnn_models.py[28] - INFO: target model size: 37.374MB
2024-10-15 03:38:54,870 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 39189449.96969697B (37.374MB), try to adapt blocks
2024-10-15 03:38:54,872 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:54,886 - optimal_runtime.py[77] - INFO: infer time of current model: 0.010492799758911132
2024-10-15 03:38:54,886 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005362240038812161, 0.0003819520026445389, 0.0003342399969696999, 0.0004287679921835661, 0.00043590399250388145, 0.0004748159935697913, 0.0007684799991548061, 0.000985087998211384]
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.027
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.906
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.239
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.684
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.448
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.501
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.902
2024-10-15 03:38:54,886 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.937
2024-10-15 03:38:54,887 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5]),)
2024-10-15 03:38:54,887 - optimal_runtime.py[116] - INFO: avg ratio: 1.8242209923693398
2024-10-15 03:38:54,887 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0026705131061362207
2024-10-15 03:38:54,887 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0004241  0.00038195 0.00033424 0.00025186 0.00037305 0.00039929
 0.00076848 0.00104514]
2024-10-15 03:38:54,889 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:55,093 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:55,094 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:55,095 - gen_series_legodnn_models.py[28] - INFO: target model size: 37.808MB
2024-10-15 03:38:55,096 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 39644660.83838384B (37.808MB), try to adapt blocks
2024-10-15 03:38:55,100 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:55,129 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01903081512451172
2024-10-15 03:38:55,129 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0010378879979252816, 0.0007535039857029915, 0.0004639679985120892, 0.0007048320099711418, 0.0005826559960842132, 0.0008152639865875244, 0.0009094720035791397, 0.001200959987938404]
2024-10-15 03:38:55,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.047
2024-10-15 03:38:55,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.966
2024-10-15 03:38:55,130 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.613
2024-10-15 03:38:55,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.241
2024-10-15 03:38:55,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.083
2024-10-15 03:38:55,131 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.874
2024-10-15 03:38:55,132 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.762
2024-10-15 03:38:55,132 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.768
2024-10-15 03:38:55,133 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:55,133 - optimal_runtime.py[116] - INFO: avg ratio: 1.0163881112995454
2024-10-15 03:38:55,134 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.004793056918367875
2024-10-15 03:38:55,135 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00082086 0.0007535  0.00046397 0.00041402 0.00049864 0.00068558
 0.00090947 0.00127418]
2024-10-15 03:38:55,139 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:55,375 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:55,377 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:55,378 - gen_series_legodnn_models.py[28] - INFO: target model size: 38.242MB
2024-10-15 03:38:55,378 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 40099871.70707071B (38.242MB), try to adapt blocks
2024-10-15 03:38:55,382 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:55,402 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013300064086914063
2024-10-15 03:38:55,403 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005956800053827465, 0.00021439999528229234, 0.00017846400174312293, 0.00034089599642902617, 0.00029100800538435577, 0.0005072959959506988, 0.0007496000060345977, 0.0009113280023448169]
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.825
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.396
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.194
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 4.634
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.168
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.405
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.925
2024-10-15 03:38:55,403 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.013
2024-10-15 03:38:55,403 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 4, 5]),)
2024-10-15 03:38:55,404 - optimal_runtime.py[116] - INFO: avg ratio: 2.1984936576957366
2024-10-15 03:38:55,404 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0022158836126537312
2024-10-15 03:38:55,404 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00047112 0.0002144  0.00017846 0.00020024 0.00024904 0.0004266
 0.0007496  0.00096689]
2024-10-15 03:38:55,406 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:55,570 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:55,572 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:55,573 - gen_series_legodnn_models.py[28] - INFO: target model size: 38.676MB
2024-10-15 03:38:55,573 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 40555082.57575758B (38.676MB), try to adapt blocks
2024-10-15 03:38:55,577 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:55,637 - optimal_runtime.py[77] - INFO: infer time of current model: 0.05180105590820312
2024-10-15 03:38:55,637 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00014931200118735433, 0.00243615994695574, 0.0001732479981146753, 0.0004008000027388334, 0.00045583999902009965, 0.0006231999918818473, 0.0007781120166182518, 0.000993919998407364]
2024-10-15 03:38:55,637 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.279
2024-10-15 03:38:55,637 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.002 = 0.299
2024-10-15 03:38:55,637 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.320
2024-10-15 03:38:55,637 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.941
2024-10-15 03:38:55,637 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.384
2024-10-15 03:38:55,638 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.144
2024-10-15 03:38:55,638 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.891
2024-10-15 03:38:55,638 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.928
2024-10-15 03:38:55,638 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 3, 4, 5, 6, 7]),)
2024-10-15 03:38:55,638 - optimal_runtime.py[116] - INFO: avg ratio: 1.8440016398001262
2024-10-15 03:38:55,638 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002641866451452388
2024-10-15 03:38:55,639 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011809 0.00243616 0.00017325 0.00023543 0.00039011 0.00052407
 0.00077811 0.00105451]
2024-10-15 03:38:55,640 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:55,809 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:55,811 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:55,812 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.110MB
2024-10-15 03:38:55,812 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41010293.44444445B (39.110MB), try to adapt blocks
2024-10-15 03:38:55,817 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:55,837 - optimal_runtime.py[77] - INFO: infer time of current model: 0.013923551559448242
2024-10-15 03:38:55,837 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0007642240014392883, 0.00012777600018307566, 0.0003263999968767166, 0.00047023998177610335, 0.0005005440097302198, 0.0006477439966984092, 0.0008080639764666557, 0.0007927999882958829]
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.422
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.698
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.293
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.359
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.261
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.100
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.858
2024-10-15 03:38:55,837 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.164
2024-10-15 03:38:55,838 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 2, 3, 4, 5, 6, 7]),)
2024-10-15 03:38:55,838 - optimal_runtime.py[116] - INFO: avg ratio: 1.6368170068955226
2024-10-15 03:38:55,838 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002976267993360419
2024-10-15 03:38:55,838 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00060442 0.00012778 0.0003264  0.00027622 0.00042837 0.00054471
 0.00080806 0.00084113]
2024-10-15 03:38:55,840 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:56,002 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:56,003 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:56,003 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.545MB
2024-10-15 03:38:56,003 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41465504.31313131B (39.545MB), try to adapt blocks
2024-10-15 03:38:56,005 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:56,020 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01136464023590088
2024-10-15 03:38:56,020 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0006717120110988618, 0.0005291520021855832, 0.0004209279865026474, 0.0005880640111863613, 0.0005318080000579358, 0.0007314240001142025, 0.0008290559761226177, 0.0011012799963355064]
2024-10-15 03:38:56,020 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.618
2024-10-15 03:38:56,020 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.376
2024-10-15 03:38:56,020 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.778
2024-10-15 03:38:56,021 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.001 = 2.686
2024-10-15 03:38:56,021 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.187
2024-10-15 03:38:56,021 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.974
2024-10-15 03:38:56,021 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.836
2024-10-15 03:38:56,021 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.838
2024-10-15 03:38:56,021 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:56,021 - optimal_runtime.py[116] - INFO: avg ratio: 1.2296403689722428
2024-10-15 03:38:56,022 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.003961813707110906
2024-10-15 03:38:56,022 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00053125 0.00052915 0.00042093 0.00034543 0.00045512 0.00061508
 0.00082906 0.00116842]
2024-10-15 03:38:56,024 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:56,258 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:56,259 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:56,260 - gen_series_legodnn_models.py[28] - INFO: target model size: 39.979MB
2024-10-15 03:38:56,260 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 41920715.18181818B (39.979MB), try to adapt blocks
2024-10-15 03:38:56,263 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:56,283 - optimal_runtime.py[77] - INFO: infer time of current model: 0.014201087951660156
2024-10-15 03:38:56,287 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00048617598600685596, 0.0004626559987664223, 0.000296608004719019, 0.0004106560023501515, 0.0003411199986003339, 0.00041699200402945275, 0.0008339199991896748, 0.0012770559841301292]
2024-10-15 03:38:56,287 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.236
2024-10-15 03:38:56,288 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.574
2024-10-15 03:38:56,288 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.523
2024-10-15 03:38:56,288 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.847
2024-10-15 03:38:56,288 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.850
2024-10-15 03:38:56,289 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.709
2024-10-15 03:38:56,289 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.832
2024-10-15 03:38:56,289 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.723
2024-10-15 03:38:56,290 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5]),)
2024-10-15 03:38:56,290 - optimal_runtime.py[116] - INFO: avg ratio: 1.9783451307868525
2024-10-15 03:38:56,291 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0024624652153962374
2024-10-15 03:38:56,291 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00038451 0.00046266 0.00029661 0.00024122 0.00029193 0.00035066
 0.00083392 0.00135491]
2024-10-15 03:38:56,294 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:56,476 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:56,476 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:56,477 - gen_series_legodnn_models.py[28] - INFO: target model size: 40.413MB
2024-10-15 03:38:56,477 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 42375926.05050505B (40.413MB), try to adapt blocks
2024-10-15 03:38:56,479 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:56,554 - optimal_runtime.py[77] - INFO: infer time of current model: 0.06787286376953125
2024-10-15 03:38:56,555 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013699199724942447, 0.00013980800006538628, 0.00018832000205293298, 0.00022719999635592103, 0.00028819200047291814, 0.00035728000616654755, 0.0006332159982994198, 0.000998240000102669]
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.934
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.208
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.974
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.953
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.190
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.995
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.095
2024-10-15 03:38:56,555 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.924
2024-10-15 03:38:56,556 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:56,556 - optimal_runtime.py[116] - INFO: avg ratio: 3.3416960397338937
2024-10-15 03:38:56,556 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0014578244133176997
2024-10-15 03:38:56,557 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00010835 0.00013981 0.00018832 0.00013346 0.00024663 0.00030045
 0.00063322 0.0010591 ]
2024-10-15 03:38:56,559 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:56,727 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:56,727 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:56,728 - gen_series_legodnn_models.py[28] - INFO: target model size: 40.847MB
2024-10-15 03:38:56,728 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 42831136.91919192B (40.847MB), try to adapt blocks
2024-10-15 03:38:56,729 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:56,816 - optimal_runtime.py[77] - INFO: infer time of current model: 0.08053788757324219
2024-10-15 03:38:56,817 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0001445439988747239, 0.00015651199757121503, 0.00018319999938830732, 0.0002170879994519055, 0.0002918719975277781, 0.0003623039964586496, 0.0006245440002530813, 0.0007796479938551783]
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.519
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.652
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.085
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.277
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.162
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.967
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.110
2024-10-15 03:38:56,817 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.184
2024-10-15 03:38:56,818 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:56,818 - optimal_runtime.py[116] - INFO: avg ratio: 3.2166905918258317
2024-10-15 03:38:56,818 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0015144776687539485
2024-10-15 03:38:56,818 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011432 0.00015651 0.0001832  0.00012752 0.00024978 0.00030467
 0.00062454 0.00082718]
2024-10-15 03:38:56,820 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:56,985 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:56,987 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:56,988 - gen_series_legodnn_models.py[28] - INFO: target model size: 41.281MB
2024-10-15 03:38:56,989 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 43286347.78787879B (41.281MB), try to adapt blocks
2024-10-15 03:38:56,994 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:57,067 - optimal_runtime.py[77] - INFO: infer time of current model: 0.06487407684326171
2024-10-15 03:38:57,068 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00014438399765640496, 0.00014259200217202304, 0.00018348800111562012, 0.00022095999866724014, 0.00046006399765610695, 0.0006489279940724373, 0.0007913920097053051, 0.001021215993911028]
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.528
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.106
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.079
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.149
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.372
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.098
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.876
2024-10-15 03:38:57,068 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.904
2024-10-15 03:38:57,069 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:57,069 - optimal_runtime.py[116] - INFO: avg ratio: 2.239178587317728
2024-10-15 03:38:57,069 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002175621942886991
2024-10-15 03:38:57,069 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011419 0.00014259 0.00018349 0.00012979 0.00039372 0.0005457
 0.00079139 0.00108347]
2024-10-15 03:38:57,071 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:57,235 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:57,236 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:57,236 - gen_series_legodnn_models.py[28] - INFO: target model size: 41.715MB
2024-10-15 03:38:57,236 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 43741558.65656566B (41.715MB), try to adapt blocks
2024-10-15 03:38:57,238 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:57,335 - optimal_runtime.py[77] - INFO: infer time of current model: 0.08913919830322266
2024-10-15 03:38:57,335 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000134783998131752, 0.00015507199941202997, 0.00017647999711334702, 0.00021395199932157993, 0.00028128000209107993, 0.00035254399431869387, 0.0006753279976546764, 0.0011299519948661328]
2024-10-15 03:38:57,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 8.064
2024-10-15 03:38:57,335 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.695
2024-10-15 03:38:57,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.241
2024-10-15 03:38:57,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.384
2024-10-15 03:38:57,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.243
2024-10-15 03:38:57,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.022
2024-10-15 03:38:57,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.027
2024-10-15 03:38:57,336 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.817
2024-10-15 03:38:57,336 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:57,337 - optimal_runtime.py[116] - INFO: avg ratio: 3.3003504943586695
2024-10-15 03:38:57,337 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0014760874873557344
2024-10-15 03:38:57,337 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.0001066  0.00015507 0.00017648 0.00012568 0.00024072 0.00029647
 0.00067533 0.00119884]
2024-10-15 03:38:57,340 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:57,577 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:57,577 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:57,578 - gen_series_legodnn_models.py[28] - INFO: target model size: 42.149MB
2024-10-15 03:38:57,578 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 44196769.52525253B (42.149MB), try to adapt blocks
2024-10-15 03:38:57,579 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:57,595 - optimal_runtime.py[77] - INFO: infer time of current model: 0.01148476791381836
2024-10-15 03:38:57,595 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005809599943459035, 0.0003874559998512268, 0.0003437760025262833, 0.00046035199984908104, 0.0004513280056416989, 0.0006658240072429179, 0.0008543040081858634, 0.0008021760093979536]
2024-10-15 03:38:57,595 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.871
2024-10-15 03:38:57,595 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.879
2024-10-15 03:38:57,595 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.177
2024-10-15 03:38:57,595 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 3.432
2024-10-15 03:38:57,595 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.398
2024-10-15 03:38:57,595 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.070
2024-10-15 03:38:57,596 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.812
2024-10-15 03:38:57,596 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.150
2024-10-15 03:38:57,596 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 7]),)
2024-10-15 03:38:57,596 - optimal_runtime.py[116] - INFO: avg ratio: 1.5910189323972048
2024-10-15 03:38:57,596 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0030619409797160895
2024-10-15 03:38:57,597 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00045948 0.00038746 0.00034378 0.00027041 0.00038625 0.00055991
 0.0008543  0.00085108]
2024-10-15 03:38:57,599 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:57,765 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:57,766 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:57,766 - gen_series_legodnn_models.py[28] - INFO: target model size: 42.583MB
2024-10-15 03:38:57,766 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 44651980.39393939B (42.583MB), try to adapt blocks
2024-10-15 03:38:57,768 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:57,908 - optimal_runtime.py[77] - INFO: infer time of current model: 0.13101132202148438
2024-10-15 03:38:57,908 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.00013974399911239742, 0.00013753599720075726, 0.00017430399823933841, 0.00021750400378368795, 0.0002865279973484576, 0.00035260800295509404, 0.0006168320041615516, 0.000757408007979393]
2024-10-15 03:38:57,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 7.777
2024-10-15 03:38:57,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.294
2024-10-15 03:38:57,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.294
2024-10-15 03:38:57,908 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.263
2024-10-15 03:38:57,909 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.202
2024-10-15 03:38:57,909 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.021
2024-10-15 03:38:57,909 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.124
2024-10-15 03:38:57,909 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.218
2024-10-15 03:38:57,909 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([1, 2, 4, 5]),)
2024-10-15 03:38:57,909 - optimal_runtime.py[116] - INFO: avg ratio: 3.4528872958583894
2024-10-15 03:38:57,909 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.0014108789691613902
2024-10-15 03:38:57,910 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00011052 0.00013754 0.0001743  0.00012776 0.00024521 0.00029652
 0.00061683 0.00080358]
2024-10-15 03:38:57,911 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:58,076 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:58,078 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:58,079 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.018MB
2024-10-15 03:38:58,079 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 45107191.26262626B (43.018MB), try to adapt blocks
2024-10-15 03:38:58,084 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:58,107 - optimal_runtime.py[77] - INFO: infer time of current model: 0.017141759872436522
2024-10-15 03:38:58,108 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.0005312639973126352, 0.00033856000192463397, 0.0006283839996904135, 0.0002200960023328662, 0.0005191360015887768, 0.0005446719981264322, 0.000826559987384826, 0.0007647360223345459]
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 2.046
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.151
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.191
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.177
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.216
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.308
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.839
2024-10-15 03:38:58,108 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.207
2024-10-15 03:38:58,109 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:58,109 - optimal_runtime.py[116] - INFO: avg ratio: 1.4224510309648573
2024-10-15 03:38:58,109 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00342479703171694
2024-10-15 03:38:58,109 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00042017 0.00033856 0.00062838 0.00012928 0.00044428 0.00045803
 0.00082656 0.00081136]
2024-10-15 03:38:58,111 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:58,290 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:58,292 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:58,293 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.452MB
2024-10-15 03:38:58,293 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 45562402.13131313B (43.452MB), try to adapt blocks
2024-10-15 03:38:58,298 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:58,391 - optimal_runtime.py[77] - INFO: infer time of current model: 0.08628928375244141
2024-10-15 03:38:58,392 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.000917376013007015, 0.0001632320010103285, 0.00019401600304991008, 0.00022006400348618623, 0.0002918400021735579, 0.0003638400107156485, 0.0006326080018188804, 0.0007594879949465394]
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.185
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 4.461
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.858
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 7.178
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.162
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.959
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.096
2024-10-15 03:38:58,392 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 1.215
2024-10-15 03:38:58,393 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([0, 1, 2, 4, 5, 6, 7]),)
2024-10-15 03:38:58,393 - optimal_runtime.py[116] - INFO: avg ratio: 2.27647535108374
2024-10-15 03:38:58,393 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.00213997751668691
2024-10-15 03:38:58,393 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00072555 0.00016323 0.00019402 0.00012927 0.00024976 0.00030597
 0.00063261 0.00080579]
2024-10-15 03:38:58,395 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:58,662 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:58,662 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
2024-10-15 03:38:58,663 - gen_series_legodnn_models.py[28] - INFO: target model size: 43.886MB
2024-10-15 03:38:58,663 - optimal_runtime.py[268] - INFO: cur max inference time: 100.000000s, cur available max memory: 46017613.0B (43.886MB), try to adapt blocks
2024-10-15 03:38:58,665 - optimal_runtime.py[243] - INFO: no blocks infer time info, profile it through an inference
2024-10-15 03:38:58,755 - optimal_runtime.py[77] - INFO: infer time of current model: 0.08365261077880859
2024-10-15 03:38:58,755 - optimal_runtime.py[85] - INFO: infer time of current blocks: [0.002422784115653486, 0.00014499199716374277, 0.00018860800284892319, 0.00022697600396350025, 0.00029340800433419646, 0.0004783680001273751, 0.0008104960061609745, 0.0010365759804844858]
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.002 = 0.449
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 5.022
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 3.968
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.002 / 0.000 = 6.960
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 2.151
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.000 = 1.490
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.856
2024-10-15 03:38:58,755 - optimal_runtime.py[106] - INFO: ratio: cal infer time / real infer time of biggest block of cur sparsity: 0.001 / 0.001 = 0.890
2024-10-15 03:38:58,756 - optimal_runtime.py[114] - INFO: legal avg ratio indexes: (array([2, 4, 5, 6, 7]),)
2024-10-15 03:38:58,756 - optimal_runtime.py[116] - INFO: avg ratio: 1.8709383545278926
2024-10-15 03:38:58,756 - optimal_runtime.py[119] - INFO: cur cal infer time of original model: 0.002603830348991072
2024-10-15 03:38:58,757 - optimal_runtime.py[254] - INFO: cur original blocks pred infer time: [0.00191617 0.00014499 0.00018861 0.00013333 0.0002511  0.00040228
 0.0008105  0.00109977]
2024-10-15 03:38:58,758 - optimal_runtime.py[226] - INFO: solving...
2024-10-15 03:38:58,922 - optimal_runtime.py[228] - INFO: solving finished
2024-10-15 03:38:58,922 - pure_runtime.py[26] - INFO: load blocks with sparsity [0.2, 0.0, 0.0, 0.2, 0.2, 0.4, 0.0, 0.2]
